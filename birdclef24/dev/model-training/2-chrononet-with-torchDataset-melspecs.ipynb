{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corresponded information in 11.1-organize-in-torchDataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from typing import List\n",
    "from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
    "\n",
    "import torchaudio\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "from lightning.pytorch.callbacks  import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path='../../data/train_metadata_new_tiny.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize label encoder\n",
    "\n",
    "encoder=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lblwar1', 'blrwar1', 'bkskit1', 'comros', 'houcro1', 'houspa', 'graher1', 'blhori1', 'mawthr1', 'grewar3', 'hoopoe', 'indpit1', 'litspi1', 'wemhar1', 'laudov1', 'litgre1', 'rocpig', 'grecou1', 'whbwoo2', 'barswa', 'gyhcaf1', 'purher1', 'litegr', 'commyn', 'lirplo', 'putbab1', 'cregos1', 'bkwsti', 'gybpri1', 'commoo3', 'categr', 'asbfly', 'brwowl1', 'marsan', 'maghor2', 'zitcis1', 'bcnher', 'woosan', 'greegr', 'grtdro1', 'comtai1', 'eaywag1', 'grejun2', 'placuc3', 'grnsan', 'eucdov', 'comkin1', 'junowl1', 'ingori1', 'emedov2', 'sttwoo1', 'rorpar', 'thbwar1', 'comsan', 'goflea1', 'indrol2', 'cohcuc1', 'blakit1', 'comgre', 'eurcoo', 'whbbul2', 'rewlap1', 'inbrob1', 'brnshr', 'rerswa1', 'plapri1', 'whiter2', 'whbwat1', 'labcro1', 'plaflo1', 'grywag', 'spodov', 'redspu1', 'spepic1', 'yebbul3', 'gargan', 'spoowl1', 'aspswi1', 'eurbla2', 'brodro1', 'rewbul', 'stbkin1', 'ashdro1', 'lobsun2', 'rossta2', 'tilwar1', 'grefla1', 'compea', 'sbeowl1', 'barfly1', 'crseag1', 'comior1', 'grenig1', 'ruftre2', 'grehor1', 'blnmon1', 'whtkin2', 'asikoe2', 'insbab1', 'bladro1', 'heswoo1', 'brnhao1', 'grbeat1', 'inpher1', 'piebus1', 'wynlau1', 'kenplo1', 'grnwar1', 'junmyn1', 'insowl1', 'bwfshr1', 'junbab2', 'orihob2', 'shikra1', 'indrob1', 'btbeat1', 'whbwag1', 'pursun3', 'oripip1', 'forwag1', 'brcful1', 'sqtbul1', 'sohmyn1', 'whrmun', 'litswi1', 'yebbab1', 'brwjac1', 'revbul', 'purswa3', 'moipig1', 'lewduc1', 'gryfra', 'tibfly3', 'comfla1', 'whbsho3', 'ashpri1', 'pabflo1', 'copbar1', 'vehpar1', 'grynig2', 'gloibi', 'piekin1', 'lesyel1', 'nutman', 'whcbar1', 'bkrfla1', 'pursun4', 'ashwoo2', 'brasta1', 'malwoo1', 'kerlau2', 'plhpar1', 'smamin1', 'dafbab1', 'indtit1', 'maltro1', 'vefnut1', 'brakit1', 'wbbfly1', 'paisto1']\n",
      "160\n",
      "[ 89  16  10  36  71  72  52  14 102  60  70  74  95 145  88  94 125  54\n",
      " 150   7  68 115  93  34  92 119  40  11  67  33  27   0  24 101  98 159\n",
      "   8 155  55  63  38  43  58 111  61  45  32  84  78  44 138 126 139  37\n",
      "  51  76  28  13  30  47 146 124  73  21 121 113 152 149  87 112  66 134\n",
      " 120 133 158  49 135   5  46  22 123 137   1  97 127 141  56  35 129   6\n",
      "  41  31  59 128  57  15 154   4  80  12  69  20  53  79 109 156  85  62\n",
      "  83  81  26  82 105 130  75  25 148 116 106  48  19 136 132 153  96 157\n",
      "  23 122 118 103  91  64 140  29 147   2 107  39 143  65  50 110  90 104\n",
      " 151   9 117   3  18 100  86 114 131  42  77  99 142  17 144 108]\n",
      "{'asbfly': 0, 'ashdro1': 1, 'ashpri1': 2, 'ashwoo2': 3, 'asikoe2': 4, 'aspswi1': 5, 'barfly1': 6, 'barswa': 7, 'bcnher': 8, 'bkrfla1': 9, 'bkskit1': 10, 'bkwsti': 11, 'bladro1': 12, 'blakit1': 13, 'blhori1': 14, 'blnmon1': 15, 'blrwar1': 16, 'brakit1': 17, 'brasta1': 18, 'brcful1': 19, 'brnhao1': 20, 'brnshr': 21, 'brodro1': 22, 'brwjac1': 23, 'brwowl1': 24, 'btbeat1': 25, 'bwfshr1': 26, 'categr': 27, 'cohcuc1': 28, 'comfla1': 29, 'comgre': 30, 'comior1': 31, 'comkin1': 32, 'commoo3': 33, 'commyn': 34, 'compea': 35, 'comros': 36, 'comsan': 37, 'comtai1': 38, 'copbar1': 39, 'cregos1': 40, 'crseag1': 41, 'dafbab1': 42, 'eaywag1': 43, 'emedov2': 44, 'eucdov': 45, 'eurbla2': 46, 'eurcoo': 47, 'forwag1': 48, 'gargan': 49, 'gloibi': 50, 'goflea1': 51, 'graher1': 52, 'grbeat1': 53, 'grecou1': 54, 'greegr': 55, 'grefla1': 56, 'grehor1': 57, 'grejun2': 58, 'grenig1': 59, 'grewar3': 60, 'grnsan': 61, 'grnwar1': 62, 'grtdro1': 63, 'gryfra': 64, 'grynig2': 65, 'grywag': 66, 'gybpri1': 67, 'gyhcaf1': 68, 'heswoo1': 69, 'hoopoe': 70, 'houcro1': 71, 'houspa': 72, 'inbrob1': 73, 'indpit1': 74, 'indrob1': 75, 'indrol2': 76, 'indtit1': 77, 'ingori1': 78, 'inpher1': 79, 'insbab1': 80, 'insowl1': 81, 'junbab2': 82, 'junmyn1': 83, 'junowl1': 84, 'kenplo1': 85, 'kerlau2': 86, 'labcro1': 87, 'laudov1': 88, 'lblwar1': 89, 'lesyel1': 90, 'lewduc1': 91, 'lirplo': 92, 'litegr': 93, 'litgre1': 94, 'litspi1': 95, 'litswi1': 96, 'lobsun2': 97, 'maghor2': 98, 'maltro1': 99, 'malwoo1': 100, 'marsan': 101, 'mawthr1': 102, 'moipig1': 103, 'nutman': 104, 'orihob2': 105, 'oripip1': 106, 'pabflo1': 107, 'paisto1': 108, 'piebus1': 109, 'piekin1': 110, 'placuc3': 111, 'plaflo1': 112, 'plapri1': 113, 'plhpar1': 114, 'purher1': 115, 'pursun3': 116, 'pursun4': 117, 'purswa3': 118, 'putbab1': 119, 'redspu1': 120, 'rerswa1': 121, 'revbul': 122, 'rewbul': 123, 'rewlap1': 124, 'rocpig': 125, 'rorpar': 126, 'rossta2': 127, 'ruftre2': 128, 'sbeowl1': 129, 'shikra1': 130, 'smamin1': 131, 'sohmyn1': 132, 'spepic1': 133, 'spodov': 134, 'spoowl1': 135, 'sqtbul1': 136, 'stbkin1': 137, 'sttwoo1': 138, 'thbwar1': 139, 'tibfly3': 140, 'tilwar1': 141, 'vefnut1': 142, 'vehpar1': 143, 'wbbfly1': 144, 'wemhar1': 145, 'whbbul2': 146, 'whbsho3': 147, 'whbwag1': 148, 'whbwat1': 149, 'whbwoo2': 150, 'whcbar1': 151, 'whiter2': 152, 'whrmun': 153, 'whtkin2': 154, 'woosan': 155, 'wynlau1': 156, 'yebbab1': 157, 'yebbul3': 158, 'zitcis1': 159}\n"
     ]
    }
   ],
   "source": [
    "raw_df=pd.read_csv(labels_path,header=0)\n",
    "\n",
    "labels_all=raw_df.primary_label.unique().tolist()\n",
    "\n",
    "print(labels_all)\n",
    "print(len(labels_all))\n",
    "\n",
    "labels_encoded=encoder.fit_transform(labels_all)\n",
    "\n",
    "print(labels_encoded)\n",
    "\n",
    "# If needed, you can view the mapping of original labels to encodings\n",
    "label_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw_df,labels_all,labels_encoded,label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(path: str):\n",
    "    \"\"\"\n",
    "    Read an OGG file using torchaudio and return the waveform tensor and sample rate.\n",
    "\n",
    "    Parameters:\n",
    "        path: Path to the .ogg file\n",
    "\n",
    "    Returns:\n",
    "        waveform: Tensor representing the waveform\n",
    "        sample_rate: Sample rate of the audio file\n",
    "    \"\"\"\n",
    "    audio, sample_rate = torchaudio.load(path)\n",
    "    return audio, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regarding the data of a single audio, some audio information needs to be paid attention to, such as audio duration and number of channels.\n",
    "\n",
    "\n",
    "def audio_info(audio: torch.Tensor, sample_rate: int):\n",
    "    \"\"\"\n",
    "    Grab all information of the input audio loaded by torchaudio.\n",
    "\n",
    "    Parameters:\n",
    "        audio: Tensor representing the waveform\n",
    "        sample_rate: Sample rate of the audio file\n",
    "\n",
    "    Return:\n",
    "        duration_seconds: Duration of the audio in seconds\n",
    "        num_channels: Number of audio channels\n",
    "    \"\"\"\n",
    "    # The audio duration time (seconds)\n",
    "    duration_seconds = audio.shape[1] / sample_rate\n",
    "\n",
    "    # The number of channels\n",
    "    num_channels = audio.shape[0]\n",
    "\n",
    "\n",
    "    return duration_seconds, num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert audio data into mel spectrogram\n",
    "\n",
    "\n",
    "def mel_transform(sample_rate:float,audio:torch.Tensor,window_size: float=0.04,hop_size:float=0.02,n_mels:int=40)->torch.Tensor:\n",
    "    \"\"\"\n",
    "    transform audio data into mel sepctrogram\n",
    "    \"\"\"\n",
    "    # Determine window size and frame shift\n",
    "    # window_size = 0.04 # 40 milliseconds\n",
    "    # hop_size = 0.02 # 20 milliseconds, usually half the window size\n",
    "    n_fft = int(window_size * sample_rate)  # Convert the window size to the number of sampling points\n",
    "    hop_length = int(hop_size * sample_rate)  # Convert frame shift to sampling point number\n",
    "\n",
    "    # Calculate Mel Spectrogram\n",
    "    # n_mels = 40 # Number of Mel filters\n",
    "\n",
    "    # Set up Mel Spectrogram converter\n",
    "    mel_transformer = MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "        f_min=0,\n",
    "        f_max=16000\n",
    "    )\n",
    "\n",
    "    melspec=mel_transformer(audio)\n",
    "\n",
    "    return melspec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdclefDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 encoder:LabelEncoder,\n",
    "                 audio_dir:str='../../data/train_audio',\n",
    "                 labels_path:str=None,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            encoder: label encoder\n",
    "            audio_dir: the parent path where all audio files stored\n",
    "            labels_path: the file including all corresponding labels\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.encoder=encoder\n",
    "        self.audio_dir=audio_dir\n",
    "        # read data into dataframe\n",
    "        self.labels_df=pd.read_csv(labels_path,header=0)\n",
    "\n",
    "\n",
    "    def get_audio_path(self,index) -> str:\n",
    "        '''\n",
    "        Get the audio path of the corresponding index through the provided train metadata csv file. \n",
    "        Since there is only one index, only one path will be returned.\n",
    "\n",
    "        Parameters:\n",
    "            index: the index of labels metadata file\n",
    "\n",
    "        Return:\n",
    "            the single audio path string\n",
    "        '''\n",
    "        # Get the child path of audio from labels_df\n",
    "        audio_child_path=self.labels_df['filename'].iloc[index]\n",
    "\n",
    "        # concatenate parent path and child path\n",
    "        return os.path.join(self.audio_dir,audio_child_path)\n",
    "    \n",
    "\n",
    "    def get_audio_label(self,index)->str:\n",
    "        '''\n",
    "        According to the provided index, get the corresponding label from the train metadata file\n",
    "\n",
    "        Parameters:\n",
    "            index: the index of labels metadata file\n",
    "        '''\n",
    "\n",
    "        return self.labels_df['primary_label'].iloc[index]\n",
    "    \n",
    "\n",
    "    def target_clip(self,index:int,audio:torch.Tensor,sample_rate:int, duration_seconds:float)->torch.Tensor:\n",
    "        \"\"\"\n",
    "        calculate the index corresponding audio clip \n",
    "\n",
    "        information from the train metadata csv\n",
    "\n",
    "        Parameters:\n",
    "            audio: the raw audio in tensor [num_channels,length]\n",
    "            sample_rate: audio sampling rate\n",
    "            duration_seconds: audio duration in seconds\n",
    "        \"\"\"\n",
    "        # Get the audio start time corresponding to index\n",
    "        clip_start_time=self.labels_df['clip_start_time'].iloc[index]\n",
    "\n",
    "        #define clip length\n",
    "        segment_duration = 5 * sample_rate\n",
    "\n",
    "        # Total number of samples in the waveform\n",
    "        total_samples = audio.shape[1]\n",
    "\n",
    "        if clip_start_time<=duration_seconds:\n",
    "            clip_start_point=clip_start_time*sample_rate\n",
    "            # For the last clip, the original audio may not be long enough, so we need to use a mask to fill the sequence\n",
    "            # The first step is to confirm whether the length is sufficient\n",
    "            # The length is sufficient, no mask is needed\n",
    "            if clip_start_point+segment_duration<=total_samples:\n",
    "                clip=audio[:, clip_start_point:clip_start_point + segment_duration]\n",
    "\n",
    "            # Not long enough, a mask is needed\n",
    "            else:\n",
    "                padding_length = clip_start_point+segment_duration - total_samples\n",
    "                silence = torch.zeros(audio.shape[0], padding_length)\n",
    "                # concat the last segment of raw audio with silence\n",
    "                clip=torch.cat((audio[:,clip_start_point:],silence),dim=1)\n",
    "\n",
    "            # Calculate mean and standard deviation\n",
    "            mean_vals = clip.mean(dim=1, keepdim=True)\n",
    "            std_vals = clip.std(dim=1, keepdim=True)\n",
    "\n",
    "            # Standardization\n",
    "            standardized_clip = (clip - mean_vals) / std_vals\n",
    "\n",
    "                \n",
    "        else:\n",
    "            raise ValueError('The clip start time is out of raw audio length')\n",
    "        \n",
    "\n",
    "\n",
    "        return standardized_clip\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        #  return the size of the dataset by many Sampler implementations and the default options of DataLoader.\n",
    "    \n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # a_list[1] -> a_list.__getitems__(1)\n",
    "        # Get the path of a single audio file\n",
    "        single_audio_dir=self.get_audio_path(index)\n",
    "        # Get the corresponding label value\n",
    "        audio_label=self.encoder.transform([self.get_audio_label(index)])[0]\n",
    "\n",
    "        # Read the audio array according to the path\n",
    "        audio, sr=read_audio(single_audio_dir)\n",
    "        \n",
    "        # Read the duration and number of channels corresponding to the audio\n",
    "        duration_seconds, num_channels=audio_info(audio,sample_rate=sr)\n",
    "\n",
    "        # Get the audio clip corresponding to index\n",
    "        clip=self.target_clip(index,audio,sample_rate=sr, duration_seconds=duration_seconds)\n",
    "\n",
    "        # mel spectrogram transformation\n",
    "        mel_spec=mel_transform(sample_rate=sr,audio=clip)\n",
    "\n",
    "        return audio_label, mel_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 47, 134,  72,  45,  52,   1,  30,  31,  55, 125, 119,   7,  70,   0,\n",
      "        126,   1, 127,  16,  92,  49, 149, 126,   7,  80,   7,  72,  21,  70,\n",
      "         51,  73,  92,  34,  14,  13, 159, 126, 147, 104, 124,   0,  87, 122,\n",
      "         52, 126,  41,   7,  15,   8,   8,  94,  16,  34,  46,  38,  60,  16,\n",
      "         16,  72, 154, 119,  34, 158,  72,  10,  38,  10, 148,  36,  61,  94,\n",
      "        125,  27,  34,  47, 126,  32,  67,  47,  45,   7,  11,  60,   8,  66,\n",
      "         61,  96,  11,  13,  10, 137,  67,  20,  70,  61,  72,  78, 146, 123,\n",
      "         34,  16,   2,  16,  36,  72,  45, 128,  70, 137,  47,   7,  30,  15,\n",
      "         43,  16,  45,  73,   7,  12,  16,  92,  36,  36, 100,  89,  20,  36,\n",
      "        150, 113])\n",
      "tensor([[[[2.2131e+01, 3.2052e+00, 2.1518e+00,  ..., 6.9497e-01,\n",
      "           2.4243e+00, 7.2464e+00],\n",
      "          [3.6364e+01, 2.7217e+01, 5.2286e+01,  ..., 5.4511e+00,\n",
      "           9.3516e+00, 1.8424e+01],\n",
      "          [7.4918e+01, 5.9747e+01, 1.2876e+02,  ..., 1.5926e+01,\n",
      "           1.6743e+02, 8.6694e+01],\n",
      "          ...,\n",
      "          [1.0224e+02, 1.0881e+02, 8.5824e+01,  ..., 9.0021e+01,\n",
      "           6.6951e+01, 8.8360e+01],\n",
      "          [7.3218e+01, 1.0460e+02, 7.5978e+01,  ..., 8.7710e+01,\n",
      "           5.5959e+01, 1.2929e+02],\n",
      "          [5.1397e+01, 5.0154e+01, 6.9320e+01,  ..., 7.9224e+01,\n",
      "           5.7787e+01, 7.3213e+01]]],\n",
      "\n",
      "\n",
      "        [[[1.0923e+03, 1.1688e+03, 3.1072e+02,  ..., 2.1621e+02,\n",
      "           3.5830e+02, 2.6463e+02],\n",
      "          [4.7239e+03, 5.9452e+03, 1.5869e+03,  ..., 5.2341e+02,\n",
      "           3.8451e+02, 1.1740e+02],\n",
      "          [8.1122e+03, 3.0469e+03, 2.3877e+03,  ..., 1.8573e+03,\n",
      "           3.5395e+03, 7.9001e+02],\n",
      "          ...,\n",
      "          [3.8904e+01, 4.5195e+01, 3.8844e+01,  ..., 4.1754e+01,\n",
      "           3.4735e+01, 4.1731e+01],\n",
      "          [3.8120e+01, 5.0623e+01, 4.1164e+01,  ..., 5.6093e+01,\n",
      "           3.4875e+01, 4.9310e+01],\n",
      "          [1.6389e+01, 3.0528e+01, 3.4164e+01,  ..., 4.1196e+01,\n",
      "           3.9511e+01, 4.6804e+01]]],\n",
      "\n",
      "\n",
      "        [[[1.7715e+03, 4.9856e+03, 6.5914e+02,  ..., 1.4812e+03,\n",
      "           4.4651e+03, 1.6380e+03],\n",
      "          [4.9093e+02, 5.4974e+03, 1.7247e+03,  ..., 6.3158e+03,\n",
      "           2.8066e+03, 9.9404e+02],\n",
      "          [2.7921e+03, 9.6069e+03, 4.5027e+03,  ..., 1.0722e+04,\n",
      "           4.8295e+03, 4.1150e+03],\n",
      "          ...,\n",
      "          [1.4431e+02, 5.0297e+01, 4.8645e+01,  ..., 1.6329e+02,\n",
      "           1.0247e+02, 6.2705e+01],\n",
      "          [1.0330e+02, 6.5767e+01, 5.7140e+01,  ..., 8.3681e+01,\n",
      "           7.7451e+01, 5.7437e+01],\n",
      "          [1.4858e+02, 3.4609e+01, 3.4779e+01,  ..., 4.3679e+01,\n",
      "           5.7788e+01, 8.8979e+01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1.3517e-02, 5.9908e-03, 8.4303e-03,  ..., 7.4013e-03,\n",
      "           3.2581e-03, 2.2066e-03],\n",
      "          [3.5520e-02, 9.5060e-03, 5.4948e-02,  ..., 5.7718e-02,\n",
      "           6.0800e-02, 1.1833e-02],\n",
      "          [3.4395e-02, 1.1753e-02, 5.3322e-02,  ..., 8.4867e-02,\n",
      "           2.8875e-02, 8.4616e-03],\n",
      "          ...,\n",
      "          [1.0047e-01, 1.2789e-01, 1.0942e-01,  ..., 1.0140e-01,\n",
      "           9.9047e-02, 7.6188e-02],\n",
      "          [1.3072e-01, 1.3350e-01, 1.2851e-01,  ..., 1.4837e-01,\n",
      "           1.3351e-01, 9.1077e-02],\n",
      "          [7.9936e-02, 6.7246e-02, 8.1247e-02,  ..., 1.0807e-01,\n",
      "           6.6217e-02, 8.9870e-02]]],\n",
      "\n",
      "\n",
      "        [[[8.3611e+04, 5.9699e+04, 4.0452e+04,  ..., 7.9867e+00,\n",
      "           7.9867e+00, 7.9867e+00],\n",
      "          [7.3229e+03, 2.9993e+04, 1.6590e+04,  ..., 2.7073e-15,\n",
      "           2.7073e-15, 2.7073e-15],\n",
      "          [1.0018e+04, 2.7593e+03, 2.9095e+03,  ..., 3.3576e-15,\n",
      "           3.3576e-15, 3.3576e-15],\n",
      "          ...,\n",
      "          [3.8038e+01, 3.5175e+01, 3.4536e+01,  ..., 4.9080e-14,\n",
      "           4.9080e-14, 4.9080e-14],\n",
      "          [2.9496e+01, 3.0260e+01, 2.4392e+01,  ..., 2.5010e-14,\n",
      "           2.5010e-14, 2.5010e-14],\n",
      "          [1.5058e+01, 2.0731e+01, 1.4726e+01,  ..., 1.8357e-14,\n",
      "           1.8357e-14, 1.8357e-14]]],\n",
      "\n",
      "\n",
      "        [[[4.1919e+02, 3.2004e-04, 4.1899e-04,  ..., 4.4770e-04,\n",
      "           3.2567e-04, 1.3164e+00],\n",
      "          [4.6410e+02, 7.8183e-03, 6.5186e-03,  ..., 1.5173e-02,\n",
      "           7.5679e-02, 1.8470e+00],\n",
      "          [5.3195e+02, 1.8299e-01, 1.4502e-01,  ..., 7.5341e-02,\n",
      "           3.7334e-01, 2.1062e+00],\n",
      "          ...,\n",
      "          [1.8317e+03, 1.1793e+03, 1.9574e+03,  ..., 1.6279e+03,\n",
      "           1.4007e+03, 2.2568e+03],\n",
      "          [1.3184e+03, 1.4398e+03, 1.9208e+03,  ..., 1.1171e+03,\n",
      "           1.5009e+03, 8.9448e+02],\n",
      "          [5.3260e+02, 1.0020e+03, 7.2433e+02,  ..., 5.7114e+02,\n",
      "           1.0502e+03, 1.4393e+03]]]])\n",
      "torch.Size([128, 1, 40, 251])\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "BD=BirdclefDataset(encoder=encoder,labels_path=labels_path)\n",
    "\n",
    "dataloader = DataLoader(dataset=BD, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "labels, mel_specs = batch\n",
    "print(labels)\n",
    "print(mel_specs)\n",
    "print(mel_specs.shape)\n",
    "print(len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=1,out_channels=32,kernel_size=(2,2),stride=2,padding=0)\n",
    "        self.conv2=nn.Conv2d(in_channels=1,out_channels=32,kernel_size=(4,4),stride=2,padding=1)\n",
    "        self.conv3=nn.Conv2d(in_channels=1,out_channels=32,kernel_size=(8,8),stride=2,padding=3)\n",
    "    def forward(self,x):\n",
    "        x1=self.conv1(x)\n",
    "        x2=self.conv2(x)\n",
    "        x3=self.conv3(x)\n",
    "        # The length of the input data shape is 32000, and the stride is 2, so after conv1d, the length becomes 16000\n",
    "        # The number of output channels of each conv1d layer is 32, so for the shape of the entire output, regardless of batchsize, it is 32*16000\n",
    "        # Because of the chrononet architecture, we need to connect the outputs of the three layers to become 96*16000 output data.\n",
    "        x=torch.cat((x1,x2,x3),dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 96, 20, 125])\n",
      "tensor([[[[ 9.5496e+00,  1.1246e+01,  5.3699e+00,  ...,  4.1395e+00,\n",
      "            2.5180e+00,  1.5766e+00],\n",
      "          [ 6.6051e+01,  7.6504e+00,  3.6524e+01,  ...,  2.9806e+01,\n",
      "            4.5469e+01,  1.3541e+01],\n",
      "          [ 2.8718e+01, -8.4494e+00, -6.9029e+01,  ...,  6.6813e+01,\n",
      "           -4.9247e+00, -3.7171e+01],\n",
      "          ...,\n",
      "          [-2.4250e+00, -2.0166e+00, -6.0259e+00,  ..., -2.1248e-01,\n",
      "           -1.1884e+01, -7.1522e+00],\n",
      "          [-2.7115e+00, -1.3597e+01, -1.2595e+00,  ..., -1.1967e+01,\n",
      "           -1.8934e+01, -6.2785e+00],\n",
      "          [-2.8084e+01, -1.3915e+01, -1.2219e+01,  ..., -1.0935e+01,\n",
      "           -9.3906e+00, -1.3192e+00]],\n",
      "\n",
      "         [[-2.7752e+01, -2.8979e+01, -1.3609e+01,  ..., -1.0738e+01,\n",
      "           -6.8813e+00, -6.5438e+00],\n",
      "          [-2.2020e+02, -8.3683e+01, -1.1905e+02,  ..., -1.1551e+02,\n",
      "           -1.2815e+02, -1.9631e+02],\n",
      "          [-3.2874e+02, -3.0995e+02, -3.2455e+02,  ..., -3.6275e+02,\n",
      "           -3.7750e+02, -1.7218e+02],\n",
      "          ...,\n",
      "          [-7.6925e+01, -8.0941e+01, -7.4581e+01,  ..., -7.9282e+01,\n",
      "           -6.8947e+01, -5.9206e+01],\n",
      "          [-1.0859e+02, -9.3792e+01, -9.7289e+01,  ..., -7.0147e+01,\n",
      "           -8.5562e+01, -8.2421e+01],\n",
      "          [-6.5218e+01, -7.8705e+01, -7.3472e+01,  ..., -8.2555e+01,\n",
      "           -7.1064e+01, -7.1233e+01]],\n",
      "\n",
      "         [[-5.1153e+00,  6.4717e+00, -5.2932e-01,  ...,  8.7270e-01,\n",
      "           -1.0447e-01,  9.4253e-01],\n",
      "          [ 1.0671e+01, -4.1386e+01, -4.4227e+00,  ...,  1.2485e+01,\n",
      "            7.3121e+00,  3.4104e+01],\n",
      "          [-7.7930e+01,  7.3029e+00,  1.7685e+01,  ..., -1.2258e+02,\n",
      "            3.0151e+01,  2.4428e+01],\n",
      "          ...,\n",
      "          [-4.4010e+00, -1.1991e+01, -7.3241e+00,  ..., -2.8177e+00,\n",
      "            1.4071e+00, -1.8986e+00],\n",
      "          [-1.4011e+00, -1.5139e+01, -3.0901e+00,  ..., -9.5973e+00,\n",
      "           -5.1649e+00, -2.9949e+00],\n",
      "          [-2.2746e+00, -5.7700e+00, -1.9990e+01,  ..., -9.2073e+00,\n",
      "           -1.8962e+01, -1.7473e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.8816e+01, -1.0456e+02, -1.4520e+02,  ..., -1.2927e+02,\n",
      "           -1.1361e+02, -3.5146e+01],\n",
      "          [-1.3690e+02, -2.4786e+02, -2.9418e+02,  ..., -2.5754e+02,\n",
      "           -3.0332e+02, -2.4503e+02],\n",
      "          [-3.8742e+02, -3.8215e+02, -9.7427e+02,  ..., -9.0161e+02,\n",
      "           -2.5493e+02, -3.7786e+02],\n",
      "          ...,\n",
      "          [-3.5765e+01, -6.6195e+01, -6.6130e+01,  ..., -7.5998e+01,\n",
      "           -6.4097e+01, -4.6468e+01],\n",
      "          [-1.2277e+00, -2.7871e+01, -5.0518e+01,  ..., -3.8045e+01,\n",
      "           -4.2356e+01, -5.2737e+01],\n",
      "          [ 1.2837e+01,  1.1724e+01, -1.5038e+01,  ..., -1.1170e+01,\n",
      "           -7.9655e+00, -1.1387e+01]],\n",
      "\n",
      "         [[-6.5117e+01, -7.5816e+01, -1.0116e+02,  ..., -8.0767e+01,\n",
      "           -1.2874e+02, -5.9506e+01],\n",
      "          [-4.6346e+01, -1.5053e+02, -6.2614e+01,  ..., -1.0090e+02,\n",
      "           -1.8720e+02, -1.9136e+02],\n",
      "          [-1.0841e+03, -1.4449e+03, -1.5251e+03,  ..., -6.6541e+02,\n",
      "           -6.3640e+02, -1.2001e+03],\n",
      "          ...,\n",
      "          [ 2.8972e+00,  4.2063e+00,  8.0879e+00,  ...,  1.1925e+01,\n",
      "            1.6543e+01,  1.5276e+01],\n",
      "          [ 2.4956e+01,  2.1533e+01,  4.6982e+01,  ...,  4.6167e+01,\n",
      "            4.0120e+01,  4.6154e+01],\n",
      "          [ 4.0932e+01,  5.1240e+01,  6.0347e+01,  ...,  5.4571e+01,\n",
      "            4.6349e+01,  3.8137e+01]],\n",
      "\n",
      "         [[-2.5009e+01,  2.7990e+01,  1.1264e+02,  ...,  2.0443e+01,\n",
      "            4.0478e+01,  3.1623e+01],\n",
      "          [-1.0940e+02,  1.1635e+02, -1.4406e+01,  ...,  6.6383e+01,\n",
      "            5.5869e+01,  5.5545e+01],\n",
      "          [ 1.5472e+02,  1.2467e+02,  1.9660e+02,  ...,  1.1971e+02,\n",
      "           -3.5151e+02, -2.2737e+02],\n",
      "          ...,\n",
      "          [-3.2876e+01,  8.1017e+00, -1.0147e+01,  ..., -1.1249e+00,\n",
      "            4.7134e+00, -1.7348e+01],\n",
      "          [-4.6080e+01, -2.4556e+01, -2.9224e+01,  ..., -3.2576e+01,\n",
      "           -2.8327e+01, -5.0059e+01],\n",
      "          [-5.1009e+00,  9.4827e+00,  8.9357e-01,  ..., -2.4091e+00,\n",
      "            7.9280e+00, -2.1916e+01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6028e+03, -8.3826e+02,  1.5949e+05,  ...,  5.2787e+02,\n",
      "            1.8945e+02,  7.1127e+00],\n",
      "          [ 1.9574e+03,  2.0569e+03, -9.4205e+03,  ..., -1.5098e+02,\n",
      "           -3.4750e+01,  1.3824e+03],\n",
      "          [-1.6916e+02, -7.3070e+02, -2.4599e+03,  ..., -1.9831e+03,\n",
      "           -4.0111e+02, -1.7050e+03],\n",
      "          ...,\n",
      "          [-3.6004e+00, -6.2812e-01, -2.9380e+00,  ..., -6.5584e+00,\n",
      "           -9.5283e+00, -1.3327e+01],\n",
      "          [-6.1150e+00,  1.6649e+00,  1.2581e+00,  ..., -2.4173e+00,\n",
      "           -2.3797e-01, -4.0797e+00],\n",
      "          [-1.3513e+01, -1.1848e+01, -8.7655e+00,  ..., -1.1066e+01,\n",
      "           -1.5310e+01, -1.2967e+00]],\n",
      "\n",
      "         [[-4.6494e+03, -2.3491e+03, -7.9696e+05,  ..., -1.0776e+03,\n",
      "           -6.2097e+02, -4.5042e+02],\n",
      "          [-9.2360e+03, -8.2112e+03, -7.1346e+04,  ..., -5.0823e+03,\n",
      "           -3.6096e+03, -7.2696e+03],\n",
      "          [-9.6827e+03, -2.7976e+03, -7.7250e+03,  ..., -3.2402e+03,\n",
      "           -2.7554e+03, -3.1534e+03],\n",
      "          ...,\n",
      "          [-5.5006e+01, -5.5431e+01, -4.2852e+01,  ..., -5.0397e+01,\n",
      "           -4.5323e+01, -5.3288e+01],\n",
      "          [-4.6811e+01, -4.6093e+01, -5.0081e+01,  ..., -4.8718e+01,\n",
      "           -5.5271e+01, -4.0744e+01],\n",
      "          [-3.0827e+01, -4.0114e+01, -2.7300e+01,  ..., -3.6972e+01,\n",
      "           -4.0068e+01, -4.2581e+01]],\n",
      "\n",
      "         [[ 1.6314e+02,  9.0960e+02, -9.7607e+04,  ..., -3.9885e+01,\n",
      "            7.9850e+00,  4.8494e+01],\n",
      "          [-1.1381e+03,  1.4415e+03, -1.2041e+05,  ...,  6.0791e+02,\n",
      "            3.4927e+02,  1.0225e+03],\n",
      "          [-1.1432e+04, -1.8531e+03,  2.2828e+03,  ...,  1.4335e+03,\n",
      "            6.2562e+02,  1.1329e+03],\n",
      "          ...,\n",
      "          [ 6.3855e+00, -1.6117e+01, -4.8898e+00,  ..., -4.3549e+00,\n",
      "           -3.1967e+00, -2.3925e+00],\n",
      "          [-1.3016e+01, -5.9233e+00, -2.1660e+00,  ..., -7.7141e+00,\n",
      "           -1.8180e+01, -2.6179e+00],\n",
      "          [-3.8516e+00, -1.8156e+00, -7.7625e+00,  ..., -7.4313e+00,\n",
      "           -5.2287e+00, -1.2895e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5674e+05, -1.4088e+05,  7.3728e+04,  ..., -1.5908e+03,\n",
      "           -1.7343e+03, -1.2295e+03],\n",
      "          [ 1.1531e+05, -2.1672e+03, -5.5569e+04,  ..., -2.6102e+03,\n",
      "           -3.8712e+03, -1.3101e+03],\n",
      "          [-5.0721e+04,  5.3911e+04, -9.0406e+04,  ..., -4.9464e+03,\n",
      "           -3.7953e+03, -2.7076e+03],\n",
      "          ...,\n",
      "          [-9.5429e+00, -3.1492e+01, -4.1073e+01,  ..., -3.9706e+01,\n",
      "           -3.5002e+01, -3.8947e+01],\n",
      "          [-8.1839e+00, -1.8790e+01, -3.0890e+01,  ..., -3.5290e+01,\n",
      "           -2.8950e+01, -2.8705e+01],\n",
      "          [ 2.7110e+00,  3.8492e+00, -7.4121e+00,  ..., -4.7145e+00,\n",
      "           -3.5610e+00, -1.3853e+01]],\n",
      "\n",
      "         [[-7.6329e+04,  2.6286e+04, -4.6941e+04,  ..., -2.3501e+03,\n",
      "           -1.4323e+03, -1.9026e+03],\n",
      "          [ 1.0209e+05,  9.9996e+04,  1.7291e+05,  ..., -5.9796e+02,\n",
      "           -1.6018e+03, -1.2469e+03],\n",
      "          [-7.4758e+03, -4.5042e+04,  8.1947e+04,  ...,  2.0298e+03,\n",
      "            4.6879e+03,  2.9649e+03],\n",
      "          ...,\n",
      "          [ 1.1149e+01,  4.2289e+00,  1.4353e+01,  ...,  2.2349e+01,\n",
      "            1.8550e+01,  1.5476e+01],\n",
      "          [ 1.5993e+01,  2.2557e+01,  2.2371e+01,  ...,  3.0781e+01,\n",
      "            3.3171e+01,  2.6560e+01],\n",
      "          [ 2.2934e+01,  2.4963e+01,  3.7254e+01,  ...,  3.6262e+01,\n",
      "            3.1389e+01,  1.6560e+01]],\n",
      "\n",
      "         [[-7.1044e+04, -1.7478e+05, -1.1470e+05,  ..., -4.0334e+02,\n",
      "           -6.9823e+02, -7.9377e+02],\n",
      "          [ 2.3340e+05, -5.3544e+04,  9.1647e+04,  ..., -8.4554e+02,\n",
      "           -4.0843e+01, -1.5311e+02],\n",
      "          [ 1.8657e+05, -1.4042e+05, -8.5776e+04,  ..., -1.1783e+03,\n",
      "           -2.4572e+03, -1.5789e+03],\n",
      "          ...,\n",
      "          [-2.4592e+01,  6.4209e+00, -2.0927e+00,  ..., -1.7584e+01,\n",
      "            3.8325e+00, -1.8468e+01],\n",
      "          [-3.0598e+01, -3.5279e+00, -1.7786e+01,  ..., -1.7083e+01,\n",
      "           -1.1588e+01, -3.2343e+01],\n",
      "          [-7.0712e+00, -6.1617e+00,  3.2651e+00,  ...,  2.0908e-01,\n",
      "           -5.0092e+00, -2.0606e+01]]],\n",
      "\n",
      "\n",
      "        [[[-7.8625e+02,  1.2605e+03,  1.1108e+03,  ..., -9.1305e+01,\n",
      "            6.7712e+02, -4.0196e+02],\n",
      "          [-1.0257e+03, -3.8854e+03, -1.1948e+03,  ..., -2.0155e+02,\n",
      "           -1.8532e+01, -4.3747e+01],\n",
      "          [-1.7985e+02, -4.1040e+02, -8.4350e+02,  ..., -3.8156e+02,\n",
      "           -6.2745e+02, -7.8393e+01],\n",
      "          ...,\n",
      "          [ 2.5076e+00, -1.2044e+01, -5.6578e+01,  ..., -3.5463e+01,\n",
      "           -4.3756e+02,  1.8930e+03],\n",
      "          [ 5.6297e+00, -1.0613e+01, -3.6897e+00,  ..., -1.8751e+01,\n",
      "           -7.7364e+01, -6.1190e+02],\n",
      "          [-1.9518e+00, -7.5829e+00, -2.1459e+01,  ..., -1.6410e+01,\n",
      "           -3.6362e+01, -1.5623e+01]],\n",
      "\n",
      "         [[-3.5038e+03, -5.6319e+03, -4.4249e+03,  ..., -2.3415e+03,\n",
      "           -3.6881e+03, -4.6464e+03],\n",
      "          [-8.1801e+03, -6.0862e+03, -5.0266e+03,  ..., -4.2332e+03,\n",
      "           -4.4357e+03, -5.8234e+03],\n",
      "          [-2.1567e+02, -3.5554e+02, -6.0974e+02,  ..., -1.9622e+02,\n",
      "           -3.1043e+02, -8.1756e+01],\n",
      "          ...,\n",
      "          [-2.8364e+02, -1.1169e+02, -1.1241e+02,  ..., -1.3120e+02,\n",
      "           -1.4928e+03, -5.9571e+03],\n",
      "          [-1.0123e+02, -5.6694e+01, -7.4870e+01,  ..., -8.5344e+01,\n",
      "           -2.8971e+02, -6.1205e+02],\n",
      "          [-9.2529e+01, -3.9760e+01, -4.2883e+01,  ..., -3.3514e+01,\n",
      "           -9.2488e+01, -6.0649e+01]],\n",
      "\n",
      "         [[ 1.8355e+02,  2.2115e+02, -1.2626e+01,  ..., -1.1735e+03,\n",
      "            3.1994e+02,  1.2519e+03],\n",
      "          [ 1.2611e+03,  2.0223e+03,  2.4905e+02,  ..., -2.6111e+03,\n",
      "           -3.6646e+03, -3.7537e+03],\n",
      "          [-2.1831e+02, -8.8069e+02, -1.3913e+03,  ...,  9.5200e+01,\n",
      "            9.2471e+01, -2.5490e+02],\n",
      "          ...,\n",
      "          [-1.9956e+02, -1.5285e+01,  2.4893e+01,  ..., -3.6766e-01,\n",
      "           -4.7410e+01,  7.7902e+02],\n",
      "          [-7.7540e+01, -5.2696e+00, -2.3293e+00,  ...,  3.5219e+00,\n",
      "           -2.5142e+01, -1.9725e+03],\n",
      "          [-1.0098e+01, -1.1689e+01, -6.0490e+00,  ..., -1.6254e+00,\n",
      "           -1.5331e+01, -1.5671e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2714e+03, -3.8932e+03, -2.6410e+03,  ..., -2.8458e+03,\n",
      "           -2.3144e+03, -8.9806e+02],\n",
      "          [ 2.2553e+02,  1.7365e+03, -1.5073e+03,  ...,  1.0767e+02,\n",
      "           -1.0813e+03, -1.0355e+03],\n",
      "          [ 1.0285e+03, -8.7513e+02, -3.3598e+03,  ..., -1.3069e+03,\n",
      "           -1.8228e+03, -1.3062e+03],\n",
      "          ...,\n",
      "          [-9.1382e+01, -9.9186e+01, -8.3544e+01,  ...,  3.1946e+02,\n",
      "           -2.2091e+03, -5.6141e+02],\n",
      "          [-5.0373e+01, -7.5287e+01, -1.0744e+02,  ...,  8.6863e+02,\n",
      "           -6.7875e+01, -4.4081e+02],\n",
      "          [-3.1297e+00, -1.4491e+01, -2.5778e+01,  ...,  9.8757e+01,\n",
      "            6.5810e+02, -6.7102e+02]],\n",
      "\n",
      "         [[-1.0650e+03, -1.7955e+03,  3.3519e+02,  ..., -1.9771e+02,\n",
      "            7.2757e+02,  1.5937e+03],\n",
      "          [ 3.0350e+03,  2.2437e+03,  5.1333e+03,  ...,  1.8132e+03,\n",
      "            1.9740e+03,  8.6022e+02],\n",
      "          [ 1.8412e+03,  4.3007e+03,  2.8506e+03,  ...,  1.3308e+03,\n",
      "            1.6169e+03,  4.8021e+02],\n",
      "          ...,\n",
      "          [ 1.7417e+02,  7.8715e+01,  6.4218e+01,  ..., -2.9741e+00,\n",
      "            1.0387e+03,  1.0401e+03],\n",
      "          [ 1.0187e+02,  9.3377e+01,  8.6958e+01,  ...,  6.3216e+02,\n",
      "            1.9649e+03,  8.9054e+02],\n",
      "          [ 5.1391e+01,  6.6369e+01,  5.6951e+01,  ..., -1.6345e+02,\n",
      "           -5.3557e+02,  9.5074e+02]],\n",
      "\n",
      "         [[-3.8417e+03, -1.1332e+03, -2.0037e+03,  ..., -3.0936e+03,\n",
      "           -1.9841e+03, -1.0116e+03],\n",
      "          [-8.9405e+02, -9.6871e+02,  1.3127e+03,  ...,  2.5118e+02,\n",
      "           -8.7803e+02, -8.8062e+02],\n",
      "          [ 1.9946e+03,  1.2645e+03,  8.0120e+01,  ...,  1.5069e+03,\n",
      "           -8.3178e+02, -3.0856e+03],\n",
      "          ...,\n",
      "          [-1.3463e+01, -1.1986e+02, -2.9337e+01,  ..., -1.3812e+03,\n",
      "           -2.2864e+03, -1.5545e+03],\n",
      "          [-6.2324e+01, -1.0971e+02, -1.0162e+01,  ...,  1.2749e+03,\n",
      "            2.5857e+02, -1.0717e+03],\n",
      "          [-1.4665e+01, -5.5878e+01, -1.1942e+01,  ...,  1.3333e+03,\n",
      "           -9.2345e+02, -3.8215e+02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.2857e-01, -4.2336e-01, -4.3010e-01,  ..., -4.2176e-01,\n",
      "           -4.1872e-01, -4.1141e-01],\n",
      "          [-3.9700e-01, -2.6604e-01, -2.9723e-01,  ..., -1.8494e-01,\n",
      "           -6.3400e-02, -2.4705e-01],\n",
      "          [-1.9990e-01, -6.5379e-01, -3.9365e-01,  ..., -8.7881e-01,\n",
      "           -1.1782e+00, -9.6564e-01],\n",
      "          ...,\n",
      "          [-4.3807e-01, -4.2859e-01, -4.2716e-01,  ..., -4.4176e-01,\n",
      "           -4.4063e-01, -4.3149e-01],\n",
      "          [-4.3413e-01, -4.3876e-01, -4.3783e-01,  ..., -4.3017e-01,\n",
      "           -4.2944e-01, -4.4354e-01],\n",
      "          [-4.6627e-01, -4.5046e-01, -4.4500e-01,  ..., -4.4672e-01,\n",
      "           -4.6236e-01, -4.6296e-01]],\n",
      "\n",
      "         [[ 2.0284e-03, -2.0473e-02,  1.4075e-02,  ..., -8.3471e-03,\n",
      "           -6.9913e-03, -2.7298e-02],\n",
      "          [-8.6801e-02, -3.3859e-01, -3.5715e-01,  ..., -6.2680e-01,\n",
      "           -9.5284e-01, -4.3987e-01],\n",
      "          [-5.3569e-01, -1.0809e+00, -5.0121e-01,  ..., -7.3823e-01,\n",
      "           -7.2911e-01, -6.6025e-01],\n",
      "          ...,\n",
      "          [-8.0952e-02, -7.7457e-02, -9.0796e-02,  ..., -5.6418e-02,\n",
      "           -7.8748e-02, -9.2129e-02],\n",
      "          [-9.5334e-02, -8.6175e-02, -1.0440e-01,  ..., -8.6697e-02,\n",
      "           -1.1688e-01, -8.4477e-02],\n",
      "          [-7.0175e-02, -7.8408e-02, -7.8146e-02,  ..., -6.9668e-02,\n",
      "           -7.9765e-02, -8.2116e-02]],\n",
      "\n",
      "         [[ 3.6925e-01,  3.7581e-01,  3.6722e-01,  ...,  3.7178e-01,\n",
      "            3.7023e-01,  3.7177e-01],\n",
      "          [ 3.8460e-01,  3.4054e-01,  4.4717e-01,  ...,  3.8596e-01,\n",
      "            5.3215e-01,  4.1855e-01],\n",
      "          [ 3.0037e-01,  5.6577e-01,  2.7984e-01,  ...,  1.4208e-01,\n",
      "           -8.4092e-02,  4.6796e-01],\n",
      "          ...,\n",
      "          [ 3.5396e-01,  3.5764e-01,  3.4377e-01,  ...,  3.6018e-01,\n",
      "            3.5771e-01,  3.4484e-01],\n",
      "          [ 3.6386e-01,  3.5240e-01,  3.4027e-01,  ...,  3.5609e-01,\n",
      "            3.4520e-01,  3.7121e-01],\n",
      "          [ 3.5040e-01,  3.4495e-01,  3.5160e-01,  ...,  3.4946e-01,\n",
      "            3.5920e-01,  3.4662e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5414e-02,  3.5519e-02, -1.5276e-01,  ..., -1.5798e-01,\n",
      "           -4.2180e-01, -2.1469e-01],\n",
      "          [-3.2079e-02, -4.6260e-01, -2.6586e-01,  ..., -1.0351e+00,\n",
      "           -7.0991e-01, -1.9663e-01],\n",
      "          [-2.4296e-01, -3.6855e-01, -6.3609e-01,  ...,  1.0143e-02,\n",
      "           -5.5575e-01, -3.0393e-01],\n",
      "          ...,\n",
      "          [ 6.1114e-02,  1.4556e-02, -5.0515e-03,  ...,  4.5058e-03,\n",
      "            7.1534e-03, -6.9710e-03],\n",
      "          [ 9.2688e-02,  6.2552e-02,  3.9059e-02,  ...,  2.9460e-02,\n",
      "            1.6566e-02,  3.3045e-02],\n",
      "          [ 1.1065e-01,  9.4981e-02,  7.5443e-02,  ...,  8.6486e-02,\n",
      "            8.2104e-02,  6.5072e-02]],\n",
      "\n",
      "         [[-7.0790e-02, -2.5859e-01, -2.5453e-01,  ..., -4.5088e-01,\n",
      "           -7.1782e-01, -7.0853e-01],\n",
      "          [-3.5925e-01, -2.2470e-01, -2.9017e-01,  ..., -1.2375e-01,\n",
      "           -1.0172e-01, -3.7916e-02],\n",
      "          [-3.8809e-01, -4.4347e-01, -3.3081e-01,  ...,  6.0140e-01,\n",
      "            2.4081e-01,  3.2005e-01],\n",
      "          ...,\n",
      "          [-1.9983e-02, -7.0225e-03,  1.3396e-02,  ...,  6.6171e-03,\n",
      "            1.7697e-03, -1.5383e-02],\n",
      "          [ 1.5704e-02,  1.3178e-02,  3.4743e-02,  ...,  1.2625e-02,\n",
      "            5.0310e-02,  5.2952e-02],\n",
      "          [ 2.0688e-02,  3.7372e-02,  5.0289e-02,  ...,  4.0660e-02,\n",
      "            5.1631e-02,  2.3634e-02]],\n",
      "\n",
      "         [[-9.9965e-02,  9.4537e-02,  2.2705e-01,  ...,  2.4130e-02,\n",
      "            2.1177e-01,  4.0657e-01],\n",
      "          [-3.0848e-01, -2.2658e-01,  1.4263e-01,  ..., -1.8040e-01,\n",
      "           -2.7214e-02,  8.4569e-02],\n",
      "          [-7.2831e-02,  3.2887e-02,  1.2570e-02,  ..., -2.1947e-01,\n",
      "           -1.6108e-01, -7.8365e-02],\n",
      "          ...,\n",
      "          [-1.8278e-02,  3.8765e-02,  2.1514e-02,  ...,  2.4801e-02,\n",
      "            1.9651e-02, -3.1923e-03],\n",
      "          [-6.1209e-03,  4.6303e-03, -2.3290e-03,  ...,  5.5617e-03,\n",
      "           -1.8535e-02, -3.3200e-02],\n",
      "          [ 1.9108e-02,  2.8411e-02,  3.5947e-02,  ...,  3.6431e-02,\n",
      "            2.0455e-02, -2.6312e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9423e+04, -7.5755e+03,  2.9058e+03,  ..., -4.0960e+00,\n",
      "           -4.0960e+00, -4.0960e+00],\n",
      "          [-1.0854e+03, -5.9930e+02, -1.2244e+01,  ..., -4.3301e-01,\n",
      "           -4.3301e-01, -4.3301e-01],\n",
      "          [ 6.0228e+01, -3.5684e+02, -1.3620e+03,  ..., -4.3301e-01,\n",
      "           -4.3301e-01, -4.3301e-01],\n",
      "          ...,\n",
      "          [ 2.8746e+00,  2.7894e-02,  1.8142e+00,  ..., -4.3301e-01,\n",
      "           -4.3301e-01, -4.3301e-01],\n",
      "          [-6.8998e+00, -1.7075e+00, -2.2090e+00,  ..., -4.3301e-01,\n",
      "           -4.3301e-01, -4.3301e-01],\n",
      "          [-7.0399e+00, -3.2212e+00, -6.6446e+00,  ..., -4.3301e-01,\n",
      "           -4.3301e-01, -4.3301e-01]],\n",
      "\n",
      "         [[-3.1078e+04, -1.6259e+04, -1.8038e+04,  ..., -1.9132e+00,\n",
      "           -1.9132e+00, -1.9132e+00],\n",
      "          [-1.7222e+03, -2.2501e+03, -2.6407e+03,  ...,  2.2227e-02,\n",
      "            2.2227e-02,  2.2227e-02],\n",
      "          [-4.8487e+03, -1.8996e+03, -3.7031e+03,  ...,  2.2227e-02,\n",
      "            2.2227e-02,  2.2227e-02],\n",
      "          ...,\n",
      "          [-5.9449e+01, -7.0086e+01, -5.8972e+01,  ...,  2.2227e-02,\n",
      "            2.2227e-02,  2.2227e-02],\n",
      "          [-4.0459e+01, -3.7486e+01, -2.9652e+01,  ...,  2.2227e-02,\n",
      "            2.2227e-02,  2.2227e-02],\n",
      "          [-2.1935e+01, -1.8284e+01, -2.1465e+01,  ...,  2.2227e-02,\n",
      "            2.2227e-02,  2.2227e-02]],\n",
      "\n",
      "         [[-2.4468e+04, -1.0463e+04, -9.8320e+03,  ..., -1.3263e+00,\n",
      "           -1.3263e+00, -1.3263e+00],\n",
      "          [-3.9229e+03, -4.3707e+02, -2.6096e+02,  ...,  3.6909e-01,\n",
      "            3.6909e-01,  3.6909e-01],\n",
      "          [ 1.8272e+03, -7.5357e+02, -1.1727e+03,  ...,  3.6909e-01,\n",
      "            3.6909e-01,  3.6909e-01],\n",
      "          ...,\n",
      "          [-4.1205e+00,  4.0438e+00, -4.6735e+00,  ...,  3.6909e-01,\n",
      "            3.6909e-01,  3.6909e-01],\n",
      "          [-1.8393e+00, -4.2380e+00, -3.1429e+00,  ...,  3.6909e-01,\n",
      "            3.6909e-01,  3.6909e-01],\n",
      "          [-4.6097e+00, -4.7197e+00, -1.3882e+00,  ...,  3.6909e-01,\n",
      "            3.6909e-01,  3.6909e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0625e+02, -2.4316e+03,  6.2005e+03,  ...,  1.2967e+00,\n",
      "            1.2967e+00,  3.7313e-01],\n",
      "          [-2.3530e+03, -1.2321e+03, -9.5090e+03,  ..., -1.1075e+00,\n",
      "           -1.1075e+00, -1.0314e+00],\n",
      "          [ 4.7122e+02, -2.6893e+03, -4.1200e+03,  ...,  9.3228e-02,\n",
      "            9.3228e-02,  9.3228e-02],\n",
      "          ...,\n",
      "          [-9.3841e+00, -1.8117e+01, -4.2107e+01,  ...,  9.3228e-02,\n",
      "            9.3228e-02,  9.3228e-02],\n",
      "          [-7.5783e-02, -1.6724e+01, -2.4858e+01,  ...,  9.3228e-02,\n",
      "            9.3228e-02,  9.3228e-02],\n",
      "          [ 1.5045e+00, -4.1634e+00, -1.4677e+01,  ...,  9.3228e-02,\n",
      "            9.3228e-02,  9.3228e-02]],\n",
      "\n",
      "         [[ 5.2848e+03, -5.4572e+03,  4.2704e+03,  ...,  1.5782e+00,\n",
      "            1.5782e+00,  1.3879e+00],\n",
      "          [ 3.9655e+03, -3.8621e+03,  5.4282e+03,  ..., -9.8173e-01,\n",
      "           -9.8173e-01, -1.5582e+00],\n",
      "          [ 2.1803e+03,  3.2009e+03,  4.4307e+03,  ..., -2.4251e-02,\n",
      "           -2.4251e-02, -2.4251e-02],\n",
      "          ...,\n",
      "          [ 4.3771e+00,  1.3668e+01,  1.9535e+01,  ..., -2.4251e-02,\n",
      "           -2.4251e-02, -2.4251e-02],\n",
      "          [ 2.6708e+01,  3.3632e+01,  3.4455e+01,  ..., -2.4251e-02,\n",
      "           -2.4251e-02, -2.4251e-02],\n",
      "          [ 1.5671e+01,  2.0834e+01,  3.0722e+01,  ..., -2.4251e-02,\n",
      "           -2.4251e-02, -2.4251e-02]],\n",
      "\n",
      "         [[-1.5826e+04,  1.8703e+03,  6.9586e+03,  ..., -4.6935e-02,\n",
      "           -4.6935e-02, -1.0131e+00],\n",
      "          [ 4.0397e+03, -2.9404e+03,  1.3777e+04,  ...,  8.9287e-01,\n",
      "            8.9287e-01, -8.8240e-01],\n",
      "          [ 2.5699e+03, -1.6066e+03, -3.7351e+03,  ...,  3.1251e-02,\n",
      "            3.1251e-02,  3.1251e-02],\n",
      "          ...,\n",
      "          [-2.8247e+01, -1.3870e+01, -2.2394e+01,  ...,  3.1251e-02,\n",
      "            3.1251e-02,  3.1251e-02],\n",
      "          [-1.3001e+01,  2.8024e+00, -4.9623e+00,  ...,  3.1251e-02,\n",
      "            3.1251e-02,  3.1251e-02],\n",
      "          [-5.5776e+00, -7.9432e+00, -6.4670e+00,  ...,  3.1251e-02,\n",
      "            3.1251e-02,  3.1251e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5804e+01, -4.3130e-01, -4.0299e-01,  ..., -4.1047e-01,\n",
      "           -4.2206e-01, -4.1226e-01],\n",
      "          [ 6.6724e+01,  3.7884e-01,  4.0919e-01,  ..., -1.1356e-01,\n",
      "           -3.5257e-02, -1.7408e-01],\n",
      "          [ 3.2604e+01,  1.5023e+01,  2.9435e+01,  ...,  1.3961e+01,\n",
      "            8.0633e+00,  1.1734e+01],\n",
      "          ...,\n",
      "          [-3.9871e+01, -5.7478e+01,  1.1913e+02,  ..., -1.2483e+01,\n",
      "            3.3703e+01,  6.2100e+01],\n",
      "          [-6.8988e+01,  4.5242e+00, -1.8536e+02,  ..., -9.1641e+01,\n",
      "           -1.2475e+02, -1.3437e+02],\n",
      "          [-3.3491e+02, -4.0697e+02, -1.9899e+02,  ..., -1.7345e+02,\n",
      "           -1.7853e+02, -3.4002e+02]],\n",
      "\n",
      "         [[-2.1074e+02,  1.7793e-02, -6.0277e-02,  ..., -1.6960e-02,\n",
      "           -8.2861e-03, -1.5227e-02],\n",
      "          [-2.5513e+02, -2.1525e+00, -1.7078e+00,  ..., -1.1079e+00,\n",
      "           -1.0892e+00, -7.8840e-01],\n",
      "          [-1.6092e+02, -5.4602e+01, -7.3666e+01,  ..., -3.7704e+01,\n",
      "           -2.7096e+01, -4.2612e+01],\n",
      "          ...,\n",
      "          [-1.0091e+03, -1.1739e+03, -1.1695e+03,  ..., -9.1413e+02,\n",
      "           -7.8132e+02, -8.6636e+02],\n",
      "          [-1.5737e+03, -1.7869e+03, -1.4571e+03,  ..., -1.2565e+03,\n",
      "           -1.3524e+03, -1.5931e+03],\n",
      "          [-9.7195e+02, -1.1696e+03, -1.5047e+03,  ..., -1.0765e+03,\n",
      "           -9.4512e+02, -1.0084e+03]],\n",
      "\n",
      "         [[-1.2274e+02,  3.6978e-01,  3.9546e-01,  ...,  3.6504e-01,\n",
      "            3.7946e-01,  3.6677e-01],\n",
      "          [-1.6081e+02,  8.5579e-01,  2.0518e-01,  ...,  3.4589e-01,\n",
      "            5.5391e-01,  3.6012e-01],\n",
      "          [-1.9942e+02,  7.5983e+00,  4.6109e+00,  ...,  3.5880e-01,\n",
      "            5.7018e-01,  7.6488e-01],\n",
      "          ...,\n",
      "          [ 3.9873e+01, -2.1504e+01, -4.6451e+01,  ...,  1.4862e+00,\n",
      "           -1.3317e+01, -1.6156e+02],\n",
      "          [-2.5463e+02,  1.0375e+01, -6.3335e+01,  ..., -1.2243e+02,\n",
      "           -1.3016e+02,  6.6474e+01],\n",
      "          [-2.2639e+02, -4.1901e+02, -1.6424e+02,  ..., -1.7463e+02,\n",
      "           -3.2284e+02, -1.1414e+02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.7149e+01, -1.9491e+01, -2.0550e+00,  ..., -2.8321e+00,\n",
      "           -3.2984e+00, -1.5399e+00],\n",
      "          [-1.0460e+02, -3.1717e+01, -9.6513e+01,  ..., -4.5941e+01,\n",
      "           -1.9438e+02, -2.1977e+00],\n",
      "          [-3.1375e+02, -4.5633e+02, -3.5230e+02,  ..., -2.2913e+02,\n",
      "           -5.1801e+02, -2.3170e+02],\n",
      "          ...,\n",
      "          [-3.4347e+02, -1.1575e+03, -1.2292e+03,  ..., -1.3770e+03,\n",
      "           -1.4018e+03, -9.4884e+02],\n",
      "          [-3.2735e+02, -2.6307e+02, -7.6077e+02,  ..., -4.2706e+02,\n",
      "           -4.5693e+02, -5.1465e+02],\n",
      "          [ 1.5079e+02, -1.9219e+01, -1.3772e+02,  ..., -6.5635e+01,\n",
      "           -1.7522e+02, -3.4299e+02]],\n",
      "\n",
      "         [[-5.5050e+01, -7.9844e+01, -2.9412e+00,  ..., -2.5494e+00,\n",
      "           -2.2559e+00, -3.6418e+00],\n",
      "          [ 7.9561e+01, -7.0005e+01, -9.7615e+01,  ..., -3.5069e+01,\n",
      "            2.3729e+01, -9.5665e+01],\n",
      "          [-1.3512e+02, -2.2236e+02, -2.5525e+02,  ..., -2.3454e+02,\n",
      "           -5.4842e+02, -2.9775e+02],\n",
      "          ...,\n",
      "          [ 1.1894e+02, -4.1454e+02, -7.6503e+01,  ...,  2.0202e+02,\n",
      "            1.4252e+02,  2.3706e+02],\n",
      "          [ 4.5174e+02,  4.8086e+02,  6.5271e+02,  ...,  6.8078e+02,\n",
      "            5.0724e+02,  6.4956e+02],\n",
      "          [ 8.0666e+02,  7.8857e+02,  8.8570e+02,  ...,  9.0872e+02,\n",
      "            9.7607e+02,  5.4235e+02]],\n",
      "\n",
      "         [[-2.1188e+01,  1.5381e+02,  3.3244e+00,  ...,  1.5121e+00,\n",
      "            6.2429e-01,  2.2542e+00],\n",
      "          [ 6.0777e+01,  1.4582e+02,  4.6481e+01,  ...,  2.0249e+01,\n",
      "            6.3521e+01,  9.4701e+01],\n",
      "          [ 6.5748e+01,  1.7750e+02, -3.6767e+01,  ...,  4.4999e+01,\n",
      "            1.3887e+02, -5.6789e+01],\n",
      "          ...,\n",
      "          [-5.7461e+02, -2.3151e+01, -1.1800e+02,  ..., -3.5114e+02,\n",
      "           -3.4428e+02, -4.9641e+02],\n",
      "          [-8.5171e+02, -4.4146e+02, -5.8947e+02,  ..., -4.5706e+02,\n",
      "           -3.5685e+02, -6.8491e+02],\n",
      "          [ 3.2164e+01,  1.7438e+01, -9.8180e+01,  ...,  8.3637e+01,\n",
      "            2.1957e+02, -6.2234e+02]]]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model =ConvBlock1()\n",
    "\n",
    "output_test_1=model(mel_specs)\n",
    "\n",
    "print(output_test_1.shape)\n",
    "print(output_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=96,out_channels=32,kernel_size=(2,2),stride=2,padding=0)\n",
    "        self.conv2=nn.Conv2d(in_channels=96,out_channels=32,kernel_size=(4,4),stride=2,padding=1)\n",
    "        self.conv3=nn.Conv2d(in_channels=96,out_channels=32,kernel_size=(8,8),stride=2,padding=3)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x1=self.conv1(x)\n",
    "        x2=self.conv2(x)\n",
    "        x3=self.conv3(x)\n",
    "        # From the output of ConvBlock1, we know that the input shape of convBlock2 is 96*16000\n",
    "        # After the calculation of this block, the output will become 96*8000\n",
    "        x=torch.cat((x1,x2,x3),dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 96, 10, 62])\n",
      "tensor([[[[ 3.9639e+01,  7.8152e+00,  3.3213e+01,  ...,  8.4826e+01,\n",
      "            5.7910e+01,  4.0655e+01],\n",
      "          [ 5.3729e+02,  7.6089e+02,  1.0988e+03,  ...,  4.6021e+02,\n",
      "            4.0823e+02,  5.1080e+02],\n",
      "          [-4.6800e+02, -6.8036e+01,  2.7977e+02,  ...,  1.4788e+02,\n",
      "           -1.9590e+02,  1.7623e+02],\n",
      "          ...,\n",
      "          [ 7.8117e+00,  1.3898e+01,  1.8326e+01,  ...,  1.3463e+01,\n",
      "            3.5881e+00,  2.2058e+00],\n",
      "          [ 2.8225e+01,  1.5488e+01,  2.2156e+01,  ...,  2.1408e+01,\n",
      "            5.3735e+00,  1.3720e+01],\n",
      "          [ 2.2280e+01,  2.2439e+01,  1.5581e+01,  ...,  1.6920e+01,\n",
      "            1.4210e+01,  1.8780e+01]],\n",
      "\n",
      "         [[ 4.3399e+01, -6.4069e+00,  5.5218e+01,  ...,  1.7421e+01,\n",
      "            2.6955e+00, -1.5655e+01],\n",
      "          [ 8.1665e+02,  5.1402e+02,  3.7353e+02,  ...,  6.0700e+02,\n",
      "            4.5032e+02,  3.2020e+02],\n",
      "          [ 1.0027e+02,  6.3871e+01, -3.7434e+02,  ..., -1.4297e+02,\n",
      "           -1.1242e+02,  2.2151e+02],\n",
      "          ...,\n",
      "          [ 2.1774e+01,  1.6161e+01,  5.0958e+00,  ...,  1.6414e+01,\n",
      "            5.2788e+00,  1.8321e+01],\n",
      "          [ 2.2522e+01,  2.1340e+01,  2.4791e+01,  ...,  1.8566e+01,\n",
      "            2.1117e+01,  2.2398e+01],\n",
      "          [ 2.7517e+01,  3.0770e+01,  2.8895e+01,  ...,  3.5966e+01,\n",
      "            2.8589e+01,  3.0578e+01]],\n",
      "\n",
      "         [[ 5.4199e-01,  1.5693e+01, -2.3215e+01,  ...,  1.1382e+01,\n",
      "           -1.6164e+01, -1.9291e+01],\n",
      "          [ 1.9847e+02,  3.0170e+00, -1.8173e+02,  ...,  6.5765e+01,\n",
      "           -1.1327e+02, -2.2527e+01],\n",
      "          [-1.1620e+03, -8.1098e+02, -6.5912e+02,  ..., -7.9834e+02,\n",
      "           -7.7679e+02, -6.9832e+02],\n",
      "          ...,\n",
      "          [-1.8615e+01, -1.4994e+01, -2.1993e+01,  ..., -2.5025e+01,\n",
      "           -1.6987e+01, -2.8045e+01],\n",
      "          [-2.3887e+01, -3.0139e+01, -2.4586e+01,  ..., -2.6384e+01,\n",
      "           -2.3704e+01, -2.5589e+01],\n",
      "          [-5.2493e+01, -4.4592e+01, -4.9248e+01,  ..., -3.7713e+01,\n",
      "           -3.6777e+01, -4.6723e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3607e-01,  1.3238e+02,  5.3009e+01,  ..., -2.6138e+01,\n",
      "            1.4642e+02,  6.0918e+01],\n",
      "          [-2.7170e+01, -2.6777e+02, -3.7388e+02,  ..., -4.7982e-01,\n",
      "           -4.1243e+01, -4.5303e+02],\n",
      "          [-8.4305e+01, -1.2267e+01, -3.7155e+02,  ..., -2.2086e+02,\n",
      "            1.0325e+02,  2.5529e+02],\n",
      "          ...,\n",
      "          [-6.8226e+00,  2.7108e-01,  9.0291e+00,  ...,  1.8527e+00,\n",
      "            8.8439e+00,  1.1702e+01],\n",
      "          [-2.0182e+01, -1.1036e+01, -6.7513e+00,  ..., -5.8425e+00,\n",
      "           -9.8956e+00, -3.1861e+00],\n",
      "          [-2.3283e+01, -1.7315e+01, -1.1457e+01,  ..., -8.1412e+00,\n",
      "            8.4305e-01,  1.1937e+01]],\n",
      "\n",
      "         [[-1.3708e+02, -1.0383e+02, -2.1370e+02,  ..., -8.3320e+01,\n",
      "           -4.7332e+02, -1.0189e+02],\n",
      "          [ 1.2012e+01,  5.8927e+01,  2.7951e+02,  ...,  5.1214e+01,\n",
      "           -2.1204e+02,  6.1179e+01],\n",
      "          [ 1.3578e+02,  5.0387e+02, -4.6765e+01,  ...,  1.0176e+02,\n",
      "           -6.4238e+00,  3.1647e+02],\n",
      "          ...,\n",
      "          [-9.9940e+00, -1.3342e+01, -7.1966e+00,  ..., -8.2549e+00,\n",
      "           -8.8161e+00,  4.0624e+00],\n",
      "          [ 6.4199e+00,  9.7214e+00,  8.7455e+00,  ...,  2.4992e+00,\n",
      "            3.1864e+00,  1.5548e+01],\n",
      "          [-1.0953e+00, -1.0599e+01, -8.7510e+00,  ..., -8.4082e+00,\n",
      "           -1.0736e+01, -1.8217e+00]],\n",
      "\n",
      "         [[-1.9732e+02, -1.5682e+02, -1.4043e+01,  ..., -4.8843e+01,\n",
      "            1.3171e+02,  1.0646e+02],\n",
      "          [ 3.0256e+02,  1.9113e+02,  1.8819e+02,  ...,  5.4816e+02,\n",
      "            1.1441e+02,  1.9300e+02],\n",
      "          [-4.1426e+02, -4.7256e+02, -7.6831e+02,  ..., -6.2395e+02,\n",
      "           -3.5203e+02, -3.2222e+02],\n",
      "          ...,\n",
      "          [-4.9610e+00, -6.3681e+00, -5.4769e+00,  ..., -1.3175e+01,\n",
      "           -6.4587e+00, -3.0850e+00],\n",
      "          [-1.2949e+01, -1.5713e+01, -1.6882e+01,  ..., -1.8016e+01,\n",
      "           -1.6336e+01, -1.1464e+01],\n",
      "          [-1.8332e+01, -2.3215e+01, -3.0402e+01,  ..., -2.8658e+01,\n",
      "           -3.1002e+01, -2.0072e+01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5158e+04,  7.1038e+04, -1.0798e+05,  ...,  1.5978e+03,\n",
      "            5.4214e+02,  1.0401e+03],\n",
      "          [-4.1313e+04, -2.8075e+03,  4.6246e+03,  ...,  3.3326e+03,\n",
      "            3.2190e+03,  2.5376e+03],\n",
      "          [ 3.3109e+02,  6.7138e+02,  1.4986e+03,  ..., -2.1588e+02,\n",
      "            4.8716e+02,  7.6002e+02],\n",
      "          ...,\n",
      "          [ 3.8155e+00,  1.9343e+01,  1.3481e+01,  ..., -1.3380e+02,\n",
      "            2.1689e+02, -7.6142e+02],\n",
      "          [ 1.7536e+01,  1.2277e+01,  5.8922e+00,  ...,  6.9954e-01,\n",
      "           -2.4817e+01, -1.0850e+01],\n",
      "          [ 1.3942e+01,  6.1771e+00,  1.5333e+01,  ...,  1.1347e+01,\n",
      "            1.3763e+01,  8.6444e+00]],\n",
      "\n",
      "         [[ 7.7027e+04,  3.8244e+04,  8.8349e+04,  ..., -5.1216e+02,\n",
      "            5.7306e+02,  1.4822e+03],\n",
      "          [ 5.2633e+04,  1.4003e+04,  1.6433e+04,  ...,  7.3391e+03,\n",
      "            3.8198e+03,  2.4837e+03],\n",
      "          [ 5.4739e+02,  4.1387e+02,  1.1821e+02,  ...,  4.3134e+02,\n",
      "            4.3451e+02,  6.6162e+02],\n",
      "          ...,\n",
      "          [ 2.1863e+01,  1.2754e+01,  1.2960e+01,  ...,  1.1334e+02,\n",
      "            6.5597e+01, -5.6852e+02],\n",
      "          [ 1.5616e+01,  1.2404e+01,  1.3438e+01,  ...,  3.0843e+01,\n",
      "            5.0902e+01,  3.0773e+01],\n",
      "          [ 1.0516e+01,  1.4989e+01,  1.9139e+01,  ...,  2.0474e+01,\n",
      "            2.0279e+01,  1.7468e+01]],\n",
      "\n",
      "         [[-1.0887e+05, -1.1584e+05, -5.5601e+04,  ..., -1.0678e+03,\n",
      "           -3.3075e+02, -1.3841e+02],\n",
      "          [ 2.4507e+04, -2.5187e+04, -1.7853e+04,  ..., -1.4033e+03,\n",
      "           -1.3476e+03, -1.8995e+03],\n",
      "          [-2.7703e+03, -2.7833e+03, -3.2311e+03,  ..., -4.3645e+03,\n",
      "           -2.1660e+03, -7.8983e+02],\n",
      "          ...,\n",
      "          [-2.2775e+01, -2.2177e+01, -2.8339e+01,  ..., -2.0955e+02,\n",
      "           -3.3218e+02, -6.0460e+02],\n",
      "          [-2.9235e+01, -3.1447e+01, -2.7793e+01,  ..., -2.6566e+01,\n",
      "           -2.2323e+01, -1.9526e+01],\n",
      "          [-3.1801e+01, -2.6488e+01, -2.8592e+01,  ..., -3.1096e+01,\n",
      "           -2.4768e+01, -2.7567e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1940e+04,  4.6151e+04,  1.8398e+04,  ...,  6.0360e+03,\n",
      "            4.3701e+02,  4.3198e+02],\n",
      "          [-3.3504e+04, -3.2367e+04,  1.7290e+04,  ..., -4.0413e+02,\n",
      "           -1.2028e+03,  5.0746e+02],\n",
      "          [-9.0224e+03,  1.0292e+03, -9.3678e+03,  ...,  1.1755e+04,\n",
      "            6.8490e+02,  5.4714e+02],\n",
      "          ...,\n",
      "          [-2.9646e+01, -1.3011e+01,  1.0403e+02,  ..., -7.3723e+01,\n",
      "           -8.7811e+02,  1.9250e+02],\n",
      "          [-1.5990e+01, -1.9413e+01,  3.3313e+01,  ...,  1.7991e+02,\n",
      "           -9.3110e+02, -1.7936e+02],\n",
      "          [-1.3237e+01, -1.2341e+01,  2.5822e-01,  ..., -1.1279e+00,\n",
      "            1.3829e+00, -4.5616e+01]],\n",
      "\n",
      "         [[-4.1089e+04, -2.7176e+04, -1.7912e+03,  ...,  3.6525e+02,\n",
      "           -1.2691e+03,  6.1108e+02],\n",
      "          [ 6.8275e+04,  8.9950e+03,  6.6513e+03,  ..., -8.2353e+03,\n",
      "           -1.5192e+03,  3.7442e+02],\n",
      "          [ 1.6328e+04,  2.3467e+04,  7.8774e+03,  ..., -7.7952e+03,\n",
      "           -2.0054e+03, -9.3836e+02],\n",
      "          ...,\n",
      "          [ 1.1848e+00,  1.0424e+01, -4.5888e+01,  ...,  9.1215e+01,\n",
      "           -1.4842e+02, -1.5828e+02],\n",
      "          [ 1.0857e+00,  7.4207e+00,  1.1229e+01,  ...,  6.2203e+02,\n",
      "            1.4541e+01,  4.9116e+02],\n",
      "          [ 1.0751e+00, -7.9593e+00,  3.3842e+00,  ..., -2.9780e+00,\n",
      "            6.0946e+01,  4.0401e+01]],\n",
      "\n",
      "         [[ 2.2192e+04, -3.8905e+03, -2.2466e+04,  ...,  5.0941e+03,\n",
      "            6.6478e+02,  6.5970e+02],\n",
      "          [-1.9845e+04, -1.8236e+04, -2.8121e+04,  ...,  5.9365e+02,\n",
      "            2.5967e+02,  2.1565e+02],\n",
      "          [-1.3314e+04, -7.0001e+03,  5.0491e+03,  ..., -1.3968e+04,\n",
      "           -4.5515e+03, -1.6971e+03],\n",
      "          ...,\n",
      "          [-3.4304e+01, -2.1853e+01, -9.2596e+01,  ..., -5.6835e+02,\n",
      "           -1.4641e+03, -1.5955e+03],\n",
      "          [-1.3417e+01, -1.8480e+01,  2.8514e+01,  ..., -2.2376e+02,\n",
      "           -1.2803e+02, -4.7438e+02],\n",
      "          [-1.2871e+01, -2.5481e+01, -2.8381e+01,  ..., -1.0011e+01,\n",
      "           -4.3971e+01, -2.0520e+01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8526e+03,  2.2961e+03,  6.1720e+03,  ..., -1.6570e+02,\n",
      "            2.6991e+03,  1.9250e+03],\n",
      "          [ 7.2540e+02,  7.4445e+01,  5.7549e+02,  ..., -2.3264e+02,\n",
      "           -1.1493e+02, -4.9465e+01],\n",
      "          [ 1.4153e+02,  8.3759e+01,  1.0954e+02,  ...,  5.5444e+01,\n",
      "            6.4300e+01,  2.3335e+02],\n",
      "          ...,\n",
      "          [-6.1780e+03,  7.2658e+02, -2.4894e+03,  ..., -1.3402e+02,\n",
      "            1.4706e+03,  3.3157e+05],\n",
      "          [ 1.1409e+02, -2.2388e+02, -9.0005e+00,  ...,  1.4216e+01,\n",
      "            1.7022e+02, -4.1845e+01],\n",
      "          [ 2.0428e+01, -7.7839e-01,  5.0382e+00,  ...,  5.2639e+00,\n",
      "            3.9286e+01,  3.9136e+02]],\n",
      "\n",
      "         [[ 1.5241e+03,  2.1498e+03,  1.1458e+03,  ...,  3.2294e+03,\n",
      "            2.1528e+03,  2.5925e+03],\n",
      "          [-8.5807e+02, -1.4044e+02, -9.1994e+02,  ...,  4.3127e+02,\n",
      "            4.2000e+01,  3.2845e+02],\n",
      "          [ 9.9092e+01,  2.5934e+01,  1.7047e+00,  ..., -7.1912e+01,\n",
      "            3.5537e+01, -1.3333e-01],\n",
      "          ...,\n",
      "          [ 1.4069e+04, -1.2108e+03, -5.5405e+02,  ..., -9.2821e+01,\n",
      "           -8.8193e+01,  1.7671e+05],\n",
      "          [-1.0738e+01,  3.0702e+00,  2.9165e+01,  ...,  1.8442e+01,\n",
      "            1.0577e+02, -2.3836e+02],\n",
      "          [ 3.5657e+01,  2.0527e+01,  1.8503e+01,  ...,  1.9907e+01,\n",
      "            1.1942e+01,  2.2118e+02]],\n",
      "\n",
      "         [[-2.0735e+03, -1.3180e+03, -9.3556e+02,  ...,  5.4144e+02,\n",
      "           -1.7643e+03, -1.9226e+03],\n",
      "          [-1.0186e+03, -1.8500e+03, -2.4075e+03,  ..., -9.3899e+02,\n",
      "           -1.2673e+03, -7.5455e+02],\n",
      "          [-7.6597e+01, -3.6499e+01, -7.4309e+01,  ..., -3.3661e+01,\n",
      "           -4.2245e+01, -8.4743e+01],\n",
      "          ...,\n",
      "          [-6.7374e+04, -7.1226e+03, -5.1829e+02,  ..., -4.6566e+02,\n",
      "           -1.2114e+03, -1.2581e+05],\n",
      "          [-2.5301e+02,  2.2656e+01, -3.6929e+01,  ..., -2.8465e+01,\n",
      "           -2.2827e+02, -6.4971e+02],\n",
      "          [-8.1374e+01, -3.0312e+01, -2.9126e+01,  ..., -2.5799e+01,\n",
      "           -5.5593e+01, -4.9826e+02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.1777e+01, -7.5597e+02, -1.1818e+03,  ...,  5.3800e+02,\n",
      "           -2.6036e+02, -1.8012e+02],\n",
      "          [-2.0982e+03, -1.7500e+03, -2.2612e+03,  ..., -9.1461e+02,\n",
      "           -5.8931e+02, -2.7311e+01],\n",
      "          [-9.5104e+02, -4.4287e+02,  1.2226e+03,  ...,  5.4441e+02,\n",
      "            3.5104e+02,  1.5592e+02],\n",
      "          ...,\n",
      "          [ 4.1777e+04, -1.1927e+04,  1.0334e+04,  ...,  2.2728e+04,\n",
      "           -1.6358e+05, -3.7975e+05],\n",
      "          [-2.2452e+04,  2.1649e+04,  1.0639e+03,  ..., -9.6189e+04,\n",
      "            1.5273e+05,  2.4902e+05],\n",
      "          [ 4.1140e+03,  3.1363e+03,  1.2810e+03,  ...,  2.3949e+04,\n",
      "            3.7999e+04,  1.9595e+04]],\n",
      "\n",
      "         [[-4.6068e+02, -9.3291e+02,  1.0194e+02,  ..., -1.8848e+03,\n",
      "           -2.0530e+03, -8.6334e+02],\n",
      "          [ 7.6785e+02,  7.5210e+02,  1.0834e+01,  ..., -3.1882e+01,\n",
      "           -3.2601e+01,  6.2316e+02],\n",
      "          [ 5.5118e+02, -3.1653e+02,  3.0838e+03,  ...,  1.0532e+03,\n",
      "            3.0511e+02,  8.2757e+02],\n",
      "          ...,\n",
      "          [-3.4153e+03,  1.0722e+03, -1.1418e+04,  ...,  8.3309e+04,\n",
      "            3.0739e+04,  1.1737e+05],\n",
      "          [-1.8688e+04,  4.1298e+03,  1.1678e+04,  ..., -1.3063e+05,\n",
      "           -1.4162e+05,  8.3352e+04],\n",
      "          [-3.1180e+03,  8.9632e+03,  7.1976e+02,  ..., -3.3792e+04,\n",
      "           -5.6060e+04, -3.8409e+04]],\n",
      "\n",
      "         [[ 4.9909e+02,  8.2242e+01,  1.1726e+03,  ...,  1.4040e+03,\n",
      "            6.7132e+02,  4.2302e+02],\n",
      "          [-1.4368e+03, -3.5213e+03, -5.2206e+03,  ..., -2.2452e+03,\n",
      "           -2.0868e+03, -9.3237e+02],\n",
      "          [-9.6096e+02, -4.3553e+02, -1.8961e+02,  ..., -2.9123e+02,\n",
      "           -8.3588e+02,  3.0127e+00],\n",
      "          ...,\n",
      "          [-2.9432e+04, -2.5454e+04, -8.8072e+03,  ..., -8.7866e+04,\n",
      "            8.8037e+04, -1.0542e+05],\n",
      "          [ 3.2537e+03,  1.5481e+04, -4.1826e+03,  ...,  4.2706e+04,\n",
      "           -9.6108e+04,  1.2594e+04],\n",
      "          [-5.9710e+03,  3.7733e+03, -6.2743e+02,  ..., -1.8393e+04,\n",
      "           -3.4152e+04,  3.8947e+04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.0894e-02,  7.4142e-02,  1.0081e-01,  ...,  3.0378e-01,\n",
      "            9.3164e-02,  2.9450e-01],\n",
      "          [ 4.9256e-02,  8.3419e-02,  3.8406e-01,  ...,  1.1148e-01,\n",
      "            2.0337e-01,  3.3541e-01],\n",
      "          [ 5.6759e-01,  3.8617e-01,  2.6888e-01,  ...,  1.6312e-01,\n",
      "            3.1039e-01,  4.0432e-01],\n",
      "          ...,\n",
      "          [ 8.2311e-01, -7.3413e-01, -1.6779e+00,  ...,  1.0036e-01,\n",
      "            9.2695e-02,  9.5588e-02],\n",
      "          [ 1.0406e-01,  1.0804e-01,  9.4802e-02,  ...,  1.0417e-01,\n",
      "            9.6296e-02,  9.5826e-02],\n",
      "          [ 1.1908e-01,  1.0321e-01,  1.1029e-01,  ...,  1.0022e-01,\n",
      "            1.0724e-01,  1.0304e-01]],\n",
      "\n",
      "         [[ 3.3443e-01,  2.2616e-01,  2.4431e-01,  ...,  3.1570e-01,\n",
      "            2.2469e-01,  4.1197e-01],\n",
      "          [ 4.9050e-01,  7.6828e-01,  6.4556e-01,  ...,  4.5633e-01,\n",
      "            5.4197e-01,  5.5797e-01],\n",
      "          [ 2.5968e-01,  1.1516e+00,  6.6941e-01,  ...,  5.3201e-01,\n",
      "            9.1828e-01,  5.4361e-01],\n",
      "          ...,\n",
      "          [ 5.1496e-02,  8.0533e-02,  1.3487e+00,  ...,  2.9604e-01,\n",
      "            3.0759e-01,  2.9780e-01],\n",
      "          [ 3.1026e-01,  2.9848e-01,  3.1416e-01,  ...,  3.0227e-01,\n",
      "            3.0365e-01,  2.9406e-01],\n",
      "          [ 3.0892e-01,  3.1014e-01,  3.0446e-01,  ...,  3.0285e-01,\n",
      "            3.0173e-01,  3.0296e-01]],\n",
      "\n",
      "         [[ 1.8788e-01,  5.4932e-02,  8.8263e-02,  ...,  1.1074e-02,\n",
      "            1.1473e-01,  1.7594e-01],\n",
      "          [-1.0427e-01, -3.3243e-01, -2.7612e-01,  ..., -1.4960e-01,\n",
      "           -7.4585e-02, -2.8339e-01],\n",
      "          [-2.8507e-01, -4.0578e-01, -3.0405e-01,  ..., -4.2423e-01,\n",
      "           -2.4713e-01, -2.4012e-01],\n",
      "          ...,\n",
      "          [-4.4916e-01, -1.6093e-01,  1.5180e-01,  ...,  3.7737e-02,\n",
      "            3.8292e-02,  2.8841e-02],\n",
      "          [ 4.3609e-02,  3.6658e-02,  5.2347e-02,  ...,  3.8984e-02,\n",
      "            5.0064e-02,  3.9728e-02],\n",
      "          [ 3.5423e-02,  3.4202e-02,  3.7150e-02,  ...,  4.6780e-02,\n",
      "            4.5190e-02,  4.3543e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5883e-01,  1.5002e-01,  1.1869e-01,  ...,  1.0903e-01,\n",
      "           -7.7017e-03,  6.1061e-03],\n",
      "          [ 9.3258e-02,  1.2445e-01,  3.4871e-01,  ...,  3.9563e-01,\n",
      "            1.7243e-01,  1.5577e-01],\n",
      "          [-7.9541e-02, -1.6688e-01,  2.3544e-02,  ...,  2.2853e-01,\n",
      "           -5.8222e-03,  9.0335e-02],\n",
      "          ...,\n",
      "          [-8.9685e-01,  7.9936e-02, -5.2794e-02,  ...,  1.5350e-01,\n",
      "            1.7205e-01,  9.5943e-02],\n",
      "          [-4.8143e-01,  1.1189e+00,  1.4842e+00,  ...,  1.0266e-01,\n",
      "            1.0383e-01,  3.5872e-02],\n",
      "          [ 8.1982e-02,  9.8770e-02,  1.4403e-01,  ...,  1.0646e-01,\n",
      "            1.0106e-01,  6.2141e-02]],\n",
      "\n",
      "         [[ 1.4965e-01,  1.4986e-01, -8.7981e-02,  ...,  9.5109e-02,\n",
      "            2.9305e-01,  1.0865e-01],\n",
      "          [-1.6482e-02,  1.2323e-01,  2.8792e-02,  ...,  1.3404e-01,\n",
      "           -2.4828e-01, -1.1733e-03],\n",
      "          [ 3.3232e-02,  1.2831e-01,  7.8604e-02,  ..., -1.2536e-01,\n",
      "           -1.7647e-01,  2.8290e-01],\n",
      "          ...,\n",
      "          [-1.9288e-01,  7.2856e-01,  2.3534e+00,  ...,  9.6937e-02,\n",
      "            9.9770e-02,  7.5455e-02],\n",
      "          [-5.1285e-02, -7.3662e-02,  1.7144e+00,  ...,  9.9997e-02,\n",
      "            1.1743e-01,  1.1290e-01],\n",
      "          [ 2.0624e-02,  3.6077e-02,  3.9786e-02,  ...,  2.3606e-02,\n",
      "            2.6068e-02,  4.9324e-02]],\n",
      "\n",
      "         [[ 1.2202e-01,  1.5091e-01,  4.6855e-02,  ...,  2.6320e-01,\n",
      "            1.7792e-01,  8.7116e-02],\n",
      "          [ 2.6366e-01,  1.2253e-01, -6.5238e-02,  ...,  2.9954e-01,\n",
      "            1.6858e-01,  2.2584e-01],\n",
      "          [ 1.5639e-01, -6.8269e-02, -1.8605e-01,  ..., -4.0211e-01,\n",
      "           -1.7400e-02,  5.8939e-02],\n",
      "          ...,\n",
      "          [-1.5938e+00, -2.1453e+00, -8.5016e+00,  ...,  8.2521e-02,\n",
      "            9.8556e-02,  9.5734e-02],\n",
      "          [ 1.0088e-01, -1.9820e-01, -1.5113e+00,  ...,  7.0517e-02,\n",
      "            6.9163e-02,  4.6265e-02],\n",
      "          [-1.7637e-02, -1.0302e-02,  1.9599e-02,  ...,  3.7800e-02,\n",
      "            4.9369e-02,  5.3134e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.4434e+03, -6.2978e+03,  1.7098e+03,  ..., -5.2484e-02,\n",
      "           -5.2484e-02, -5.2484e-02],\n",
      "          [ 3.4645e+02,  4.9526e+02, -1.5790e+03,  ...,  8.7522e-02,\n",
      "            8.7522e-02,  8.7522e-02],\n",
      "          [ 2.6866e+02, -9.7031e+01, -1.2776e+02,  ...,  8.7522e-02,\n",
      "            8.7522e-02,  8.7522e-02],\n",
      "          ...,\n",
      "          [ 9.7438e+01,  1.1970e+01,  5.1557e+01,  ...,  8.7522e-02,\n",
      "            8.7522e-02,  8.7522e-02],\n",
      "          [ 3.1645e+01, -1.6890e+01, -1.4351e+01,  ...,  8.7522e-02,\n",
      "            8.7522e-02,  8.7522e-02],\n",
      "          [ 6.0427e+00,  8.9163e-01,  3.8083e+00,  ...,  8.7522e-02,\n",
      "            8.7522e-02,  8.7522e-02]],\n",
      "\n",
      "         [[ 6.4095e+01,  7.2803e+02, -2.0506e+03,  ..., -7.3420e-01,\n",
      "           -7.3420e-01, -7.3420e-01],\n",
      "          [ 2.3919e+03,  4.1338e+02,  1.0233e+03,  ...,  2.6661e-01,\n",
      "            2.6661e-01,  2.6661e-01],\n",
      "          [ 2.1864e+02,  9.8663e+01,  2.3065e+02,  ...,  2.6661e-01,\n",
      "            2.6661e-01,  2.6661e-01],\n",
      "          ...,\n",
      "          [ 3.5510e+01,  8.7340e+01,  8.3209e+01,  ...,  2.6661e-01,\n",
      "            2.6661e-01,  2.6661e-01],\n",
      "          [ 2.6648e+01,  2.1683e+01,  2.7905e+01,  ...,  2.6661e-01,\n",
      "            2.6661e-01,  2.6661e-01],\n",
      "          [ 4.9787e+00,  6.1602e+00,  7.5981e+00,  ...,  2.6661e-01,\n",
      "            2.6661e-01,  2.6661e-01]],\n",
      "\n",
      "         [[-1.0835e+04, -1.5369e+04, -5.9503e+03,  ..., -4.7188e-01,\n",
      "           -4.7188e-01, -4.7188e-01],\n",
      "          [-1.1974e+03, -2.1693e+03, -1.8215e+03,  ...,  9.8993e-02,\n",
      "            9.8993e-02,  9.8993e-02],\n",
      "          [-4.8689e+02, -7.2142e+02, -6.6249e+02,  ...,  9.8993e-02,\n",
      "            9.8993e-02,  9.8993e-02],\n",
      "          ...,\n",
      "          [-1.8087e+02, -1.1183e+02, -2.0188e+02,  ...,  9.8993e-02,\n",
      "            9.8993e-02,  9.8993e-02],\n",
      "          [-4.3947e+01, -2.8279e+01, -3.7177e+01,  ...,  9.8993e-02,\n",
      "            9.8993e-02,  9.8993e-02],\n",
      "          [-2.4247e+01, -1.7188e+01, -1.7108e+01,  ...,  9.8993e-02,\n",
      "            9.8993e-02,  9.8993e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.5531e+03,  1.8145e+02,  4.1768e+03,  ...,  5.9963e-03,\n",
      "            2.5625e-03, -7.8038e-02],\n",
      "          [-4.6758e+03, -9.2904e+02, -5.3558e+03,  ..., -2.3100e-01,\n",
      "           -2.2062e-01, -7.8045e-03],\n",
      "          [-1.9937e+03, -9.9612e+02,  2.3371e+02,  ...,  2.6595e-01,\n",
      "            2.8283e-01,  1.8850e-01],\n",
      "          ...,\n",
      "          [-3.1501e+01, -6.9410e+01, -9.4263e+00,  ...,  1.4816e-01,\n",
      "            1.4816e-01,  5.8813e-02],\n",
      "          [-8.0059e+01, -7.0739e+01, -8.3453e+00,  ...,  1.0992e-01,\n",
      "            1.0992e-01,  3.0709e-02],\n",
      "          [-4.2255e+01, -1.6824e+01, -8.3581e+00,  ...,  1.0828e-01,\n",
      "            1.0828e-01,  6.1205e-02]],\n",
      "\n",
      "         [[-3.8177e+03, -1.6326e+03, -4.2700e+03,  ..., -4.7643e-01,\n",
      "           -4.7898e-01, -2.8765e-01],\n",
      "          [ 8.5456e+02, -1.8596e+03,  1.4909e+03,  ...,  2.1915e-01,\n",
      "            3.1153e-01,  2.4226e-01],\n",
      "          [ 9.6825e+02,  6.5903e+02,  2.2659e+03,  ...,  2.2757e-01,\n",
      "            2.6370e-01,  2.5092e-01],\n",
      "          ...,\n",
      "          [ 6.3621e+00, -1.8868e+01,  1.8346e+02,  ...,  8.4441e-02,\n",
      "            8.4441e-02,  6.0049e-02],\n",
      "          [-1.9032e+01, -2.7075e+01,  8.4887e+01,  ...,  8.2949e-02,\n",
      "            8.2949e-02,  8.8600e-02],\n",
      "          [ 2.2176e+01,  1.8880e+01,  3.7669e+01,  ...,  4.0111e-02,\n",
      "            4.0111e-02,  4.9553e-02]],\n",
      "\n",
      "         [[ 3.5737e+03,  1.7780e+03,  4.9774e+03,  ...,  3.3622e-01,\n",
      "            3.5772e-01,  8.6274e-02],\n",
      "          [-1.2378e+03, -3.6114e+03, -1.6698e+03,  ..., -1.1555e-01,\n",
      "           -1.0577e-01,  5.4048e-02],\n",
      "          [-1.7825e+03, -1.9780e+03, -2.4234e+03,  ..., -6.6983e-02,\n",
      "           -1.6291e-02, -2.3000e-02],\n",
      "          ...,\n",
      "          [-7.2082e+01, -3.4029e+01, -9.9413e+01,  ...,  1.7761e-01,\n",
      "            1.7761e-01,  1.4230e-01],\n",
      "          [-6.1454e+01, -9.0045e+01, -1.0689e+02,  ...,  1.2035e-01,\n",
      "            1.2035e-01,  9.2078e-02],\n",
      "          [-3.8437e+01, -2.8425e+01, -4.8025e+01,  ...,  9.1450e-02,\n",
      "            9.1450e-02,  9.8810e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8613e+01,  3.2368e+00, -1.4821e+00,  ...,  4.6061e+00,\n",
      "            1.3334e+00, -9.9534e+00],\n",
      "          [-4.0732e+02,  3.7507e+02,  1.2142e+02,  ..., -5.4174e+01,\n",
      "           -6.4981e+01,  7.2700e+01],\n",
      "          [ 1.8734e+03,  2.9835e+03,  1.4109e+03,  ...,  6.5980e+02,\n",
      "            1.2712e+03,  6.0540e+02],\n",
      "          ...,\n",
      "          [ 5.0172e+02, -1.5268e+03, -3.0301e+03,  ...,  2.8114e+02,\n",
      "           -4.5142e+02,  5.0302e+00],\n",
      "          [ 2.3010e+02,  1.2961e+02,  6.8479e+01,  ...,  1.5970e+02,\n",
      "           -1.8157e+02, -1.4848e+02],\n",
      "          [ 4.4491e+02,  3.9923e+02,  2.5777e+02,  ...,  2.8957e+02,\n",
      "            1.7984e+02,  1.8175e+02]],\n",
      "\n",
      "         [[ 4.0469e+01, -1.8944e+01, -1.2086e+00,  ..., -6.2239e+00,\n",
      "           -1.4493e+01, -2.3460e+01],\n",
      "          [-2.1205e+02,  9.2062e+01, -3.5117e+02,  ..., -2.7130e+02,\n",
      "           -5.7529e+01, -3.6590e+01],\n",
      "          [ 3.3947e+03,  4.2251e+03,  4.2262e+03,  ...,  1.3161e+03,\n",
      "            1.4977e+03,  9.7822e+02],\n",
      "          ...,\n",
      "          [-8.6133e+01,  2.4109e+02,  2.0114e+03,  ...,  9.9004e+02,\n",
      "            1.6865e+02,  2.2235e+03],\n",
      "          [ 3.8315e+02,  3.0559e+02,  3.7086e+02,  ...,  2.9055e+02,\n",
      "            4.0251e+02,  3.4745e+02],\n",
      "          [ 3.5558e+02,  5.1090e+02,  4.0392e+02,  ...,  5.5522e+02,\n",
      "            5.5248e+02,  4.5519e+02]],\n",
      "\n",
      "         [[-1.9359e+01, -1.3811e+01, -4.4575e+00,  ..., -1.8714e+01,\n",
      "            4.8396e+00,  1.3002e+01],\n",
      "          [-2.2830e+02, -4.5451e+02, -5.4592e+02,  ...,  2.4803e+02,\n",
      "           -5.5474e+01,  2.6709e+02],\n",
      "          [-4.5739e+02, -2.0704e+03,  4.9403e+02,  ..., -1.0057e+03,\n",
      "           -2.2151e+03, -7.3145e+02],\n",
      "          ...,\n",
      "          [-1.3718e+03,  4.7889e+01, -1.3823e+03,  ..., -3.0155e+03,\n",
      "           -3.7269e+03, -1.3628e+03],\n",
      "          [-3.9099e+02, -3.2366e+02, -3.9076e+02,  ..., -4.2783e+02,\n",
      "           -4.5630e+02, -7.6383e+02],\n",
      "          [-9.4547e+02, -7.1773e+02, -7.3030e+02,  ..., -6.4767e+02,\n",
      "           -7.0761e+02, -6.3736e+02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.5992e+02, -5.3561e+01,  8.8907e+02,  ...,  2.3419e+02,\n",
      "            6.1486e+02,  4.4645e+02],\n",
      "          [ 2.3458e+03,  1.2584e+03,  1.8579e+03,  ...,  6.0852e+02,\n",
      "            1.3575e+03,  8.9321e+02],\n",
      "          [-1.4605e+03, -2.0083e+03,  7.6375e+01,  ...,  3.8266e+02,\n",
      "            5.8041e+02, -6.0158e+01],\n",
      "          ...,\n",
      "          [-1.6567e+04,  9.7922e+02,  9.7116e+03,  ..., -1.1461e+02,\n",
      "           -3.1714e+02,  6.5132e+03],\n",
      "          [-2.4042e+03, -1.3118e+03,  4.4376e+03,  ..., -1.9089e+03,\n",
      "           -1.3039e+03,  1.2053e+03],\n",
      "          [-3.5564e+02,  4.0836e+02,  3.2767e+01,  ...,  5.3082e+02,\n",
      "           -1.4385e+02,  8.9317e+01]],\n",
      "\n",
      "         [[-9.2116e+01, -3.0117e+02, -3.5419e+02,  ..., -2.9618e+02,\n",
      "           -2.0756e+02, -1.0277e+02],\n",
      "          [-1.6375e+03,  2.1978e+02,  6.0209e+02,  ..., -1.8237e+02,\n",
      "           -8.2744e+02,  5.8840e+02],\n",
      "          [-1.2118e+03,  8.6932e+02, -1.2045e+03,  ..., -8.5292e+02,\n",
      "            3.3838e+02,  3.2103e+02],\n",
      "          ...,\n",
      "          [ 4.0759e+03, -7.6611e+03,  1.7598e+04,  ...,  1.3693e+03,\n",
      "           -4.0891e+03,  4.9169e+03],\n",
      "          [ 3.8938e+02,  1.1100e+03,  3.1469e+03,  ...,  4.1688e+02,\n",
      "            1.2105e+03,  8.6125e+02],\n",
      "          [ 1.5004e+00, -6.9729e+01, -3.9222e+02,  ...,  2.9087e+02,\n",
      "            6.3673e+02,  2.5398e+02]],\n",
      "\n",
      "         [[ 2.7547e+02,  1.6710e+01, -2.8527e+02,  ...,  1.0680e+02,\n",
      "           -1.0585e+01, -1.0135e+02],\n",
      "          [ 1.2809e+03, -8.5524e+02, -1.2183e+03,  ..., -1.4215e+02,\n",
      "            2.7035e+02, -4.5280e+02],\n",
      "          [ 2.4849e+03, -8.1940e+02,  1.3227e+03,  ...,  9.3140e+02,\n",
      "            3.6804e+01,  1.5099e+03],\n",
      "          ...,\n",
      "          [-6.1489e+03, -1.9359e+03,  2.5359e+03,  ..., -1.3028e+03,\n",
      "           -2.7226e+03, -7.8670e+02],\n",
      "          [-2.7270e+02, -3.1974e+03,  7.6659e+02,  ..., -3.1756e+03,\n",
      "           -2.2222e+03, -1.0642e+03],\n",
      "          [-2.5199e+02, -6.0066e+01, -2.7357e+02,  ..., -6.4969e+02,\n",
      "           -5.3010e+02, -8.0684e+02]]]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## check output shape\n",
    "\n",
    "model =ConvBlock2()\n",
    "\n",
    "output_test_2=model(output_test_1)\n",
    "\n",
    "print(output_test_2.shape)\n",
    "print(output_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChronoNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1=ConvBlock1()\n",
    "        self.block2=ConvBlock2()\n",
    "        # input_size=ch_num*height\n",
    "        self.gru1=nn.GRU(input_size=96*10,hidden_size=32,num_layers=1,batch_first=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.block1(x)\n",
    "        x=self.block2(x)\n",
    "        # Because the input shape required by gru is (batch_size, sequence length, feature_size)\n",
    "        # But the result of the previous conversion calculation is (batchsize, channel_num, width, length)\n",
    "        # I need to change the shape\n",
    "        # (batch_size,width,ch_num*height)\n",
    "        batch_size,ch_num,height,width=x.size()\n",
    "        # x=x.permute(0,2,1,3).reshape(batch_size,width,ch_num*height)\n",
    "        x=x.reshape(batch_size,width,ch_num*height)\n",
    "        gru_out1,_=self.gru1(x)\n",
    "\n",
    "        return gru_out1,_\n",
    "        \n",
    "        \n",
    "# The above is used to view the output after adding a gru\n",
    "# Next I need to add more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 62, 32])\n",
      "torch.Size([1, 128, 32])\n"
     ]
    }
   ],
   "source": [
    "model=ChronoNet()\n",
    "output_test_4,_=model(mel_specs)\n",
    "\n",
    "print(output_test_4.shape)\n",
    "\n",
    "print(_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChronoNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1=ConvBlock1()\n",
    "        self.block2=ConvBlock2()\n",
    "        # input_size=ch_num*height\n",
    "        self.gru1=nn.GRU(input_size=96*10,hidden_size=32,num_layers=1,batch_first=True)\n",
    "        self.gru2=nn.GRU(input_size=32,hidden_size=32,num_layers=1,batch_first=True)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.block1(x)\n",
    "        x=self.block2(x)\n",
    "        # Because the input shape required by gru is (batch_size, sequence length, feature_size)\n",
    "        # But the result of the previous conversion calculation is (batchsize, channel_num, width, length)\n",
    "        # I need to change the shape\n",
    "        # (batch_size, width, ch_num*height)\n",
    "        batch_size,ch_num,height,width=x.size()\n",
    "        # x=x.permute(0,2,1,3).reshape(batch_size,width,ch_num*height)\n",
    "        x=x.reshape(batch_size,width,ch_num*height)\n",
    "        gru_out1,_=self.gru1(x)\n",
    "        gru_out2,_=self.gru2(gru_out1)\n",
    "        # According to the chrononet architecture, we need to connect the calculations of the two layers of GRU according to the feature-size dimension\n",
    "        x=torch.cat((gru_out1,gru_out2),dim=2)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 62, 64])\n"
     ]
    }
   ],
   "source": [
    "model=ChronoNet()\n",
    "output_test_5=model(mel_specs)\n",
    "\n",
    "print(output_test_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChronoNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1=ConvBlock1()\n",
    "        self.block2=ConvBlock2()\n",
    "        # input_size=ch_num*height\n",
    "        self.gru1=nn.GRU(input_size=96*10,hidden_size=32,num_layers=1,batch_first=True)\n",
    "        self.gru2=nn.GRU(input_size=32,hidden_size=32,num_layers=1,batch_first=True)\n",
    "        self.gru3=nn.GRU(input_size=64,hidden_size=32,num_layers=1,batch_first=True)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.block1(x)\n",
    "        x=self.block2(x)\n",
    "        # Because the input shape required by gru is (batch_size, sequence length, feature_size)\n",
    "        # But the result of the previous conversion calculation is (batchsize, channel_num, width, length)\n",
    "        # I need to change the shape\n",
    "        # (batch_size,width,ch_num*height)\n",
    "        batch_size,ch_num,height,width=x.size()\n",
    "        # x=x.permute(0,2,1,3).reshape(batch_size,width,ch_num*height)\n",
    "        x=x.reshape(batch_size,width,ch_num*height)\n",
    "        gru_out1,_=self.gru1(x)\n",
    "        gru_out2,_=self.gru2(gru_out1)\n",
    "        # According to the chrononet architecture, we need to connect the calculations of the two layers of GRU according to the feature-size dimension\n",
    "        x=torch.cat((gru_out1,gru_out2),dim=2)\n",
    "        gru_out3,_=self.gru3(x)\n",
    "        x=torch.cat((gru_out1,gru_out2,gru_out3),dim=2)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 62, 96])\n"
     ]
    }
   ],
   "source": [
    "model=ChronoNet()\n",
    "output_test_6=model(mel_specs)\n",
    "\n",
    "print(output_test_6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChronoNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1=ConvBlock1()\n",
    "        self.block2=ConvBlock2()\n",
    "        # input_size=ch_num*height\n",
    "        self.gru1=nn.GRU(input_size=96*10,hidden_size=32,num_layers=1,batch_first=True)\n",
    "        self.gru2=nn.GRU(input_size=32,hidden_size=32,num_layers=1,batch_first=True)\n",
    "        self.gru3=nn.GRU(input_size=64,hidden_size=32,num_layers=1,batch_first=True)\n",
    "        self.gru4=nn.GRU(input_size=96,hidden_size=32,num_layers=1,batch_first=True)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.block1(x)\n",
    "        x=self.block2(x)\n",
    "        # Because the input shape required by gru is (batch_size, sequence length, feature_size)\n",
    "        # But the result of the previous conversion calculation is (batchsize, channel_num, width, length)\n",
    "        # I need to change the shape\n",
    "        # (batch_size,width,ch_num*height)\n",
    "        batch_size,ch_num,height,width=x.size()\n",
    "        # x=x.permute(0,2,1,3).reshape(batch_size,width,ch_num*height)\n",
    "        x=x.reshape(batch_size,width,ch_num*height)\n",
    "        gru_out1,_=self.gru1(x)\n",
    "        gru_out2,_=self.gru2(gru_out1)\n",
    "        # According to the chrononet architecture, we need to connect the calculations of the two layers of GRU according to the feature-size dimension\n",
    "        x=torch.cat((gru_out1,gru_out2),dim=2)\n",
    "        gru_out3,_=self.gru3(x)\n",
    "        x=torch.cat((gru_out1,gru_out2,gru_out3),dim=2)\n",
    "        gru_out4,_=self.gru4(x)\n",
    "\n",
    "        return gru_out4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 62, 32])\n"
     ]
    }
   ],
   "source": [
    "model=ChronoNet()\n",
    "output_test_7=model(mel_specs)\n",
    "\n",
    "print(output_test_7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, integrate the steps of building the model above, and add activation functions and regularization layers\n",
    "\n",
    "# Because we need to train the model first, we need to calculate the loss\n",
    "# For multi-classification problems, if you choose to use nn.crossentropylss, you need to remove F.softmax(),\n",
    "# Because this loss function already combines Log-Softmax and NLL Loss (Negative Log Likelihood Loss).\n",
    "\n",
    "class ChronoNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1=ConvBlock1()\n",
    "        self.block2=ConvBlock2()\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=62)\n",
    "        # input_size=ch_num*height\n",
    "        self.gru1=nn.GRU(input_size=96*10,hidden_size=32,num_layers=1,batch_first=True)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=62)\n",
    "        self.gru2=nn.GRU(input_size=32,hidden_size=32,num_layers=1,batch_first=True)\n",
    "        self.gru3=nn.GRU(input_size=64,hidden_size=32,num_layers=1,batch_first=True)\n",
    "        self.gru4=nn.GRU(input_size=96,hidden_size=32,num_layers=1,batch_first=True)\n",
    "        self.fc1=nn.Linear(in_features=32,out_features=64)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, 160)  \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.block1(x)\n",
    "        x=self.block2(x)\n",
    "        # Because the input shape required by gru is (batch_size, sequence length, feature_size)\n",
    "        # But the result of the previous conversion calculation is (batchsize, channel_num, width, length)\n",
    "        # I need to change the shape\n",
    "        # (batch_size,width,ch_num*height)\n",
    "        batch_size,ch_num,height,width=x.size()\n",
    "        # x=x.permute(0,2,1,3).reshape(batch_size,width,ch_num*height)\n",
    "        x=x.reshape(batch_size,width,ch_num*height)\n",
    "\n",
    "        # add batch normalization\n",
    "        x=self.bn1(x)\n",
    "        # add relu activation fucntion\n",
    "        x = F.relu(x) \n",
    "\n",
    "        gru_out1,_=self.gru1(x)\n",
    "\n",
    "        x=self.bn2(gru_out1)\n",
    "        x=F.relu(x)\n",
    "\n",
    "        gru_out2,_=self.gru2(gru_out1)\n",
    "\n",
    "        x=F.relu(x)\n",
    "\n",
    "        # According to the chrononet architecture, we need to connect the calculations of the two layers of GRU according to the feature-size dimension\n",
    "        x=torch.cat((gru_out1,gru_out2),dim=2)\n",
    "        gru_out3,_=self.gru3(x)\n",
    "\n",
    "        x=F.relu(x)\n",
    "\n",
    "        x=torch.cat((gru_out1,gru_out2,gru_out3),dim=2)\n",
    "        gru_out4,_=self.gru4(x)\n",
    "\n",
    "        x=F.relu(x)\n",
    "\n",
    "        x = self.fc1(gru_out4[:, -1, :])  #Usually take the final output of GRU\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChronoNetModule(L.LightningModule):\n",
    "    def __init__(self,model,learning_rate):\n",
    "        super().__init__()\n",
    "        self.model=model\n",
    "        self.lr=learning_rate\n",
    "        self.train_acc=torchmetrics.Accuracy(task='multiclass',num_classes=160)\n",
    "        self.val_acc=torchmetrics.Accuracy(task='multiclass',num_classes=160)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        '''\n",
    "        x: feature data for training \n",
    "\n",
    "        This is the part of the neural model that is used to read or build\n",
    "        define the computation performed at every call define the computation performed at every call\n",
    "\n",
    "        return:\n",
    "            model's output\n",
    "        '''\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        '''\n",
    "        we need to train the model right here\n",
    "        including provide the loss step, acc calculation step\n",
    "\n",
    "        This function will perform the following operations:\n",
    "        1. Calculate the loss value for each training batch\n",
    "        2. Perform optimization and gradient descent (automatically performed by lightningModule)\n",
    "        3. Update parameters (automatically performed by lightningModule)\n",
    "        https://lightning.ai/docs/pytorch/stable/common/lightning_module.html#training\n",
    "        '''\n",
    "        # Read batch data\n",
    "        labels,features=batch\n",
    "\n",
    "        # Send data to GPU for training\n",
    "        features=features.to(self.device)\n",
    "        labels=labels.to(self.device)\n",
    "        \n",
    "        # feeding feature to the model\n",
    "        # Only self() is used here because the forward() function is automatically called\n",
    "        # forward propagation\n",
    "        out=self(features)\n",
    "\n",
    "        # After getting the output of the model, you need to calculate the loss function\n",
    "        loss=F.cross_entropy(out, labels)\n",
    "\n",
    "        # logs metrics for each training_step,\n",
    "        # and the average across the epoch, to the progress bar and logger\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        # after adding self.train_acc=torchmetrics.Accuracy(task='multiclass',num_classes=6)\n",
    "        # You can add the step of calculating accuracy below\n",
    "        # Because we use cross_entropy() as the loss function\n",
    "        # So we need to use argmax to convert to normal values for accuracy calculation\n",
    "        # predicted_labels=torch.argmax(out)\n",
    "        # But torchmetrics.Accuracy is already configured to handle logits suitable for multi-category classification problems. \n",
    "        # It will apply softmax (or log_softmax) and calculate argmax internally to determine the most likely category.\n",
    "        acc=self.train_acc(out,labels)\n",
    "        self.log(\"train_acc\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "\n",
    "        # In training_step(), we only calculate and return the loss. \n",
    "        # The optimization part does not belong to this part, and the optimization method will be defined in configure_optimizers.\n",
    "        return loss # this is passed to the optimizer for training\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        '''\n",
    "        val step is not used in traning, only in validation\n",
    "        '''\n",
    "        labels,features=batch\n",
    "\n",
    "        # Send data to GPU for training\n",
    "        features=features.to(self.device)\n",
    "        labels=labels.to(self.device)\n",
    "        \n",
    "        out=self(features)\n",
    "        loss=F.cross_entropy(out, labels)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        acc=self.val_acc(out,labels)\n",
    "        self.log(\"val_acc\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        '''\n",
    "        Choose what optimizers and learning-rate schedulers to use in your optimization.\n",
    "\n",
    "        The optimizer defined here will be automatically called by lightningModule\n",
    "        Used in the training step\n",
    "        '''\n",
    "        optimizer=torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        # If you have only one tensor (feature) in your TensorDataset, batch will be a tuple containing a tensor and an empty tuple (since there are no labels)\n",
    "        features= batch\n",
    "        features=features.to(self.device)\n",
    "        predictions = self(features)\n",
    "        # Because what our model ultimately wants is the probability of an object corresponding to all categories, so add the softmax function here\n",
    "        probabilities = torch.softmax(predictions, dim=1)\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChronoNetDataModule(L.LightningDataModule):\n",
    "    def __init__(self,dataset:Dataset,pred=None,batch_size:int=128):\n",
    "        super().__init__()\n",
    "        self.dataset=dataset\n",
    "        self.batch_size=batch_size\n",
    "\n",
    "        self.pred=pred\n",
    "\n",
    "    def setup(self,stage:str):\n",
    "        # assign train/val splits for use in dataloaders\n",
    "        if stage=='fit':\n",
    "            self.train_dataset,self.val_dataset=random_split(self.dataset,[0.8,0.2],generator=torch.Generator().manual_seed(42))\n",
    "        \n",
    "        # if stage=='predict':\n",
    "            \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        loader= DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        return loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        loader= DataLoader(self.val_dataset, batch_size=self.batch_size,shuffle=False)\n",
    "\n",
    "        return loader\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        loader=DataLoader(self.dataset,batch_size=self.batch_size,shuffle=False)\n",
    "\n",
    "        return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss', \n",
    "    dirpath='/Users/yiding/personal_projects/ML/github_repo/birdcief/code/model-training/checkpoints/',\n",
    "    filename='chrononet-{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=1, \n",
    "    mode='min', \n",
    "    auto_insert_metric_name=False \n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    min_delta=0.00,\n",
    "    patience=3, \n",
    "    verbose=True,\n",
    "    mode='min'  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize Dataset first\n",
    "\n",
    "BD=BirdclefDataset(encoder=encoder,labels_path=labels_path)\n",
    "# Previously we used a separate dataloader to feed the model\n",
    "# Here we encapsulate the dataloader and use this class to read data for training\n",
    "\n",
    "dm=ChronoNetDataModule(dataset=BD,batch_size=128)\n",
    "print(dm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model=ChronoNet()\n",
    "ChronoNetModule=ChronoNetModule(model=model,learning_rate=0.01)\n",
    "\n",
    "trainer=L.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"gpu\", # set to 'auto' or 'gpu' to use gpu if possible\n",
    "    devices=1, # use all gpus if applicable like value=1 or \"auto\"\n",
    "    default_root_dir='/Users/yiding/personal_projects/ML/github_repo/birdcief/code/model-training/',\n",
    "    # logger=CSVLogger(save_dir='/Users/yiding/personal_projects/ML/github_repo/birdcief/code/model-training/log/',name='chrononet')\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],  # Add callback to trainer\n",
    ")\n",
    "\n",
    "# train the model\n",
    "trainer.fit(\n",
    "    model=ChronoNetModule,\n",
    "    datamodule=dm \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load checkpoint for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/birdclef/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|| 96/96 [00:04<00:00, 22.68 examples/s]\n"
     ]
    }
   ],
   "source": [
    "## Preparing forecast data\n",
    "\n",
    "## reference for 12.1-predict-data-transform-clean-version.ipynb\n",
    "\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "pred_dir = Path(\"../../data/predict\")\n",
    "pred_files = pred_dir.glob(\"*.ogg\")\n",
    "\n",
    "\n",
    "def read_audio(path: str):\n",
    "    \"\"\"\n",
    "    Read an OGG file using torchaudio and return the waveform tensor and sample rate.\n",
    "\n",
    "    Parameters:\n",
    "        path: Path to the .ogg file\n",
    "\n",
    "    Returns:\n",
    "        waveform: Tensor representing the waveform\n",
    "        sample_rate: Sample rate of the audio file\n",
    "    \"\"\"\n",
    "    audio, sample_rate = torchaudio.load(path)\n",
    "    return audio, sample_rate\n",
    "\n",
    "\n",
    "# Regarding the data of a single audio, some audio information needs to be paid attention to, such as audio duration and number of channels.\n",
    "\n",
    "\n",
    "def audio_info(audio: torch.Tensor, sample_rate: int):\n",
    "    \"\"\"\n",
    "    Grab all information of the input audio loaded by torchaudio.\n",
    "\n",
    "    Parameters:\n",
    "        audio: Tensor representing the waveform\n",
    "        sample_rate: Sample rate of the audio file\n",
    "\n",
    "    Return:\n",
    "        duration_seconds: Duration of the audio in seconds\n",
    "        num_channels: Number of audio channels\n",
    "    \"\"\"\n",
    "    # The audio duration time (seconds)\n",
    "    duration_seconds = audio.shape[1] / sample_rate\n",
    "\n",
    "    # The number of channels\n",
    "    num_channels = audio.shape[0]\n",
    "\n",
    "\n",
    "    return duration_seconds, num_channels\n",
    "\n",
    "\n",
    "def split_audio(audio: torch.Tensor, segment_length:int):\n",
    "\n",
    "    '''\n",
    "    split raw audio tensor into multiple clips with 5 seconds long.\n",
    "\n",
    "    Parameters:\n",
    "        audio: the raw audio tensor\n",
    "        segment_length: the audio length of each 5 seconds\n",
    "\n",
    "    return:\n",
    "        parts: list includes all clips\n",
    "        end_time_list: the list of all clips' end time in seconds\n",
    "    '''\n",
    "\n",
    "    length_audio = audio.shape[1]\n",
    "    parts = []\n",
    "    # For example, if this is the first 5 seconds of audio, then the end time is 5. If it is 5-10 seconds, the end time is 10\n",
    "    end_time_list=[]\n",
    "    end_time=5\n",
    "    for i in range(0, length_audio, segment_length):\n",
    "        part = audio[0][i:i + segment_length]\n",
    "        # if len(part) == segment_length:  # Ensure the fragment lengths are consistent\n",
    "        parts.append(part)  #Store the raw bytes of audio data\n",
    "        end_time_list.append(end_time)\n",
    "        end_time+=5\n",
    "\n",
    "        \n",
    "\n",
    "    return parts,end_time_list\n",
    "\n",
    "\n",
    "\n",
    "audio_clips_list=[]\n",
    "clip_names_list=[]\n",
    "\n",
    "for path in pred_files:\n",
    "    # read audio as tensor\n",
    "    audio,sr=read_audio(path=path)\n",
    "\n",
    "    # get audio corresponding informatino\n",
    "    duration_seconds,num_channels=audio_info(audio=audio,sample_rate=sr)\n",
    "\n",
    "    # split audio into multi clips with 5 seconds\n",
    "    audio_clips,end_time_list=split_audio(audio=audio,segment_length=5*sr)\n",
    "\n",
    "    # generate each label name for each clip\n",
    "    soundscape_id=path.stem\n",
    "    clip_name=[f'soundscape_{soundscape_id}_{end_time}' for end_time in end_time_list]\n",
    "\n",
    "    audio_clips_list.extend(audio_clips)\n",
    "    \n",
    "    clip_names_list.extend(clip_name)\n",
    "\n",
    "    \n",
    "\n",
    "# create Dataset\n",
    "dataset = Dataset.from_dict({'audio_clip': audio_clips_list})\n",
    "\n",
    "\n",
    "# We need to modify melspec so that it can accept batch as a function and use the map function\n",
    "\n",
    "\n",
    "## convert audio to mel spectrogram\n",
    "\n",
    "\n",
    "def mel_transform(batch):\n",
    "    \"\"\"\n",
    "    transform audio data into mel sepctrogram\n",
    "    \"\"\"\n",
    "    n_fft=int(0.04*32000)\n",
    "    # hop_length = int(hop_size * sample_rate)  \n",
    "    hop_length=int(0.02*32000)\n",
    "\n",
    "    n_mels = 40  \n",
    "\n",
    "    mel_transformer = MelSpectrogram(\n",
    "        sample_rate=32000,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "        f_min=0,\n",
    "        f_max=16000\n",
    "    )\n",
    "\n",
    "    audio_clip_batch=batch['audio_clip']\n",
    "\n",
    "    melspec_list=[]\n",
    "\n",
    "    for audio_clip in audio_clip_batch:\n",
    "        \n",
    "        audio_clip=torch.tensor(audio_clip).unsqueeze(0)\n",
    "\n",
    "        melspec=mel_transformer(audio_clip)\n",
    "\n",
    "        melspec_list.append(melspec)\n",
    "\n",
    "\n",
    "    return {'audio_mel':melspec_list}\n",
    "\n",
    "\n",
    "\n",
    "dataset_mel=dataset.map(mel_transform, batched=True)\n",
    "\n",
    "\n",
    "del dataset\n",
    "\n",
    "\n",
    "dataset_mel_single=dataset_mel.remove_columns('audio_clip')\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class PredDataset(Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        super().__init__()\n",
    "        self.dataset=dataset\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        audio_melspec=self.dataset['audio_mel'][index]\n",
    "\n",
    "        audio_tensor=torch.tensor(audio_melspec)\n",
    "\n",
    "        return audio_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load checkpoint\n",
    "model=ChronoNet()\n",
    "model = ChronoNetModule.load_from_checkpoint(\n",
    "    checkpoint_path=\"./checkpoints/chrononet-02-4.41.ckpt\",\n",
    "    model=model,  # Pass additional parameters needed for model initialization if they are not saved in the checkpoint\n",
    "    learning_rate=0.01  # Any other required parameters\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. prepare predicted data\n",
    "PD=PredDataset(dataset=dataset_mel)\n",
    "predict_dataloader = DataLoader(dataset=PD, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/birdclef/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 3/3 [00:11<00:00,  0.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# 3. model prediction\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"gpu\",  \n",
    "    devices=1\n",
    ")\n",
    "\n",
    "# predict using trainer\n",
    "predictions = trainer.predict(model, dataloaders=predict_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061],\n",
       "         [0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061],\n",
       "         [0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061],\n",
       "         ...,\n",
       "         [0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061],\n",
       "         [0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061],\n",
       "         [0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061]]),\n",
       " tensor([[0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061],\n",
       "         [0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061],\n",
       "         [0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061],\n",
       "         ...,\n",
       "         [0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061],\n",
       "         [0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061],\n",
       "         [0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061]]),\n",
       " tensor([[0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061],\n",
       "         [0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061],\n",
       "         [0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061],\n",
       "         ...,\n",
       "         [0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061],\n",
       "         [0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061],\n",
       "         [0.0024, 0.0029, 0.0026,  ..., 0.0006, 0.0007, 0.0061]])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.DataFrame({\n",
    "    'row_id':clip_names_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_1000170626_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_1000170626_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_1000170626_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_1000170626_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_1000170626_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>soundscape_1000389428_220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>soundscape_1000389428_225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>soundscape_1000389428_230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>soundscape_1000389428_235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>soundscape_1000389428_240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       row_id\n",
       "0     soundscape_1000170626_5\n",
       "1    soundscape_1000170626_10\n",
       "2    soundscape_1000170626_15\n",
       "3    soundscape_1000170626_20\n",
       "4    soundscape_1000170626_25\n",
       "..                        ...\n",
       "91  soundscape_1000389428_220\n",
       "92  soundscape_1000389428_225\n",
       "93  soundscape_1000389428_230\n",
       "94  soundscape_1000389428_235\n",
       "95  soundscape_1000389428_240\n",
       "\n",
       "[96 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each tensor to a NumPy array and use them as rows of the DataFrame\n",
    "data_frames = [pd.DataFrame(tensor.numpy()) for tensor in predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all DataFrames into one big DataFrame\n",
    "# Each tensor forms a block of the DataFrame\n",
    "df = pd.concat(data_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4        5         6    \\\n",
       "0   0.002427  0.002863  0.002577  0.000327  0.002349  0.00107  0.001924   \n",
       "1   0.002427  0.002863  0.002577  0.000327  0.002349  0.00107  0.001924   \n",
       "2   0.002427  0.002863  0.002577  0.000327  0.002349  0.00107  0.001924   \n",
       "3   0.002427  0.002863  0.002577  0.000327  0.002349  0.00107  0.001924   \n",
       "4   0.002427  0.002863  0.002577  0.000327  0.002349  0.00107  0.001924   \n",
       "..       ...       ...       ...       ...       ...      ...       ...   \n",
       "91  0.002427  0.002863  0.002577  0.000327  0.002349  0.00107  0.001924   \n",
       "92  0.002427  0.002863  0.002577  0.000327  0.002349  0.00107  0.001924   \n",
       "93  0.002427  0.002863  0.002577  0.000327  0.002349  0.00107  0.001924   \n",
       "94  0.002427  0.002863  0.002577  0.000327  0.002349  0.00107  0.001924   \n",
       "95  0.002427  0.002863  0.002577  0.000327  0.002349  0.00107  0.001924   \n",
       "\n",
       "         7         8         9    ...       150       151      152       153  \\\n",
       "0   0.028795  0.012024  0.000084  ...  0.000466  0.000712  0.01239  0.001746   \n",
       "1   0.028795  0.012024  0.000084  ...  0.000466  0.000712  0.01239  0.001746   \n",
       "2   0.028795  0.012024  0.000084  ...  0.000466  0.000712  0.01239  0.001746   \n",
       "3   0.028795  0.012024  0.000084  ...  0.000466  0.000712  0.01239  0.001746   \n",
       "4   0.028795  0.012024  0.000084  ...  0.000466  0.000712  0.01239  0.001746   \n",
       "..       ...       ...       ...  ...       ...       ...      ...       ...   \n",
       "91  0.028795  0.012024  0.000084  ...  0.000466  0.000712  0.01239  0.001746   \n",
       "92  0.028795  0.012024  0.000084  ...  0.000466  0.000712  0.01239  0.001746   \n",
       "93  0.028795  0.012024  0.000084  ...  0.000466  0.000712  0.01239  0.001746   \n",
       "94  0.028795  0.012024  0.000084  ...  0.000466  0.000712  0.01239  0.001746   \n",
       "95  0.028795  0.012024  0.000084  ...  0.000466  0.000712  0.01239  0.001746   \n",
       "\n",
       "         154       155       156       157       158       159  \n",
       "0   0.002529  0.010009  0.000388  0.000552  0.000695  0.006122  \n",
       "1   0.002529  0.010009  0.000388  0.000552  0.000695  0.006122  \n",
       "2   0.002529  0.010009  0.000388  0.000552  0.000695  0.006121  \n",
       "3   0.002529  0.010009  0.000388  0.000552  0.000695  0.006121  \n",
       "4   0.002529  0.010009  0.000388  0.000552  0.000695  0.006121  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "91  0.002529  0.010009  0.000388  0.000552  0.000695  0.006121  \n",
       "92  0.002529  0.010009  0.000388  0.000552  0.000695  0.006122  \n",
       "93  0.002529  0.010009  0.000388  0.000552  0.000695  0.006122  \n",
       "94  0.002529  0.010009  0.000388  0.000552  0.000695  0.006122  \n",
       "95  0.002529  0.010009  0.000388  0.000552  0.000695  0.006121  \n",
       "\n",
       "[96 rows x 160 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([submission, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_1000170626_5</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_1000170626_10</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_1000170626_15</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_1000170626_20</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_1000170626_25</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>soundscape_1000389428_220</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>soundscape_1000389428_225</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>soundscape_1000389428_230</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>soundscape_1000389428_235</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>soundscape_1000389428_240</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.006121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       row_id         0         1         2         3  \\\n",
       "0     soundscape_1000170626_5  0.002427  0.002863  0.002577  0.000327   \n",
       "1    soundscape_1000170626_10  0.002427  0.002863  0.002577  0.000327   \n",
       "2    soundscape_1000170626_15  0.002427  0.002863  0.002577  0.000327   \n",
       "3    soundscape_1000170626_20  0.002427  0.002863  0.002577  0.000327   \n",
       "4    soundscape_1000170626_25  0.002427  0.002863  0.002577  0.000327   \n",
       "..                        ...       ...       ...       ...       ...   \n",
       "91  soundscape_1000389428_220  0.002427  0.002863  0.002577  0.000327   \n",
       "92  soundscape_1000389428_225  0.002427  0.002863  0.002577  0.000327   \n",
       "93  soundscape_1000389428_230  0.002427  0.002863  0.002577  0.000327   \n",
       "94  soundscape_1000389428_235  0.002427  0.002863  0.002577  0.000327   \n",
       "95  soundscape_1000389428_240  0.002427  0.002863  0.002577  0.000327   \n",
       "\n",
       "           4        5         6         7         8  ...       150       151  \\\n",
       "0   0.002349  0.00107  0.001924  0.028795  0.012024  ...  0.000466  0.000712   \n",
       "1   0.002349  0.00107  0.001924  0.028795  0.012024  ...  0.000466  0.000712   \n",
       "2   0.002349  0.00107  0.001924  0.028795  0.012024  ...  0.000466  0.000712   \n",
       "3   0.002349  0.00107  0.001924  0.028795  0.012024  ...  0.000466  0.000712   \n",
       "4   0.002349  0.00107  0.001924  0.028795  0.012024  ...  0.000466  0.000712   \n",
       "..       ...      ...       ...       ...       ...  ...       ...       ...   \n",
       "91  0.002349  0.00107  0.001924  0.028795  0.012024  ...  0.000466  0.000712   \n",
       "92  0.002349  0.00107  0.001924  0.028795  0.012024  ...  0.000466  0.000712   \n",
       "93  0.002349  0.00107  0.001924  0.028795  0.012024  ...  0.000466  0.000712   \n",
       "94  0.002349  0.00107  0.001924  0.028795  0.012024  ...  0.000466  0.000712   \n",
       "95  0.002349  0.00107  0.001924  0.028795  0.012024  ...  0.000466  0.000712   \n",
       "\n",
       "        152       153       154       155       156       157       158  \\\n",
       "0   0.01239  0.001746  0.002529  0.010009  0.000388  0.000552  0.000695   \n",
       "1   0.01239  0.001746  0.002529  0.010009  0.000388  0.000552  0.000695   \n",
       "2   0.01239  0.001746  0.002529  0.010009  0.000388  0.000552  0.000695   \n",
       "3   0.01239  0.001746  0.002529  0.010009  0.000388  0.000552  0.000695   \n",
       "4   0.01239  0.001746  0.002529  0.010009  0.000388  0.000552  0.000695   \n",
       "..      ...       ...       ...       ...       ...       ...       ...   \n",
       "91  0.01239  0.001746  0.002529  0.010009  0.000388  0.000552  0.000695   \n",
       "92  0.01239  0.001746  0.002529  0.010009  0.000388  0.000552  0.000695   \n",
       "93  0.01239  0.001746  0.002529  0.010009  0.000388  0.000552  0.000695   \n",
       "94  0.01239  0.001746  0.002529  0.010009  0.000388  0.000552  0.000695   \n",
       "95  0.01239  0.001746  0.002529  0.010009  0.000388  0.000552  0.000695   \n",
       "\n",
       "         159  \n",
       "0   0.006122  \n",
       "1   0.006122  \n",
       "2   0.006121  \n",
       "3   0.006121  \n",
       "4   0.006121  \n",
       "..       ...  \n",
       "91  0.006121  \n",
       "92  0.006122  \n",
       "93  0.006122  \n",
       "94  0.006122  \n",
       "95  0.006121  \n",
       "\n",
       "[96 rows x 161 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdclef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
