{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an update of 13.1-data-process-augmentation-with-batch.ipynb\n",
    "\n",
    "Because I want to add mixed audio of different audio clips later, that is, stack multiple audios together, the length remains unchanged, but this audio will contain multiple types of birds.\n",
    "\n",
    "But if I want to do this, I need to modify the output of audio label.\n",
    "\n",
    "This is assuming that I have 182 categories, then I want to change the audiolabel of each data to [1,0,0,0,.....,0,0,0,0] tensor.shape=[182]\n",
    "\n",
    "In this way, if I mix audio, then audio label can also be mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/birdclef/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from typing import List\n",
    "from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
    "\n",
    "import torchaudio\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "import datasets\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader,WeightedRandomSampler\n",
    "\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "import colorednoise as cn\n",
    "import torch.nn as nn\n",
    "import librosa\n",
    "from torch.distributions import Beta\n",
    "from torch_audiomentations import Compose, PitchShift, Shift, OneOf, AddColoredNoise\n",
    "\n",
    "import timm\n",
    "from torchinfo import summary\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path='../../data/train_metadata_new_add_rating.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to interpolate missing values ​​for ratings in metadata csv files\n",
    "\n",
    "def rating_value_interplote(df:pd.DataFrame):\n",
    "    '''\n",
    "    interplote Nan values for rating col in metadata csv \n",
    "\n",
    "    parameters:\n",
    "        df: the df of the metadata csv file\n",
    "\n",
    "    rating col means the quality of the corresponding audio file\n",
    "        5 is high quality\n",
    "        1 is low quality\n",
    "        0 is without defined quality level\n",
    "    '''\n",
    "\n",
    "    if df['rating'].isna().sum()>0: # with missing value\n",
    "        df['rating'].fillna(0, inplace=True)\n",
    "\n",
    "    # For all places where the value is 0, a random value is given, choosing from the specified choices.\n",
    "    mask = df['rating'] == 0  # Create a boolean mask indicating which positions are 0\n",
    "\n",
    "    choices=np.arange(0.5,5.1,0.5).tolist() # [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
    "    random_values = np.random.choice(choices, size=mask.sum())  # Generate random numbers for these 0 values\n",
    "    df.loc[mask, 'rating'] = random_values  # Fill the generated random numbers back into the corresponding positions of the original DataFrame\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the weight of each audio file by rating helps model training\n",
    "def audio_weight(df):\n",
    "    '''\n",
    "    calculate the weight corresponding to each audio file through the rating value\n",
    "\n",
    "    Because each audio has different quality level, we use weight to affect the inportance of each audio in models,\n",
    "    the lower the quality of the audio, the lower the weight\n",
    "    '''\n",
    "    # Through rating, we calculate the credibility of each audio and express it through weight. \n",
    "    # The purpose of this is to improve the model by increasing the weight of high-quality audio and reducing the weight of low-quality audio.\n",
    "    df[\"audio_weight\"] = np.clip(df[\"rating\"] / df[\"rating\"].max(), 0.1, 1.0)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because this is an unbalanced dataset, the amount of data in each category is very different\n",
    "# So I will calculate the weight of each category here\n",
    "# **(-0.5) The purpose is to reduce the relative influence of high-frequency categories and increase the influence of low-frequency categories, \n",
    "# so as to help the model better learn those uncommon categories\n",
    "# The purpose of calculating this is to build a WeightedRandomSampler, so that each time a batch is extracted using dataloader, it is more friendly to data of different categories.\n",
    "def sampling_weight(df)->torch.Tensor:\n",
    "    '''\n",
    "    calculate the sampling weight of each audio file\n",
    "\n",
    "    because this is imbalanced dataset\n",
    "    we hope the category with less data has large probability to be picked.\n",
    "    '''\n",
    "    sample_weights = (df['primary_label'].value_counts() / df['primary_label'].value_counts().sum()) ** (-0.5)\n",
    "\n",
    "    # Map weights to each row of the original data\n",
    "    sample_weights_map = df['primary_label'].map(sample_weights)\n",
    "\n",
    "    # Convert pandas Series to NumPy array\n",
    "    sample_weights_np = sample_weights_map.to_numpy(dtype=np.float32)\n",
    "\n",
    "    # Convert a NumPy array to a PyTorch tensor using torch.from_numpy\n",
    "    sample_weights_tensor = torch.from_numpy(sample_weights_np)\n",
    "\n",
    "    return sample_weights_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.sampler.WeightedRandomSampler at 0x29cbbef80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(metadata_path,header=0)\n",
    "\n",
    "sample_weights_tensor=sampling_weight(df=df)\n",
    "# Here we will build an argument sampler that will be used by the dataloader\n",
    "# It should be noted that the order of weights in the constructed sampler needs to be consistent with the order of data passed into the dataloader, otherwise the weights will not match\n",
    "\n",
    "# Create a sampler based on the newly obtained weight list\n",
    "sampler = WeightedRandomSampler(sample_weights_tensor.type('torch.DoubleTensor'), len(sample_weights_tensor),replacement=True)\n",
    "\n",
    "sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(path: str):\n",
    "    \"\"\"\n",
    "    Read an OGG file using torchaudio and return the waveform tensor and sample rate.\n",
    "\n",
    "    Parameters:\n",
    "        path: Path to the .ogg file\n",
    "\n",
    "    Returns:\n",
    "        waveform: Tensor representing the waveform\n",
    "        sample_rate: Sample rate of the audio file\n",
    "    \"\"\"\n",
    "    audio, sample_rate = torchaudio.load(path)\n",
    "    return audio, sample_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioTransform:\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        self.always_apply = always_apply\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        if self.always_apply:\n",
    "            return self.apply(y)\n",
    "        else:\n",
    "            if np.random.rand() < self.p:\n",
    "                return self.apply(y)\n",
    "            else:\n",
    "                return y\n",
    "\n",
    "    def apply(self, y: np.ndarray):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class CustomCompose:\n",
    "    def __init__(self, transforms: list):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        for trns in self.transforms:\n",
    "            y = trns(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class CustomOneOf:\n",
    "    def __init__(self, transforms: list, p=1.0):\n",
    "        self.transforms = transforms\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        if np.random.rand() < self.p:\n",
    "            n_trns = len(self.transforms)\n",
    "            trns_idx = np.random.choice(n_trns)\n",
    "            trns = self.transforms[trns_idx]\n",
    "            y = trns(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class GaussianNoiseSNR(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, min_snr=5.0, max_snr=40.0, **kwargs):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "        self.min_snr = min_snr\n",
    "        self.max_snr = max_snr\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        snr = np.random.uniform(self.min_snr, self.max_snr)\n",
    "        a_signal = np.sqrt(y**2).max()\n",
    "        a_noise = a_signal / (10 ** (snr / 20))\n",
    "\n",
    "        white_noise = np.random.randn(len(y))\n",
    "        a_white = np.sqrt(white_noise**2).max()\n",
    "        augmented = (y + white_noise * 1 / a_white * a_noise).astype(y.dtype)\n",
    "        return augmented\n",
    "\n",
    "\n",
    "class PinkNoiseSNR(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, min_snr=5.0, max_snr=20.0, **kwargs):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "        self.min_snr = min_snr\n",
    "        self.max_snr = max_snr\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        snr = np.random.uniform(self.min_snr, self.max_snr)\n",
    "        a_signal = np.sqrt(y**2).max()\n",
    "        a_noise = a_signal / (10 ** (snr / 20))\n",
    "\n",
    "        pink_noise = cn.powerlaw_psd_gaussian(1, len(y))\n",
    "        a_pink = np.sqrt(pink_noise**2).max()\n",
    "        augmented = (y + pink_noise * 1 / a_pink * a_noise).astype(y.dtype)\n",
    "        return augmented\n",
    "\n",
    "\n",
    "class VolumeControl(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, db_limit=10, mode=\"uniform\"):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "        assert mode in [\n",
    "            \"uniform\",\n",
    "            \"fade\",\n",
    "            \"fade\",\n",
    "            \"cosine\",\n",
    "            \"sine\",\n",
    "        ], \"`mode` must be one of 'uniform', 'fade', 'cosine', 'sine'\"\n",
    "\n",
    "        self.db_limit = db_limit\n",
    "        self.mode = mode\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        db = np.random.uniform(-self.db_limit, self.db_limit)\n",
    "        if self.mode == \"uniform\":\n",
    "            db_translated = 10 ** (db / 20)\n",
    "        elif self.mode == \"fade\":\n",
    "            lin = np.arange(len(y))[::-1] / (len(y) - 1)\n",
    "            db_translated = 10 ** (db * lin / 20)\n",
    "        elif self.mode == \"cosine\":\n",
    "            cosine = np.cos(np.arange(len(y)) / len(y) * np.pi * 2)\n",
    "            db_translated = 10 ** (db * cosine / 20)\n",
    "        else:\n",
    "            sine = np.sin(np.arange(len(y)) / len(y) * np.pi * 2)\n",
    "            db_translated = 10 ** (db * sine / 20)\n",
    "        augmented = y * db_translated\n",
    "        return augmented\n",
    "\n",
    "\n",
    "class NoiseInjection(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, max_noise_level=0.5, sr=32000):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "        self.noise_level = (0.0, max_noise_level)\n",
    "        self.sr = sr\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        noise_level = np.random.uniform(*self.noise_level)\n",
    "        noise = np.random.randn(len(y))\n",
    "        augmented = (y + noise * noise_level).astype(y.dtype)\n",
    "        return augmented\n",
    "\n",
    "\n",
    "class GaussianNoise(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, min_snr=5, max_snr=20, sr=32000):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "        self.min_snr = min_snr\n",
    "        self.max_snr = max_snr\n",
    "        self.sr = sr\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        snr = np.random.uniform(self.min_snr, self.max_snr)\n",
    "        a_signal = np.sqrt(y**2).max()\n",
    "        a_noise = a_signal / (10 ** (snr / 20))\n",
    "\n",
    "        white_noise = np.random.randn(len(y))\n",
    "        a_white = np.sqrt(white_noise**2).max()\n",
    "        augmented = (y + white_noise * 1 / a_white * a_noise).astype(y.dtype)\n",
    "        return augmented\n",
    "\n",
    "\n",
    "class PinkNoise(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, min_snr=5, max_snr=20, sr=32000):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "        self.min_snr = min_snr\n",
    "        self.max_snr = max_snr\n",
    "        self.sr = sr\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        snr = np.random.uniform(self.min_snr, self.max_snr)\n",
    "        a_signal = np.sqrt(y**2).max()\n",
    "        a_noise = a_signal / (10 ** (snr / 20))\n",
    "\n",
    "        pink_noise = cn.powerlaw_psd_gaussian(1, len(y))\n",
    "        a_pink = np.sqrt(pink_noise**2).max()\n",
    "        augmented = (y + pink_noise * 1 / a_pink * a_noise).astype(y.dtype)\n",
    "        return augmented\n",
    "\n",
    "\n",
    "class TimeStretch(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, max_rate=1, sr=32000):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.max_rate = max_rate\n",
    "        self.sr = sr\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        rate = np.random.uniform(0, self.max_rate)\n",
    "        augmented = librosa.effects.time_stretch(y, rate)\n",
    "        return augmented\n",
    "\n",
    "\n",
    "def _db2float(db: float, amplitude=True):\n",
    "    if amplitude:\n",
    "        return 10 ** (db / 20)\n",
    "    else:\n",
    "        return 10 ** (db / 10)\n",
    "\n",
    "\n",
    "def volume_down(y: np.ndarray, db: float):\n",
    "    \"\"\"\n",
    "    Low level API for decreasing the volume\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: numpy.ndarray\n",
    "        stereo / monaural input audio\n",
    "    db: float\n",
    "        how much decibel to decrease\n",
    "    Returns\n",
    "    -------\n",
    "    applied: numpy.ndarray\n",
    "        audio with decreased volume\n",
    "    \"\"\"\n",
    "    applied = y * _db2float(-db)\n",
    "    return applied\n",
    "\n",
    "\n",
    "def volume_up(y: np.ndarray, db: float):\n",
    "    \"\"\"\n",
    "    Low level API for increasing the volume\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: numpy.ndarray\n",
    "        stereo / monaural input audio\n",
    "    db: float\n",
    "        how much decibel to increase\n",
    "    Returns\n",
    "    -------\n",
    "    applied: numpy.ndarray\n",
    "        audio with increased volume\n",
    "    \"\"\"\n",
    "    applied = y * _db2float(db)\n",
    "    return applied\n",
    "\n",
    "\n",
    "class RandomVolume(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, limit=10):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.limit = limit\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        db = np.random.uniform(-self.limit, self.limit)\n",
    "        if db >= 0:\n",
    "            return volume_up(y, db)\n",
    "        else:\n",
    "            return volume_down(y, db)\n",
    "\n",
    "\n",
    "class CosineVolume(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, limit=10):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.limit = limit\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        db = np.random.uniform(-self.limit, self.limit)\n",
    "        cosine = np.cos(np.arange(len(y)) / len(y) * np.pi * 2)\n",
    "        dbs = _db2float(cosine * db)\n",
    "        return y * dbs\n",
    "\n",
    "\n",
    "class AddGaussianNoise(AudioTransform):\n",
    "    \"\"\"Add gaussian noise to the samples\"\"\"\n",
    "\n",
    "    supports_multichannel = True\n",
    "\n",
    "    def __init__(\n",
    "        self, always_apply=False, min_amplitude=0.001, max_amplitude=0.015, p=0.5\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param min_amplitude: Minimum noise amplification factor\n",
    "        :param max_amplitude: Maximum noise amplification factor\n",
    "        :param p:\n",
    "        \"\"\"\n",
    "        super().__init__(always_apply, p)\n",
    "        assert min_amplitude > 0.0\n",
    "        assert max_amplitude > 0.0\n",
    "        assert max_amplitude >= min_amplitude\n",
    "        self.min_amplitude = min_amplitude\n",
    "        self.max_amplitude = max_amplitude\n",
    "\n",
    "    def apply(self, samples: np.ndarray, sample_rate=32000):\n",
    "        amplitude = np.random.uniform(self.min_amplitude, self.max_amplitude)\n",
    "        noise = np.random.randn(*samples.shape).astype(np.float32)\n",
    "        samples = samples + amplitude * noise\n",
    "        return samples\n",
    "\n",
    "\n",
    "class AddGaussianSNR(AudioTransform):\n",
    "    \"\"\"\n",
    "    Add gaussian noise to the input. A random Signal to Noise Ratio (SNR) will be picked\n",
    "    uniformly in the decibel scale. This aligns with human hearing, which is more\n",
    "    logarithmic than linear.\n",
    "    \"\"\"\n",
    "\n",
    "    supports_multichannel = True\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        always_apply=False,\n",
    "        min_snr_in_db: float = 5.0,\n",
    "        max_snr_in_db: float = 40.0,\n",
    "        p: float = 0.5,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param min_snr_in_db: Minimum signal-to-noise ratio in dB. A lower number means more noise.\n",
    "        :param max_snr_in_db: Maximum signal-to-noise ratio in dB. A greater number means less noise.\n",
    "        :param p: The probability of applying this transform\n",
    "        \"\"\"\n",
    "        super().__init__(always_apply, p)\n",
    "        self.min_snr_in_db = min_snr_in_db\n",
    "        self.max_snr_in_db = max_snr_in_db\n",
    "\n",
    "    def apply(self, samples: np.ndarray, sample_rate=32000):\n",
    "        snr = np.random.uniform(self.min_snr_in_db, self.max_snr_in_db)\n",
    "\n",
    "        clean_rms = np.sqrt(np.mean(np.square(samples)))\n",
    "\n",
    "        a = float(snr) / 20\n",
    "        noise_rms = clean_rms / (10**a)\n",
    "\n",
    "        noise = np.random.normal(0.0, noise_rms, size=samples.shape).astype(np.float32)\n",
    "        return samples + noise\n",
    "\n",
    "\n",
    "class Normalize(AudioTransform):\n",
    "    \"\"\"\n",
    "    Apply a constant amount of gain, so that highest signal level present in the sound becomes\n",
    "    0 dBFS, i.e. the loudest level allowed if all samples must be between -1 and 1. Also known\n",
    "    as peak normalization.\n",
    "    \"\"\"\n",
    "\n",
    "    supports_multichannel = True\n",
    "\n",
    "    def __init__(self, always_apply=False, apply_to: str = \"all\", p: float = 0.5):\n",
    "        super().__init__(always_apply, p)\n",
    "        assert apply_to in (\"all\", \"only_too_loud_sounds\")\n",
    "        self.apply_to = apply_to\n",
    "\n",
    "    def apply(self, samples: np.ndarray, sample_rate=32000):\n",
    "        max_amplitude = np.amax(np.abs(samples))\n",
    "        if self.apply_to == \"only_too_loud_sounds\" and max_amplitude < 1.0:\n",
    "            return samples\n",
    "\n",
    "        if max_amplitude > 0:\n",
    "            return samples / max_amplitude\n",
    "        else:\n",
    "            return samples\n",
    "\n",
    "class NormalizeMelSpec(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, X):\n",
    "        mean = X.mean((1, 2), keepdim=True)\n",
    "        std = X.std((1, 2), keepdim=True)\n",
    "        Xstd = (X - mean) / (std + self.eps)\n",
    "        norm_min, norm_max = Xstd.min(-1)[0].min(-1)[0], Xstd.max(-1)[0].max(-1)[0]\n",
    "        fix_ind = (norm_max - norm_min) > self.eps * torch.ones_like(\n",
    "            (norm_max - norm_min)\n",
    "        )\n",
    "        V = torch.zeros_like(Xstd)\n",
    "        if fix_ind.sum():\n",
    "            V_fix = Xstd[fix_ind]\n",
    "            norm_max_fix = norm_max[fix_ind, None, None]\n",
    "            norm_min_fix = norm_min[fix_ind, None, None]\n",
    "            V_fix = torch.max(\n",
    "                torch.min(V_fix, norm_max_fix),\n",
    "                norm_min_fix,\n",
    "            )\n",
    "            # print(V_fix.shape, norm_min_fix.shape, norm_max_fix.shape)\n",
    "            V_fix = (V_fix - norm_min_fix) / (norm_max_fix - norm_min_fix)\n",
    "            V[fix_ind] = V_fix\n",
    "        return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous content is the same as 13.1-data-process-augmentation-with-batch.ipynb\n",
    "\n",
    "Next, I will add the processing steps for audio labels in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to get all the types\n",
    "meta_df=pd.read_csv(metadata_path,header=0)\n",
    "bird_cates=meta_df.primary_label.unique()\n",
    "\n",
    "#Because the order is very important and needs to be matched one by one in the subsequent training, I will save these types here\n",
    "# Save as .npy file\n",
    "np.save(\"./temp_files/13-2-bird-cates.npy\", bird_cates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malpar1', 'litgre1', 'houspa', 'indrob1', 'comtai1', 'grynig2',\n",
       "       'rufwoo2', 'yebbul3', 'indpit1', 'gyhcaf1', 'ruftre2', 'wynlau1',\n",
       "       'inpher1', 'comkin1', 'comior1', 'tibfly3', 'pomgrp2', 'oripip1',\n",
       "       'indtit1', 'nutman', 'junmyn1', 'rutfly6', 'goflea1', 'litegr',\n",
       "       'lesyel1', 'lewduc1', 'inbrob1', 'crfbar1', 'scamin3', 'shikra1',\n",
       "       'gryfra', 'commoo3', 'grewar3', 'brodro1', 'rocpig', 'categr',\n",
       "       'ingori1', 'plhpar1', 'sbeowl1', 'bwfshr1', 'junowl1', 'orihob2',\n",
       "       'greegr', 'barswa', 'paisto1', 'moipig1', 'plapri1', 'forwag1',\n",
       "       'maghor2', 'brasta1', 'lirplo', 'grecou1', 'kenplo1', 'bkcbul1',\n",
       "       'grbeat1', 'junbab2', 'comsan', 'whbtre1', 'brnhao1', 'brcful1',\n",
       "       'whcbar1', 'hoopoe', 'plaflo1', 'maltro1', 'piekin1', 'brnshr',\n",
       "       'whiter2', 'brfowl1', 'pursun4', 'grehor1', 'pursun3', 'purswa3',\n",
       "       'yebbab1', 'lblwar1', 'malwoo1', 'laudov1', 'grenig1', 'tilwar1',\n",
       "       'heswoo1', 'compea', 'putbab1', 'smamin1', 'rorpar', 'graher1',\n",
       "       'ashpri1', 'piebus1', 'grnwar1', 'eurbla2', 'asikoe2', 'whbwat1',\n",
       "       'sqtbul1', 'brwowl1', 'bncwoo3', 'ashwoo2', 'pabflo1', 'eaywag1',\n",
       "       'ashdro1', 'rerswa1', 'emedov2', 'houcro1', 'btbeat1', 'gargan',\n",
       "       'insowl1', 'bcnher', 'placuc3', 'blaeag1', 'barfly1', 'insbab1',\n",
       "       'rewbul', 'grefla1', 'spoowl1', 'marsan', 'whbsho3', 'kerlau2',\n",
       "       'asiope1', 'redspu1', 'chbeat1', 'blhori1', 'integr', 'zitcis1',\n",
       "       'blakit1', 'grywag', 'crseag1', 'labcro1', 'litspi1', 'spepic1',\n",
       "       'comgre', 'vehpar1', 'gloibi', 'whbwag1', 'jerbus2', 'stbkin1',\n",
       "       'copbar1', 'whtkin2', 'blrwar1', 'rewlap1', 'woosan', 'vefnut1',\n",
       "       'mawthr1', 'isbduc1', 'grtdro1', 'bladro1', 'thbwar1', 'aspswi1',\n",
       "       'aspfly1', 'revbul', 'eucdov', 'asbfly', 'whrmun', 'nilfly2',\n",
       "       'wbbfly1', 'crbsun2', 'commyn', 'purher1', 'bkwsti', 'wemhar1',\n",
       "       'bkskit1', 'litswi1', 'sohmyn1', 'dafbab1', 'eurcoo', 'whbbul2',\n",
       "       'darter2', 'rufbab3', 'whbwoo2', 'sttwoo1', 'gybpri1', 'niwpig1',\n",
       "       'brakit1', 'grnsan', 'grejun2', 'cohcuc1', 'comros', 'brwjac1',\n",
       "       'comfla1', 'spodov', 'blnmon1', 'lobsun2', 'rossta2', 'bkrfla1',\n",
       "       'indrol2', 'cregos1'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_cates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malpar1' 'litgre1' 'houspa' 'indrob1' 'comtai1' 'grynig2' 'rufwoo2'\n",
      " 'yebbul3' 'indpit1' 'gyhcaf1' 'ruftre2' 'wynlau1' 'inpher1' 'comkin1'\n",
      " 'comior1' 'tibfly3' 'pomgrp2' 'oripip1' 'indtit1' 'nutman' 'junmyn1'\n",
      " 'rutfly6' 'goflea1' 'litegr' 'lesyel1' 'lewduc1' 'inbrob1' 'crfbar1'\n",
      " 'scamin3' 'shikra1' 'gryfra' 'commoo3' 'grewar3' 'brodro1' 'rocpig'\n",
      " 'categr' 'ingori1' 'plhpar1' 'sbeowl1' 'bwfshr1' 'junowl1' 'orihob2'\n",
      " 'greegr' 'barswa' 'paisto1' 'moipig1' 'plapri1' 'forwag1' 'maghor2'\n",
      " 'brasta1' 'lirplo' 'grecou1' 'kenplo1' 'bkcbul1' 'grbeat1' 'junbab2'\n",
      " 'comsan' 'whbtre1' 'brnhao1' 'brcful1' 'whcbar1' 'hoopoe' 'plaflo1'\n",
      " 'maltro1' 'piekin1' 'brnshr' 'whiter2' 'brfowl1' 'pursun4' 'grehor1'\n",
      " 'pursun3' 'purswa3' 'yebbab1' 'lblwar1' 'malwoo1' 'laudov1' 'grenig1'\n",
      " 'tilwar1' 'heswoo1' 'compea' 'putbab1' 'smamin1' 'rorpar' 'graher1'\n",
      " 'ashpri1' 'piebus1' 'grnwar1' 'eurbla2' 'asikoe2' 'whbwat1' 'sqtbul1'\n",
      " 'brwowl1' 'bncwoo3' 'ashwoo2' 'pabflo1' 'eaywag1' 'ashdro1' 'rerswa1'\n",
      " 'emedov2' 'houcro1' 'btbeat1' 'gargan' 'insowl1' 'bcnher' 'placuc3'\n",
      " 'blaeag1' 'barfly1' 'insbab1' 'rewbul' 'grefla1' 'spoowl1' 'marsan'\n",
      " 'whbsho3' 'kerlau2' 'asiope1' 'redspu1' 'chbeat1' 'blhori1' 'integr'\n",
      " 'zitcis1' 'blakit1' 'grywag' 'crseag1' 'labcro1' 'litspi1' 'spepic1'\n",
      " 'comgre' 'vehpar1' 'gloibi' 'whbwag1' 'jerbus2' 'stbkin1' 'copbar1'\n",
      " 'whtkin2' 'blrwar1' 'rewlap1' 'woosan' 'vefnut1' 'mawthr1' 'isbduc1'\n",
      " 'grtdro1' 'bladro1' 'thbwar1' 'aspswi1' 'aspfly1' 'revbul' 'eucdov'\n",
      " 'asbfly' 'whrmun' 'nilfly2' 'wbbfly1' 'crbsun2' 'commyn' 'purher1'\n",
      " 'bkwsti' 'wemhar1' 'bkskit1' 'litswi1' 'sohmyn1' 'dafbab1' 'eurcoo'\n",
      " 'whbbul2' 'darter2' 'rufbab3' 'whbwoo2' 'sttwoo1' 'gybpri1' 'niwpig1'\n",
      " 'brakit1' 'grnsan' 'grejun2' 'cohcuc1' 'comros' 'brwjac1' 'comfla1'\n",
      " 'spodov' 'blnmon1' 'lobsun2' 'rossta2' 'bkrfla1' 'indrol2' 'cregos1']\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# load .npy file\n",
    "loaded_array = np.load(\"./temp_files/13-2-bird-cates.npy\",allow_pickle=True)\n",
    "\n",
    "# Print the array contents to verify\n",
    "print(loaded_array)\n",
    "print(type(loaded_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the index of the target value in the array\n",
    "index = np.where(loaded_array == 'gyhcaf1')[0][0]\n",
    "\n",
    "index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.zeros(len(loaded_array))\n",
    "\n",
    "a[9]=1\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdclefDataset(Dataset):\n",
    "    def __init__(self,metadata_path:str,bird_category_dir:str,audio_dir:str='../../data/train_audio'):\n",
    "        '''\n",
    "        parameters:\n",
    "            metadata_path: the directory of the metadata csv file\n",
    "            bird_category_dir: the directory of the bird category array file (npy)\n",
    "            audio_dir: the parent path where all audio files stored\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.raw_df=pd.read_csv(metadata_path,header=0)\n",
    "        # inperplote nan or 0 value of rating col\n",
    "        self.raw_df=rating_value_interplote(df=self.raw_df)\n",
    "        # Calculate the weight of each audio file by rating\n",
    "        self.raw_df=audio_weight(self.raw_df)\n",
    "\n",
    "        self.audio_dir=audio_dir\n",
    "\n",
    "        self.bird_cate_array=np.load(bird_category_dir,allow_pickle=True)\n",
    "\n",
    "    def get_audio_path(self,file_name:str) -> str:\n",
    "        '''\n",
    "        Get the audio path of the corresponding index through the provided train metadata csv file. \n",
    "        Since there is only one index, only one path will be returned.\n",
    "\n",
    "        Parameters:\n",
    "            file_name: in format category_type/XC-ID.ogg (asbfly/XC134896.ogg)\n",
    "\n",
    "        Return:\n",
    "            the single audio path string\n",
    "        '''\n",
    "\n",
    "        # concatenate parent path and child path\n",
    "        return os.path.join(self.audio_dir,file_name)\n",
    "\n",
    "\n",
    "    def target_clip(self,index:int,audio:torch.Tensor,sample_rate:int)->torch.Tensor:\n",
    "        \"\"\"\n",
    "        calculate the index corresponding audio clip \n",
    "\n",
    "        information from the train metadata csv\n",
    "\n",
    "        Parameters:\n",
    "            audio: the raw audio in tensor [num_channels,length]\n",
    "            sample_rate: audio sampling rate\n",
    "        \"\"\"\n",
    "        # Get the audio start time corresponding to index\n",
    "        clip_start_time=self.raw_df['clip_start_time'].iloc[index]\n",
    "        duration_seconds=self.raw_df['duration'].iloc[index]\n",
    "\n",
    "        # define clip length\n",
    "        segment_duration = 5 * sample_rate\n",
    "\n",
    "        # Total number of samples in the waveform\n",
    "        total_samples = audio.shape[1]\n",
    "\n",
    "        if clip_start_time<=duration_seconds:\n",
    "            clip_start_point=clip_start_time*sample_rate\n",
    "            # For the last clip, the original audio may not be long enough, so we need to use a mask to fill the sequence\n",
    "            # The first step is to confirm whether the length is sufficient\n",
    "            # The length is sufficient, no mask is needed\n",
    "            if clip_start_point+segment_duration<=total_samples:\n",
    "                clip=audio[:, clip_start_point:clip_start_point + segment_duration]\n",
    "\n",
    "            # The length is not enough, a mask is required\n",
    "            else:\n",
    "                padding_length = clip_start_point+segment_duration - total_samples\n",
    "                silence = torch.zeros(audio.shape[0], padding_length)\n",
    "                # concat the last part of the raw audio with silence\n",
    "                clip=torch.cat((audio[:,clip_start_point:],silence),dim=1)\n",
    "                \n",
    "        else:\n",
    "            raise ValueError('The clip start time is out of raw audio length')\n",
    "\n",
    "        return clip\n",
    "\n",
    "\n",
    "    def random_audio_augmentation(self,audio:torch.Tensor):\n",
    "        '''\n",
    "        audio (torch.Tensor): A 2D tensor of audio samples with shape (1, N), where N is the number of samples.\n",
    "        '''\n",
    "        np_audio_transforms = CustomCompose(\n",
    "            [\n",
    "                CustomOneOf(\n",
    "                    [\n",
    "                        NoiseInjection(p=1, max_noise_level=0.04),\n",
    "                        GaussianNoise(p=1, min_snr=5, max_snr=20),\n",
    "                        PinkNoise(p=1, min_snr=5, max_snr=20),\n",
    "                        AddGaussianNoise(min_amplitude=0.0001, max_amplitude=0.03, p=0.5),\n",
    "                        AddGaussianSNR(min_snr_in_db=5, max_snr_in_db=15, p=0.5),\n",
    "                    ],\n",
    "                    p=0.3,  \n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        audio_aug=np_audio_transforms(audio[0].numpy())\n",
    "\n",
    "        # tranfer the array to 2D tensor and keep the num channel is 1\n",
    "        # this step is to keep the input and output shape adn type are the same\n",
    "\n",
    "        audio_aug_tensor=torch.from_numpy(audio_aug)\n",
    "        audio_aug_tensor=audio_aug_tensor.unsqueeze(0)\n",
    "\n",
    "        return audio_aug_tensor\n",
    "    \n",
    "\n",
    "    def audio_label_tensor_generator(self,true_label:str)-> torch.Tensor:\n",
    "        '''\n",
    "        Generate a tensor containing all categories based on the given real audio label\n",
    "\n",
    "        Parameters:\n",
    "            true lable: a label string\n",
    "\n",
    "        Return:\n",
    "            If have 10 class, and give a true lable\n",
    "            the return should be tensor([0,1,0,0,0,0,0,0,0,0])\n",
    "        '''\n",
    "        # Find the index of the target value in the array\n",
    "        idx = np.where(loaded_array == true_label)[0][0]\n",
    "        \n",
    "        # Create a tensor of all zeros, with length equal to the length of the array\n",
    "        audio_label_tensor = torch.zeros(len(self.bird_cate_array))\n",
    "\n",
    "        # Set the value of the corresponding index position to 1\n",
    "        audio_label_tensor[idx] = 1\n",
    "\n",
    "        return audio_label_tensor\n",
    "\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.raw_df.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        row=self.raw_df.iloc[index]\n",
    "\n",
    "        audio_label=row['primary_label']\n",
    "        audio_weight=row['audio_weight']\n",
    "\n",
    "        # Get the path of a single audio file\n",
    "        single_audio_dir=self.get_audio_path(row['filename'])\n",
    "\n",
    "        # Read the audio array according to the path\n",
    "        audio, sr=read_audio(single_audio_dir)\n",
    "\n",
    "        # augmentation\n",
    "        audio_augmentation=self.random_audio_augmentation(audio=audio)\n",
    "\n",
    "        # Get the audio clip corresponding to index\n",
    "        clip=self.target_clip(index,audio=audio_augmentation,sample_rate=sr)\n",
    "\n",
    "        # change audio label to one-hot tensor\n",
    "        audio_label_tensor=self.audio_label_tensor_generator(true_label=audio_label)\n",
    "\n",
    "        audio_label_tensor=torch.tensor(audio_label_tensor, dtype=torch.float32)\n",
    "        clip=torch.tensor(clip, dtype=torch.float32)\n",
    "        audio_weight=torch.tensor(audio_weight, dtype=torch.float32)\n",
    "\n",
    "        \n",
    "        return audio_label_tensor,clip,audio_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BD=BirdclefDataset(metadata_path=metadata_path,bird_category_dir=\"./temp_files/13-2-bird-cates.npy\")\n",
    "\n",
    "train_dataloader = DataLoader(dataset=BD, batch_size=32, sampler=sampler, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([32, 182])\n",
      "tensor([[[-2.5385e-01, -2.5273e-01, -2.5611e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.4537e-02,  3.2269e-02,  3.5367e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.2610e-04,  1.9591e-04,  1.3957e-04,  ..., -1.2754e-04,\n",
      "          -1.7877e-04, -1.6762e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.7133e-03, -3.1187e-03,  5.8716e-03,  ...,  4.1194e-03,\n",
      "           6.2594e-03,  5.5284e-03]],\n",
      "\n",
      "        [[-8.9340e-03,  2.0985e-02,  4.7529e-02,  ...,  1.3210e-02,\n",
      "           6.0540e-02,  8.2885e-02]],\n",
      "\n",
      "        [[ 7.2077e-03,  3.4099e-03,  1.9629e-03,  ..., -5.2462e-03,\n",
      "          -1.3889e-02, -1.6666e-02]]])\n",
      "torch.Size([32, 1, 160000])\n",
      "tensor([0.8000, 0.7000, 0.2000, 0.6000, 0.8000, 1.0000, 1.0000, 1.0000, 0.8000,\n",
      "        0.8000, 0.6000, 0.7000, 1.0000, 1.0000, 0.8000, 0.6000, 1.0000, 0.8000,\n",
      "        0.8000, 1.0000, 0.5000, 0.8000, 0.8000, 0.8000, 0.8000, 0.5000, 0.6000,\n",
      "        0.5000, 0.8000, 0.9000, 0.8000, 0.7000])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "audio_label,clip,audio_weights = batch\n",
    "print(audio_label)\n",
    "print(type(audio_label))\n",
    "print(audio_label.shape)\n",
    "print(clip)\n",
    "print(clip.shape)\n",
    "print(audio_weights)\n",
    "print(audio_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_label[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After completing the update of the audio label, I need to complete the audio mixing step for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixup(nn.Module):\n",
    "    def __init__(self, mix_beta, mixup_prob, mixup_double):\n",
    "        super(Mixup, self).__init__()\n",
    "        self.beta_distribution = Beta(mix_beta, mix_beta)\n",
    "        self.mixup_prob = mixup_prob\n",
    "        self.mixup_double = mixup_double\n",
    "\n",
    "    def forward(self, X, Y, weight=None):\n",
    "        p = torch.rand((1,))[0] # Generate a random number p and compare it with mixup_prob to decide whether to mix.\n",
    "        if p < self.mixup_prob:\n",
    "            bs = X.shape[0] # batch size\n",
    "            n_dims = len(X.shape)\n",
    "            perm = torch.randperm(bs) # Generate a random permutation for randomly selecting samples from the current batch for mixing.\n",
    "\n",
    "            p1 = torch.rand((1,))[0] # If the random number p1 (determines whether to perform double mixing) is less than mixup_double, perform a single mix. Otherwise, perform double mixing:\n",
    "            if p1 < self.mixup_double:\n",
    "                X = X + X[perm]\n",
    "                Y = Y + Y[perm]\n",
    "                Y = torch.clamp(Y, 0, 1) # Use torch.clamp to clamp the values ​​of Y between 0 and 1 (suitable for probabilistic or binary labels).\n",
    "\n",
    "                if weight is None:\n",
    "                    return X, Y\n",
    "                else:\n",
    "                    weight = 0.5 * weight + 0.5 * weight[perm]\n",
    "                    return X, Y, weight\n",
    "            else:\n",
    "                perm2 = torch.randperm(bs)\n",
    "                X = X + X[perm] + X[perm2]\n",
    "                Y = Y + Y[perm] + Y[perm2]\n",
    "                Y = torch.clamp(Y, 0, 1)\n",
    "\n",
    "                if weight is None:\n",
    "                    return X, Y\n",
    "                else:\n",
    "                    weight = (\n",
    "                        1 / 3 * weight + 1 / 3 * weight[perm] + 1 / 3 * weight[perm2]\n",
    "                    )\n",
    "                    return X, Y, weight\n",
    "        else:\n",
    "            if weight is None:\n",
    "                return X, Y\n",
    "            else:\n",
    "                return X, Y, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup = Mixup(mix_beta=5,mixup_prob=0.7,mixup_double=0.5)\n",
    "\n",
    "clip2, audio_label2,audio_weights2=mixup(X=clip,Y=audio_label,weight=audio_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2086, -0.1543, -0.1756,  ..., -0.0482, -0.0108,  0.0306]],\n",
      "\n",
      "        [[ 0.0445,  0.0647,  0.0697,  ..., -0.0068, -0.0083, -0.0079]],\n",
      "\n",
      "        [[-0.0051, -0.0199,  0.0076,  ...,  0.0051, -0.0060,  0.0104]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0493,  0.0224, -0.0208,  ...,  0.0076,  0.0044, -0.0039]],\n",
      "\n",
      "        [[ 0.0587,  0.0666,  0.0812,  ..., -0.0239,  0.1142,  0.1555]],\n",
      "\n",
      "        [[-0.2373, -0.1934, -0.1899,  ..., -0.0416, -0.0322, -0.0106]]])\n",
      "torch.Size([32, 1, 160000])\n"
     ]
    }
   ],
   "source": [
    "print(clip2)\n",
    "print(clip2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([32, 182])\n"
     ]
    }
   ],
   "source": [
    "print(audio_label2)\n",
    "print(audio_label2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(audio_label2[0])\n",
    "print(audio_label2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Compose to combine multiple audio transformation operations. These operations are applied to the input audio data to enhance the generalization and robustness of the model.\n",
    "\n",
    "This helps the model learn how to process audio with different pitches and time offsets, and enhances the model's ability to recognize audio data in different environments and conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_transforms = Compose(\n",
    "            [\n",
    "                # AddColoredNoise(p=0.5),\n",
    "                PitchShift(\n",
    "                    min_transpose_semitones=-4,\n",
    "                    max_transpose_semitones=4,\n",
    "                    sample_rate=32000,\n",
    "                    p=0.4,\n",
    "                ),\n",
    "                Shift(min_shift=-0.5, max_shift=0.5, p=0.4),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "clip3=audio_transforms(clip2,sample_rate=32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1824, -0.1687, -0.1614,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0088, -0.0056, -0.0065,  ..., -0.0182, -0.0152, -0.0106]],\n",
      "\n",
      "        [[-0.0152, -0.0144, -0.0030,  ..., -0.0122, -0.0156, -0.0015]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0493,  0.0224, -0.0208,  ...,  0.0076,  0.0044, -0.0039]],\n",
      "\n",
      "        [[-0.0176,  0.0132,  0.0423,  ..., -0.0548, -0.0536, -0.0306]],\n",
      "\n",
      "        [[-0.2373, -0.1934, -0.1899,  ..., -0.0416, -0.0322, -0.0106]]])\n",
      "torch.Size([32, 1, 160000])\n"
     ]
    }
   ],
   "source": [
    "print(clip3)\n",
    "\n",
    "print(clip3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After mixup, mel spec operation is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert audio data into mel spectrogram\n",
    "\n",
    "\n",
    "def mel_transform(sample_rate:float,audio:torch.Tensor,window_size: float=0.04,hop_size:float=0.02,n_mels:int=40)->torch.Tensor:\n",
    "    \"\"\"\n",
    "    transform audio data into mel sepctrogram\n",
    "    \"\"\"\n",
    "    n_fft = int(window_size * sample_rate)  \n",
    "    hop_length = int(hop_size * sample_rate)  \n",
    "\n",
    "    # Calculate Mel Spectrogram\n",
    "    # n_mels = 40 # Number of Mel filters\n",
    "\n",
    "    # Set up Mel Spectrogram converter\n",
    "    mel_transformer = MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "        f_min=0,\n",
    "        f_max=16000\n",
    "    )\n",
    "\n",
    "    melspec=mel_transformer(audio)\n",
    "\n",
    "    return melspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip4=mel_transform(sample_rate=32000,audio=clip3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[2.9909e+03, 9.7385e+02, 1.6147e+03,  ..., 5.8038e-01,\n",
      "           9.2708e-01, 1.2047e+00],\n",
      "          [8.2873e+00, 5.4697e-01, 6.4207e+00,  ..., 3.0296e-01,\n",
      "           4.2942e-01, 1.6211e+00],\n",
      "          [1.2902e-01, 5.0722e-02, 1.1639e-01,  ..., 6.4557e-01,\n",
      "           3.4999e-01, 1.2016e+00],\n",
      "          ...,\n",
      "          [5.4295e-02, 7.3266e-03, 5.2465e-02,  ..., 3.2567e-03,\n",
      "           2.4021e-03, 7.3107e-02],\n",
      "          [2.6392e-02, 3.2367e-03, 2.2114e-02,  ..., 2.1022e-03,\n",
      "           1.4728e-03, 1.4756e-02],\n",
      "          [6.0133e-02, 8.4195e-04, 1.9565e-03,  ..., 1.5346e-03,\n",
      "           1.1414e-03, 9.5083e-03]]],\n",
      "\n",
      "\n",
      "        [[[4.7839e+01, 3.2372e+01, 3.0774e+01,  ..., 2.1115e+01,\n",
      "           1.7425e+01, 8.9048e+01],\n",
      "          [4.3204e+01, 5.7600e+01, 5.6757e+01,  ..., 3.1537e+01,\n",
      "           3.6056e+01, 2.6504e+01],\n",
      "          [1.3618e+01, 4.1824e+01, 1.3072e+01,  ..., 2.2552e+01,\n",
      "           1.0491e+01, 1.5789e+01],\n",
      "          ...,\n",
      "          [6.0389e-02, 5.4137e-02, 5.7484e-02,  ..., 4.7368e-02,\n",
      "           6.4210e-02, 4.1942e-02],\n",
      "          [3.8451e-02, 3.9962e-02, 4.2439e-02,  ..., 4.4921e-02,\n",
      "           4.8391e-02, 5.6807e-02],\n",
      "          [1.6806e-02, 1.4016e-02, 1.7653e-02,  ..., 1.1948e-02,\n",
      "           1.9923e-02, 1.6014e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.9346e+00, 1.3484e+00, 7.6571e+00,  ..., 7.6678e+00,\n",
      "           2.2013e+00, 8.0449e+00],\n",
      "          [5.5113e+00, 9.3025e+00, 8.3595e+00,  ..., 5.6321e+00,\n",
      "           4.1762e+00, 4.7234e+00],\n",
      "          [1.6553e+00, 7.5093e+00, 3.9227e+00,  ..., 8.7051e-01,\n",
      "           1.7973e+00, 9.0499e-01],\n",
      "          ...,\n",
      "          [1.2842e+00, 1.3553e+00, 1.5190e+00,  ..., 1.6632e+00,\n",
      "           1.9247e+00, 1.4753e+00],\n",
      "          [1.2427e+00, 1.5167e+00, 1.3826e+00,  ..., 1.4562e+00,\n",
      "           1.7037e+00, 1.3520e+00],\n",
      "          [1.9759e+00, 1.8839e+00, 1.8427e+00,  ..., 1.6789e+00,\n",
      "           1.9568e+00, 1.6550e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[8.8611e-01, 1.9875e+00, 9.5789e+00,  ..., 3.8362e+00,\n",
      "           1.0075e+01, 3.3664e+00],\n",
      "          [1.1040e+00, 4.9455e+00, 4.4499e+00,  ..., 2.9834e+00,\n",
      "           2.9579e+00, 1.4789e+00],\n",
      "          [3.7153e+00, 2.9618e+00, 7.9623e-01,  ..., 4.4299e-01,\n",
      "           5.9629e-01, 1.3029e+00],\n",
      "          ...,\n",
      "          [8.7578e-01, 1.4579e+00, 3.2444e-01,  ..., 2.4921e-02,\n",
      "           2.1755e-02, 2.1834e-02],\n",
      "          [4.1217e-02, 1.0812e-01, 1.8191e-01,  ..., 3.1836e-02,\n",
      "           3.7350e-02, 3.1874e-02],\n",
      "          [4.2873e-02, 7.1133e-02, 8.3172e-02,  ..., 3.8000e-02,\n",
      "           3.7715e-02, 3.6737e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.0662e-01, 6.7259e-02, 1.9364e-02,  ..., 2.1621e-02,\n",
      "           3.6157e-02, 3.3985e-02],\n",
      "          [4.0406e-02, 1.0313e-01, 5.6326e-02,  ..., 2.4850e-02,\n",
      "           1.0214e-01, 1.1594e-01],\n",
      "          [8.4841e-02, 1.6581e-01, 1.1230e-01,  ..., 9.8027e-02,\n",
      "           2.1350e-01, 8.9917e-02],\n",
      "          ...,\n",
      "          [3.6573e-01, 3.6611e-01, 5.7523e-01,  ..., 4.3350e-01,\n",
      "           3.3152e-01, 4.4394e-01],\n",
      "          [1.2747e-01, 1.2722e-01, 2.0763e-01,  ..., 1.5357e-01,\n",
      "           1.3142e-01, 1.6574e-01],\n",
      "          [4.7646e-02, 3.3236e-02, 3.6086e-02,  ..., 3.2221e-02,\n",
      "           3.2557e-02, 3.7581e-02]]],\n",
      "\n",
      "\n",
      "        [[[3.7808e+03, 1.2828e+03, 7.3685e+03,  ..., 3.2968e+01,\n",
      "           1.4545e+01, 2.5162e+00],\n",
      "          [4.3129e+01, 1.9368e+01, 3.4684e+01,  ..., 1.9958e+01,\n",
      "           1.3530e+01, 3.5916e+00],\n",
      "          [2.4697e+00, 4.8697e+00, 7.2434e+00,  ..., 1.5706e+01,\n",
      "           6.8496e+00, 1.1261e+00],\n",
      "          ...,\n",
      "          [3.2294e-01, 9.1987e-02, 8.9469e-02,  ..., 6.0827e-02,\n",
      "           3.5659e-02, 5.1346e-02],\n",
      "          [1.1347e+00, 8.0978e-01, 1.5962e-01,  ..., 3.7696e-02,\n",
      "           4.2994e-02, 6.0531e-02],\n",
      "          [2.8791e+00, 1.2406e+00, 2.2131e-01,  ..., 1.7858e-02,\n",
      "           2.7894e-02, 2.7697e-02]]]])\n",
      "torch.Size([32, 1, 40, 251])\n"
     ]
    }
   ],
   "source": [
    "print(clip4)\n",
    "print(clip4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert the amplitude of Mel Spectrogram to decibel (Decibel, dB)\n",
    "\n",
    "db_transform = torchaudio.transforms.AmplitudeToDB(stype=\"power\", top_db=80)\n",
    "\n",
    "clip5=db_transform(clip4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 34.7580,  29.8849,  32.0809,  ...,  -2.3629,  -0.3288,   0.8089],\n",
      "          [  9.1842,  -2.6203,   8.0758,  ...,  -5.1862,  -3.6712,   2.0982],\n",
      "          [ -8.8934, -12.9480,  -9.3409,  ...,  -1.9005,  -4.5595,   0.7976],\n",
      "          ...,\n",
      "          [-12.6524, -21.3510, -12.8013,  ..., -24.8722, -26.1940, -11.3604],\n",
      "          [-15.7853, -24.8990, -16.5532,  ..., -26.7733, -28.3186, -18.3103],\n",
      "          [-12.2089, -30.7471, -27.0853,  ..., -28.1400, -29.4255, -20.2190]]],\n",
      "\n",
      "\n",
      "        [[[ 16.7978,  15.1017,  14.8819,  ...,  13.2459,  12.4118,  19.4962],\n",
      "          [ 16.3553,  17.6042,  17.5402,  ...,  14.9881,  15.5697,  14.2330],\n",
      "          [ 11.3412,  16.2143,  11.1634,  ...,  13.5319,  10.2081,  11.9835],\n",
      "          ...,\n",
      "          [-12.1904, -12.6650, -12.4046,  ..., -13.2452, -11.9240, -13.7735],\n",
      "          [-14.1509, -13.9835, -13.7224,  ..., -13.4755, -13.1523, -12.4560],\n",
      "          [-17.7454, -18.5337, -17.5318,  ..., -19.2270, -17.0064, -17.9550]]],\n",
      "\n",
      "\n",
      "        [[[  2.8658,   1.2980,   8.8406,  ...,   8.8467,   3.4268,   9.0552],\n",
      "          [  7.4126,   9.6860,   9.2218,  ...,   7.5067,   6.2078,   6.7426],\n",
      "          [  2.1886,   8.7560,   5.9359,  ...,  -0.6023,   2.5461,  -0.4336],\n",
      "          ...,\n",
      "          [  1.0862,   1.3204,   1.8156,  ...,   2.2095,   2.8436,   1.6889],\n",
      "          [  0.9436,   1.8091,   1.4068,  ...,   1.6321,   2.3139,   1.3098],\n",
      "          [  2.9576,   2.7506,   2.6545,  ...,   2.2504,   2.9155,   2.1881]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -0.5251,   2.9830,   9.8132,  ...,   5.8390,  10.0326,   5.2717],\n",
      "          [  0.4296,   6.9421,   6.4835,  ...,   4.7471,   4.7099,   1.6994],\n",
      "          [  5.6999,   4.7155,  -0.9896,  ...,  -3.5360,  -2.2454,   1.1492],\n",
      "          ...,\n",
      "          [ -0.5761,   1.6374,  -4.8887,  ..., -16.0343, -16.6245, -16.6086],\n",
      "          [-13.8492,  -9.6608,  -7.4015,  ..., -14.9708, -14.2771, -14.9656],\n",
      "          [-13.6781, -11.4793, -10.8003,  ..., -14.2021, -14.2349, -14.3490]]],\n",
      "\n",
      "\n",
      "        [[[ -9.7216, -11.7225, -17.1301,  ..., -16.6512, -14.4180, -14.6871],\n",
      "          [-13.9356,  -9.8661, -12.4929,  ..., -16.0467,  -9.9078,  -9.3576],\n",
      "          [-10.7139,  -7.8040,  -9.4962,  ..., -10.0866,  -6.7060, -10.4616],\n",
      "          ...,\n",
      "          [ -4.3684,  -4.3639,  -2.4016,  ...,  -3.6301,  -4.7949,  -3.5268],\n",
      "          [ -8.9459,  -8.9546,  -6.8272,  ...,  -8.1369,  -8.8134,  -7.8058],\n",
      "          [-13.2197, -14.7839, -14.4267,  ..., -14.9187, -14.8735, -14.2504]]],\n",
      "\n",
      "\n",
      "        [[[ 35.7758,  31.0815,  38.6738,  ...,  15.1810,  11.6270,   4.0074],\n",
      "          [ 16.3477,  12.8708,  15.4013,  ...,  13.0011,  11.3129,   5.5529],\n",
      "          [  3.9264,   6.8750,   8.5994,  ...,  11.9606,   8.3567,   0.5159],\n",
      "          ...,\n",
      "          [ -4.9088, -10.3628, -10.4833,  ..., -12.1590, -14.4784, -12.8949],\n",
      "          [  0.5486,  -0.9163,  -7.9690,  ..., -14.2370, -13.6659, -12.1802],\n",
      "          [  4.5926,   0.9365,  -6.5501,  ..., -17.4816, -15.5449, -15.5756]]]])\n",
      "torch.Size([32, 1, 40, 251])\n"
     ]
    }
   ],
   "source": [
    "print(clip5)\n",
    "print(clip5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip6=(clip5+80)/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.4345, 1.3736, 1.4010,  ..., 0.9705, 0.9959, 1.0101],\n",
      "          [1.1148, 0.9672, 1.1009,  ..., 0.9352, 0.9541, 1.0262],\n",
      "          [0.8888, 0.8381, 0.8832,  ..., 0.9762, 0.9430, 1.0100],\n",
      "          ...,\n",
      "          [0.8418, 0.7331, 0.8400,  ..., 0.6891, 0.6726, 0.8580],\n",
      "          [0.8027, 0.6888, 0.7931,  ..., 0.6653, 0.6460, 0.7711],\n",
      "          [0.8474, 0.6157, 0.6614,  ..., 0.6483, 0.6322, 0.7473]]],\n",
      "\n",
      "\n",
      "        [[[1.2100, 1.1888, 1.1860,  ..., 1.1656, 1.1551, 1.2437],\n",
      "          [1.2044, 1.2201, 1.2193,  ..., 1.1874, 1.1946, 1.1779],\n",
      "          [1.1418, 1.2027, 1.1395,  ..., 1.1691, 1.1276, 1.1498],\n",
      "          ...,\n",
      "          [0.8476, 0.8417, 0.8449,  ..., 0.8344, 0.8510, 0.8278],\n",
      "          [0.8231, 0.8252, 0.8285,  ..., 0.8316, 0.8356, 0.8443],\n",
      "          [0.7782, 0.7683, 0.7809,  ..., 0.7597, 0.7874, 0.7756]]],\n",
      "\n",
      "\n",
      "        [[[1.0358, 1.0162, 1.1105,  ..., 1.1106, 1.0428, 1.1132],\n",
      "          [1.0927, 1.1211, 1.1153,  ..., 1.0938, 1.0776, 1.0843],\n",
      "          [1.0274, 1.1094, 1.0742,  ..., 0.9925, 1.0318, 0.9946],\n",
      "          ...,\n",
      "          [1.0136, 1.0165, 1.0227,  ..., 1.0276, 1.0355, 1.0211],\n",
      "          [1.0118, 1.0226, 1.0176,  ..., 1.0204, 1.0289, 1.0164],\n",
      "          [1.0370, 1.0344, 1.0332,  ..., 1.0281, 1.0364, 1.0274]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.9934, 1.0373, 1.1227,  ..., 1.0730, 1.1254, 1.0659],\n",
      "          [1.0054, 1.0868, 1.0810,  ..., 1.0593, 1.0589, 1.0212],\n",
      "          [1.0712, 1.0589, 0.9876,  ..., 0.9558, 0.9719, 1.0144],\n",
      "          ...,\n",
      "          [0.9928, 1.0205, 0.9389,  ..., 0.7996, 0.7922, 0.7924],\n",
      "          [0.8269, 0.8792, 0.9075,  ..., 0.8129, 0.8215, 0.8129],\n",
      "          [0.8290, 0.8565, 0.8650,  ..., 0.8225, 0.8221, 0.8206]]],\n",
      "\n",
      "\n",
      "        [[[0.8785, 0.8535, 0.7859,  ..., 0.7919, 0.8198, 0.8164],\n",
      "          [0.8258, 0.8767, 0.8438,  ..., 0.7994, 0.8762, 0.8830],\n",
      "          [0.8661, 0.9024, 0.8813,  ..., 0.8739, 0.9162, 0.8692],\n",
      "          ...,\n",
      "          [0.9454, 0.9455, 0.9700,  ..., 0.9546, 0.9401, 0.9559],\n",
      "          [0.8882, 0.8881, 0.9147,  ..., 0.8983, 0.8898, 0.9024],\n",
      "          [0.8348, 0.8152, 0.8197,  ..., 0.8135, 0.8141, 0.8219]]],\n",
      "\n",
      "\n",
      "        [[[1.4472, 1.3885, 1.4834,  ..., 1.1898, 1.1453, 1.0501],\n",
      "          [1.2043, 1.1609, 1.1925,  ..., 1.1625, 1.1414, 1.0694],\n",
      "          [1.0491, 1.0859, 1.1075,  ..., 1.1495, 1.1045, 1.0064],\n",
      "          ...,\n",
      "          [0.9386, 0.8705, 0.8690,  ..., 0.8480, 0.8190, 0.8388],\n",
      "          [1.0069, 0.9885, 0.9004,  ..., 0.8220, 0.8292, 0.8477],\n",
      "          [1.0574, 1.0117, 0.9181,  ..., 0.7815, 0.8057, 0.8053]]]])\n",
      "torch.Size([32, 1, 40, 251])\n"
     ]
    }
   ],
   "source": [
    "print(clip6)\n",
    "print(clip6.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random mask part of the spectrogram, which helps the model learn to be robust to missing information in certain time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_mask_transform = torchaudio.transforms.TimeMasking(time_mask_param=20, iid_masks=True, p=0.3)\n",
    "\n",
    "clip7 = time_mask_transform(clip6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.4345, 1.3736, 1.4010,  ..., 0.9705, 0.9959, 1.0101],\n",
      "          [1.1148, 0.9672, 1.1009,  ..., 0.9352, 0.9541, 1.0262],\n",
      "          [0.8888, 0.8381, 0.8832,  ..., 0.9762, 0.9430, 1.0100],\n",
      "          ...,\n",
      "          [0.8418, 0.7331, 0.8400,  ..., 0.6891, 0.6726, 0.8580],\n",
      "          [0.8027, 0.6888, 0.7931,  ..., 0.6653, 0.6460, 0.7711],\n",
      "          [0.8474, 0.6157, 0.6614,  ..., 0.6483, 0.6322, 0.7473]]],\n",
      "\n",
      "\n",
      "        [[[1.2100, 1.1888, 1.1860,  ..., 1.1656, 1.1551, 1.2437],\n",
      "          [1.2044, 1.2201, 1.2193,  ..., 1.1874, 1.1946, 1.1779],\n",
      "          [1.1418, 1.2027, 1.1395,  ..., 1.1691, 1.1276, 1.1498],\n",
      "          ...,\n",
      "          [0.8476, 0.8417, 0.8449,  ..., 0.8344, 0.8510, 0.8278],\n",
      "          [0.8231, 0.8252, 0.8285,  ..., 0.8316, 0.8356, 0.8443],\n",
      "          [0.7782, 0.7683, 0.7809,  ..., 0.7597, 0.7874, 0.7756]]],\n",
      "\n",
      "\n",
      "        [[[1.0358, 1.0162, 1.1105,  ..., 1.1106, 1.0428, 1.1132],\n",
      "          [1.0927, 1.1211, 1.1153,  ..., 1.0938, 1.0776, 1.0843],\n",
      "          [1.0274, 1.1094, 1.0742,  ..., 0.9925, 1.0318, 0.9946],\n",
      "          ...,\n",
      "          [1.0136, 1.0165, 1.0227,  ..., 1.0276, 1.0355, 1.0211],\n",
      "          [1.0118, 1.0226, 1.0176,  ..., 1.0204, 1.0289, 1.0164],\n",
      "          [1.0370, 1.0344, 1.0332,  ..., 1.0281, 1.0364, 1.0274]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.9934, 1.0373, 1.1227,  ..., 1.0730, 1.1254, 1.0659],\n",
      "          [1.0054, 1.0868, 1.0810,  ..., 1.0593, 1.0589, 1.0212],\n",
      "          [1.0712, 1.0589, 0.9876,  ..., 0.9558, 0.9719, 1.0144],\n",
      "          ...,\n",
      "          [0.9928, 1.0205, 0.9389,  ..., 0.7996, 0.7922, 0.7924],\n",
      "          [0.8269, 0.8792, 0.9075,  ..., 0.8129, 0.8215, 0.8129],\n",
      "          [0.8290, 0.8565, 0.8650,  ..., 0.8225, 0.8221, 0.8206]]],\n",
      "\n",
      "\n",
      "        [[[0.8785, 0.8535, 0.7859,  ..., 0.7919, 0.8198, 0.8164],\n",
      "          [0.8258, 0.8767, 0.8438,  ..., 0.7994, 0.8762, 0.8830],\n",
      "          [0.8661, 0.9024, 0.8813,  ..., 0.8739, 0.9162, 0.8692],\n",
      "          ...,\n",
      "          [0.9454, 0.9455, 0.9700,  ..., 0.9546, 0.9401, 0.9559],\n",
      "          [0.8882, 0.8881, 0.9147,  ..., 0.8983, 0.8898, 0.9024],\n",
      "          [0.8348, 0.8152, 0.8197,  ..., 0.8135, 0.8141, 0.8219]]],\n",
      "\n",
      "\n",
      "        [[[1.4472, 1.3885, 1.4834,  ..., 1.1898, 1.1453, 1.0501],\n",
      "          [1.2043, 1.1609, 1.1925,  ..., 1.1625, 1.1414, 1.0694],\n",
      "          [1.0491, 1.0859, 1.1075,  ..., 1.1495, 1.1045, 1.0064],\n",
      "          ...,\n",
      "          [0.9386, 0.8705, 0.8690,  ..., 0.8480, 0.8190, 0.8388],\n",
      "          [1.0069, 0.9885, 0.9004,  ..., 0.8220, 0.8292, 0.8477],\n",
      "          [1.0574, 1.0117, 0.9181,  ..., 0.7815, 0.8057, 0.8053]]]])\n",
      "torch.Size([32, 1, 40, 251])\n"
     ]
    }
   ],
   "source": [
    "print(clip7)\n",
    "print(clip7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the first and second order differences of audio or other time series data, usually called delta and delta-delta (also called acceleration) features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_deltas(\n",
    "    specgram: torch.Tensor, win_length: int = 5, mode: str = \"replicate\"\n",
    ") -> torch.Tensor:\n",
    "    r\"\"\"Compute delta coefficients of a tensor, usually a spectrogram:\n",
    "\n",
    "    .. math::\n",
    "       d_t = \\frac{\\sum_{n=1}^{\\text{N}} n (c_{t+n} - c_{t-n})}{2 \\sum_{n=1}^{\\text{N}} n^2}\n",
    "\n",
    "    where :math:`d_t` is the deltas at time :math:`t`,\n",
    "    :math:`c_t` is the spectrogram coeffcients at time :math:`t`,\n",
    "    :math:`N` is ``(win_length-1)//2``.\n",
    "\n",
    "    Args:\n",
    "        specgram (Tensor): Tensor of audio of dimension (..., freq, time)\n",
    "        win_length (int, optional): The window length used for computing delta (Default: ``5``)\n",
    "        mode (str, optional): Mode parameter passed to padding (Default: ``\"replicate\"``)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Tensor of deltas of dimension (..., freq, time)\n",
    "\n",
    "    Example\n",
    "        >>> specgram = torch.randn(1, 40, 1000)\n",
    "        >>> delta = compute_deltas(specgram)\n",
    "        >>> delta2 = compute_deltas(delta)\n",
    "    \"\"\"\n",
    "    device = specgram.device\n",
    "    print(device)\n",
    "    dtype = specgram.dtype\n",
    "\n",
    "    # pack batch\n",
    "    shape = specgram.size()\n",
    "    specgram = specgram.reshape(1, -1, shape[-1])\n",
    "\n",
    "    assert win_length >= 3\n",
    "\n",
    "    n = (win_length - 1) // 2\n",
    "\n",
    "    # twice sum of integer squared\n",
    "    denom = n * (n + 1) * (2 * n + 1) / 3\n",
    "\n",
    "    specgram = torch.nn.functional.pad(specgram, (n, n), mode=mode)\n",
    "\n",
    "    kernel = torch.arange(-n, n + 1, 1, device=device, dtype=dtype).repeat(\n",
    "        specgram.shape[1], 1, 1\n",
    "    )\n",
    "\n",
    "    output = (\n",
    "        torch.nn.functional.conv1d(specgram, kernel, groups=specgram.shape[1]) / denom\n",
    "    )\n",
    "\n",
    "    # unpack batch\n",
    "    output = output.reshape(shape)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def make_delta(input_tensor: torch.Tensor):\n",
    "    input_tensor = input_tensor.transpose(3, 2)\n",
    "    input_tensor = compute_deltas(input_tensor)\n",
    "    input_tensor = input_tensor.transpose(3, 2)\n",
    "    return input_tensor\n",
    "\n",
    "\n",
    "def image_delta(x):\n",
    "    delta_1 = make_delta(x)\n",
    "    delta_2 = make_delta(delta_1)\n",
    "    x = torch.cat([x, delta_1, delta_2], dim=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "clip8= image_delta(clip7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 40, 251])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clip8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixup2(nn.Module):\n",
    "    def __init__(self, mix_beta, mixup2_prob):\n",
    "        super(Mixup2, self).__init__()\n",
    "        self.beta_distribution = Beta(mix_beta, mix_beta)\n",
    "        self.mixup2_prob = mixup2_prob\n",
    "\n",
    "    def forward(self, X, Y, weight=None):\n",
    "        p = torch.rand((1,))[0]\n",
    "        if p < self.mixup2_prob:\n",
    "            bs = X.shape[0]\n",
    "            n_dims = len(X.shape)\n",
    "            perm = torch.randperm(bs)\n",
    "            coeffs = self.beta_distribution.rsample(torch.Size((bs,))).to(X.device)\n",
    "\n",
    "            if n_dims == 2:\n",
    "                X = coeffs.view(-1, 1) * X + (1 - coeffs.view(-1, 1)) * X[perm]\n",
    "            elif n_dims == 3:\n",
    "                X = coeffs.view(-1, 1, 1) * X + (1 - coeffs.view(-1, 1, 1)) * X[perm]\n",
    "            else:\n",
    "                X = (\n",
    "                    coeffs.view(-1, 1, 1, 1) * X\n",
    "                    + (1 - coeffs.view(-1, 1, 1, 1)) * X[perm]\n",
    "                )\n",
    "            Y = coeffs.view(-1, 1) * Y + (1 - coeffs.view(-1, 1)) * Y[perm]\n",
    "            # Y = Y + Y[perm]\n",
    "            # Y = torch.clamp(Y, 0, 1)\n",
    "\n",
    "            if weight is None:\n",
    "                return X, Y\n",
    "            else:\n",
    "                weight = coeffs.view(-1) * weight + (1 - coeffs.view(-1)) * weight[perm]\n",
    "                return X, Y, weight\n",
    "        else:\n",
    "            if weight is None:\n",
    "                return X, Y\n",
    "            else:\n",
    "                return X, Y, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup2 = Mixup2(mix_beta=2, mixup2_prob=0.15)\n",
    "\n",
    "clip9, audio_label9,audio_weights9 = mixup2(clip8, audio_label2, audio_weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.4345e+00,  1.3736e+00,  1.4010e+00,  ...,  9.7046e-01,\n",
      "            9.9589e-01,  1.0101e+00],\n",
      "          [ 1.1148e+00,  9.6725e-01,  1.1009e+00,  ...,  9.3517e-01,\n",
      "            9.5411e-01,  1.0262e+00],\n",
      "          [ 8.8883e-01,  8.3815e-01,  8.8324e-01,  ...,  9.7624e-01,\n",
      "            9.4301e-01,  1.0100e+00],\n",
      "          ...,\n",
      "          [ 8.4184e-01,  7.3311e-01,  8.3998e-01,  ...,  6.8910e-01,\n",
      "            6.7257e-01,  8.5800e-01],\n",
      "          [ 8.0268e-01,  6.8876e-01,  7.9308e-01,  ...,  6.6533e-01,\n",
      "            6.4602e-01,  7.7112e-01],\n",
      "          [ 8.4739e-01,  6.1566e-01,  6.6143e-01,  ...,  6.4825e-01,\n",
      "            6.3218e-01,  7.4726e-01]],\n",
      "\n",
      "         [[-1.4110e-01, -1.4771e-01, -1.3356e-01,  ..., -2.3733e-03,\n",
      "           -1.4755e-02,  1.5833e-03],\n",
      "          [-1.6941e-01, -1.6631e-01, -1.6581e-01,  ...,  2.7224e-03,\n",
      "           -1.7414e-02, -4.3255e-03],\n",
      "          [-1.4138e-01, -1.1789e-01, -1.3459e-01,  ...,  1.1019e-02,\n",
      "            1.2764e-03, -4.9612e-03],\n",
      "          ...,\n",
      "          [-1.9575e-02, -6.2426e-02, -6.2607e-02,  ..., -5.8670e-02,\n",
      "           -5.9508e-02, -3.7832e-02],\n",
      "          [-4.2075e-03, -4.7582e-02, -5.9530e-02,  ..., -3.9810e-02,\n",
      "           -3.8984e-02, -3.6608e-02],\n",
      "          [ 5.5795e-03, -3.0801e-02, -4.8875e-02,  ..., -9.8778e-03,\n",
      "           -9.4622e-03, -2.4532e-02]],\n",
      "\n",
      "         [[-2.8887e-03,  4.1048e-03, -3.4303e-03,  ...,  3.1881e-03,\n",
      "            2.9403e-03, -1.8998e-03],\n",
      "          [ 1.8936e-02,  3.1444e-02,  1.6816e-02,  ...,  7.5332e-03,\n",
      "            1.0209e-02, -4.6753e-04],\n",
      "          [ 4.6632e-02,  5.3384e-02,  4.1423e-02,  ...,  8.2229e-03,\n",
      "            1.3475e-02,  1.7637e-03],\n",
      "          ...,\n",
      "          [ 9.2543e-03,  6.7975e-03, -9.6913e-04,  ...,  7.9326e-03,\n",
      "            9.9517e-03,  1.1752e-03],\n",
      "          [ 9.8209e-03,  8.6613e-03,  2.1337e-03,  ...,  1.4904e-02,\n",
      "            1.5512e-02,  4.0302e-03],\n",
      "          [ 6.0096e-03,  8.0032e-03,  3.8118e-03,  ...,  1.2752e-02,\n",
      "            1.2961e-02,  3.8675e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2100e+00,  1.1888e+00,  1.1860e+00,  ...,  1.1656e+00,\n",
      "            1.1551e+00,  1.2437e+00],\n",
      "          [ 1.2044e+00,  1.2201e+00,  1.2193e+00,  ...,  1.1874e+00,\n",
      "            1.1946e+00,  1.1779e+00],\n",
      "          [ 1.1418e+00,  1.2027e+00,  1.1395e+00,  ...,  1.1691e+00,\n",
      "            1.1276e+00,  1.1498e+00],\n",
      "          ...,\n",
      "          [ 8.4762e-01,  8.4169e-01,  8.4494e-01,  ...,  8.3444e-01,\n",
      "            8.5095e-01,  8.2783e-01],\n",
      "          [ 8.2311e-01,  8.2521e-01,  8.2847e-01,  ...,  8.3156e-01,\n",
      "            8.3560e-01,  8.4430e-01],\n",
      "          [ 7.7818e-01,  7.6833e-01,  7.8085e-01,  ...,  7.5966e-01,\n",
      "            7.8742e-01,  7.7556e-01]],\n",
      "\n",
      "         [[-1.4195e-02,  5.9097e-03, -5.9735e-03,  ...,  2.8930e-03,\n",
      "           -1.5618e-03, -2.5361e-02],\n",
      "          [-2.5500e-02, -1.2391e-02, -2.4387e-02,  ..., -1.5259e-02,\n",
      "           -1.9623e-02, -6.5457e-02],\n",
      "          [-4.6682e-02, -4.3617e-02, -4.0367e-02,  ..., -4.5179e-02,\n",
      "           -3.9135e-02, -6.5909e-02],\n",
      "          ...,\n",
      "          [-2.1051e-02, -1.9328e-02, -1.6519e-02,  ..., -1.9059e-02,\n",
      "           -1.6635e-02, -1.2888e-02],\n",
      "          [-2.3390e-02, -2.3336e-02, -2.0871e-02,  ..., -2.2124e-02,\n",
      "           -2.0001e-02, -1.6926e-02],\n",
      "          [-1.8381e-02, -2.0359e-02, -1.7580e-02,  ..., -2.2144e-02,\n",
      "           -1.7524e-02, -1.7327e-02]],\n",
      "\n",
      "         [[-7.6280e-03, -1.1735e-02, -8.7200e-03,  ..., -1.1430e-02,\n",
      "           -9.3208e-03, -1.2119e-02],\n",
      "          [-1.2753e-02, -1.9098e-02, -1.3061e-02,  ..., -1.7300e-02,\n",
      "           -1.2265e-02, -7.6088e-03],\n",
      "          [-7.9024e-03, -1.7934e-02, -9.7673e-03,  ..., -1.5461e-02,\n",
      "           -9.2270e-03,  2.3293e-03],\n",
      "          ...,\n",
      "          [-2.4734e-03, -2.0675e-03, -8.6997e-04,  ..., -2.0420e-03,\n",
      "           -2.6979e-03,  2.5381e-04],\n",
      "          [-1.4389e-03, -1.7202e-03, -1.7540e-03,  ..., -2.4819e-03,\n",
      "           -2.1920e-03, -2.2532e-03],\n",
      "          [ 1.0350e-03,  9.1363e-05,  1.1690e-04,  ..., -6.1905e-04,\n",
      "            6.9885e-05, -9.2812e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0358e+00,  1.0162e+00,  1.1105e+00,  ...,  1.1106e+00,\n",
      "            1.0428e+00,  1.1132e+00],\n",
      "          [ 1.0927e+00,  1.1211e+00,  1.1153e+00,  ...,  1.0938e+00,\n",
      "            1.0776e+00,  1.0843e+00],\n",
      "          [ 1.0274e+00,  1.1094e+00,  1.0742e+00,  ...,  9.9247e-01,\n",
      "            1.0318e+00,  9.9458e-01],\n",
      "          ...,\n",
      "          [ 1.0136e+00,  1.0165e+00,  1.0227e+00,  ...,  1.0276e+00,\n",
      "            1.0355e+00,  1.0211e+00],\n",
      "          [ 1.0118e+00,  1.0226e+00,  1.0176e+00,  ...,  1.0204e+00,\n",
      "            1.0289e+00,  1.0164e+00],\n",
      "          [ 1.0370e+00,  1.0344e+00,  1.0332e+00,  ...,  1.0281e+00,\n",
      "            1.0364e+00,  1.0274e+00]],\n",
      "\n",
      "         [[ 3.9905e-03,  2.9130e-02, -6.7855e-03,  ..., -2.5298e-02,\n",
      "            1.2745e-03, -2.6613e-02],\n",
      "          [ 6.9815e-04,  1.8181e-02, -9.5167e-03,  ..., -3.3146e-02,\n",
      "           -6.0967e-03, -1.8844e-02],\n",
      "          [-7.7804e-03, -4.9695e-03, -2.1318e-02,  ..., -3.1151e-02,\n",
      "           -9.7954e-03, -1.3133e-02],\n",
      "          ...,\n",
      "          [ 2.3155e-03,  4.8405e-03,  3.3808e-03,  ...,  1.1922e-04,\n",
      "            8.7583e-03, -3.0206e-03],\n",
      "          [ 5.3343e-03,  7.4700e-03,  5.6625e-03,  ...,  4.2476e-03,\n",
      "            4.8464e-03,  3.0207e-03],\n",
      "          [ 7.1959e-03,  4.7523e-03,  3.6570e-03,  ...,  8.7514e-04,\n",
      "            9.3176e-04,  2.3459e-03]],\n",
      "\n",
      "         [[-2.6834e-03, -7.9147e-03, -3.1796e-03,  ..., -1.9556e-03,\n",
      "           -2.9511e-03,  3.4729e-03],\n",
      "          [-5.5778e-03, -1.4726e-02, -5.4169e-03,  ...,  5.7899e-04,\n",
      "           -4.1917e-03,  4.9135e-03],\n",
      "          [-1.3123e-03, -1.4208e-02, -3.1801e-03,  ...,  6.8614e-03,\n",
      "           -1.9503e-03,  7.3849e-03],\n",
      "          ...,\n",
      "          [ 1.6185e-03,  1.1335e-03,  1.0285e-03,  ...,  8.3430e-05,\n",
      "           -8.7492e-04,  1.9709e-03],\n",
      "          [ 1.2935e-03,  4.2519e-04,  4.9799e-04,  ...,  3.0410e-04,\n",
      "           -1.9558e-03,  1.2352e-03],\n",
      "          [ 1.1622e-03, -2.8941e-04, -1.4531e-04,  ..., -1.8606e-04,\n",
      "           -1.9568e-03,  1.0058e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 9.9344e-01,  1.0373e+00,  1.1227e+00,  ...,  1.0730e+00,\n",
      "            1.1254e+00,  1.0659e+00],\n",
      "          [ 1.0054e+00,  1.0868e+00,  1.0810e+00,  ...,  1.0593e+00,\n",
      "            1.0589e+00,  1.0212e+00],\n",
      "          [ 1.0712e+00,  1.0589e+00,  9.8763e-01,  ...,  9.5580e-01,\n",
      "            9.7193e-01,  1.0144e+00],\n",
      "          ...,\n",
      "          [ 9.9280e-01,  1.0205e+00,  9.3889e-01,  ...,  7.9957e-01,\n",
      "            7.9219e-01,  7.9239e-01],\n",
      "          [ 8.2688e-01,  8.7924e-01,  9.0748e-01,  ...,  8.1287e-01,\n",
      "            8.2154e-01,  8.1293e-01],\n",
      "          [ 8.2902e-01,  8.5651e-01,  8.6500e-01,  ...,  8.2247e-01,\n",
      "            8.2206e-01,  8.2064e-01]],\n",
      "\n",
      "         [[ 1.6756e-02,  9.2802e-03, -3.1169e-02,  ..., -2.4803e-02,\n",
      "           -3.7348e-02, -1.4772e-02],\n",
      "          [-3.9624e-03, -1.2891e-02, -5.3112e-02,  ..., -4.1432e-02,\n",
      "           -5.7987e-02, -8.8431e-03],\n",
      "          [-1.9999e-02, -3.8990e-02, -6.4275e-02,  ..., -5.6597e-02,\n",
      "           -6.3455e-02, -4.0102e-04],\n",
      "          ...,\n",
      "          [-1.6251e-03,  1.2452e-02,  2.0169e-02,  ...,  9.0308e-03,\n",
      "            6.1379e-03,  1.4958e-02],\n",
      "          [-2.4690e-02, -9.6147e-03,  4.5161e-03,  ...,  8.4075e-03,\n",
      "            8.7342e-03,  1.0833e-02],\n",
      "          [-3.2541e-02, -3.5065e-02, -1.9027e-02,  ...,  5.5412e-03,\n",
      "            6.0267e-03,  6.4198e-03]],\n",
      "\n",
      "         [[-9.4228e-03, -1.1871e-02, -8.8155e-03,  ..., -8.0219e-03,\n",
      "           -7.2853e-03,  3.4670e-03],\n",
      "          [-1.3069e-02, -1.9699e-02, -8.4451e-03,  ..., -7.2115e-03,\n",
      "           -2.1527e-03,  4.2598e-03],\n",
      "          [-1.0981e-02, -1.5276e-02,  1.7124e-03,  ...,  2.3033e-03,\n",
      "            8.9591e-03,  6.4891e-03],\n",
      "          ...,\n",
      "          [-2.2388e-02, -2.0473e-02, -6.8206e-03,  ..., -9.8686e-04,\n",
      "            2.5914e-04, -1.2181e-03],\n",
      "          [-1.3958e-02, -1.7612e-02, -1.2070e-02,  ..., -1.1987e-03,\n",
      "           -5.9643e-05, -2.4791e-03],\n",
      "          [-6.9684e-03, -1.2048e-02, -1.0193e-02,  ..., -9.8455e-04,\n",
      "           -2.9298e-04, -2.1490e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7848e-01,  8.5347e-01,  7.8587e-01,  ...,  7.9186e-01,\n",
      "            8.1977e-01,  8.1641e-01],\n",
      "          [ 8.2581e-01,  8.7667e-01,  8.4384e-01,  ...,  7.9942e-01,\n",
      "            8.7615e-01,  8.8303e-01],\n",
      "          [ 8.6608e-01,  9.0245e-01,  8.8130e-01,  ...,  8.7392e-01,\n",
      "            9.1618e-01,  8.6923e-01],\n",
      "          ...,\n",
      "          [ 9.4540e-01,  9.4545e-01,  9.6998e-01,  ...,  9.5462e-01,\n",
      "            9.4006e-01,  9.5592e-01],\n",
      "          [ 8.8818e-01,  8.8807e-01,  9.1466e-01,  ...,  8.9829e-01,\n",
      "            8.8983e-01,  9.0243e-01],\n",
      "          [ 8.3475e-01,  8.1520e-01,  8.1967e-01,  ...,  8.1352e-01,\n",
      "            8.1408e-01,  8.2187e-01]],\n",
      "\n",
      "         [[-7.7484e-03,  1.2117e-02,  2.4881e-02,  ...,  1.7167e-02,\n",
      "            2.4918e-02,  1.7226e-02],\n",
      "          [ 1.4647e-03,  2.3104e-02,  3.9291e-02,  ...,  3.7648e-02,\n",
      "            4.6602e-02,  3.6044e-02],\n",
      "          [ 1.1514e-02,  1.0957e-02,  3.8925e-02,  ...,  4.1507e-02,\n",
      "            3.5380e-02,  2.7938e-02],\n",
      "          ...,\n",
      "          [-5.1767e-02, -5.2166e-02, -5.0164e-02,  ..., -5.0305e-02,\n",
      "           -5.2995e-02, -4.8038e-02],\n",
      "          [-4.4827e-02, -4.9484e-02, -5.2582e-02,  ..., -5.0975e-02,\n",
      "           -5.0260e-02, -4.9183e-02],\n",
      "          [-2.7471e-02, -3.3337e-02, -3.9562e-02,  ..., -3.6699e-02,\n",
      "           -3.2772e-02, -3.4865e-02]],\n",
      "\n",
      "         [[ 4.7739e-03,  8.6673e-04,  4.2498e-03,  ...,  6.9161e-03,\n",
      "            4.2609e-03,  4.0242e-03],\n",
      "          [ 6.7541e-03, -3.5017e-03, -1.6329e-04,  ...,  3.9269e-03,\n",
      "           -2.3274e-03, -1.3371e-03],\n",
      "          [ 6.4411e-03, -6.1985e-03, -7.3000e-03,  ..., -6.7555e-03,\n",
      "           -9.9169e-03, -5.3998e-03],\n",
      "          ...,\n",
      "          [-4.2640e-03, -4.4425e-03, -8.1152e-03,  ..., -7.0610e-03,\n",
      "           -4.9953e-03, -6.3723e-03],\n",
      "          [ 2.6473e-03,  2.0481e-03, -1.4221e-03,  ..., -4.4035e-04,\n",
      "            2.5868e-03,  5.0827e-04],\n",
      "          [ 6.5949e-03,  5.3806e-03,  3.4222e-03,  ...,  4.1490e-03,\n",
      "            5.7934e-03,  4.0664e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4472e+00,  1.3885e+00,  1.4834e+00,  ...,  1.1898e+00,\n",
      "            1.1453e+00,  1.0501e+00],\n",
      "          [ 1.2043e+00,  1.1609e+00,  1.1925e+00,  ...,  1.1625e+00,\n",
      "            1.1414e+00,  1.0694e+00],\n",
      "          [ 1.0491e+00,  1.0859e+00,  1.1075e+00,  ...,  1.1495e+00,\n",
      "            1.1045e+00,  1.0064e+00],\n",
      "          ...,\n",
      "          [ 9.3864e-01,  8.7047e-01,  8.6896e-01,  ...,  8.4801e-01,\n",
      "            8.1902e-01,  8.3881e-01],\n",
      "          [ 1.0069e+00,  9.8855e-01,  9.0039e-01,  ...,  8.2204e-01,\n",
      "            8.2918e-01,  8.4775e-01],\n",
      "          [ 1.0574e+00,  1.0117e+00,  9.1812e-01,  ...,  7.8148e-01,\n",
      "            8.0569e-01,  8.0530e-01]],\n",
      "\n",
      "         [[-1.0391e-01, -8.3280e-02, -1.0428e-01,  ..., -1.0776e-02,\n",
      "           -8.5685e-03, -6.7967e-03],\n",
      "          [-1.1440e-01, -9.5081e-02, -1.2128e-01,  ..., -3.2191e-02,\n",
      "           -1.3931e-02, -1.5360e-02],\n",
      "          [-1.0159e-01, -8.7533e-02, -1.0556e-01,  ..., -5.3135e-02,\n",
      "           -1.4099e-02, -1.8331e-02],\n",
      "          ...,\n",
      "          [-2.4327e-02, -2.5311e-02, -3.6263e-02,  ..., -8.4727e-03,\n",
      "           -8.0452e-03, -7.7791e-03],\n",
      "          [ 3.7875e-03,  7.8704e-03, -1.1760e-02,  ..., -1.7283e-02,\n",
      "           -5.0117e-03, -5.8803e-03],\n",
      "          [ 2.8808e-02,  3.0564e-02,  1.1607e-02,  ..., -1.7362e-02,\n",
      "           -5.0150e-03, -1.0946e-02]],\n",
      "\n",
      "         [[-5.8404e-04, -2.0308e-03, -1.9579e-03,  ..., -1.0613e-02,\n",
      "           -1.6424e-03, -3.1631e-03],\n",
      "          [ 1.0864e-02,  7.2803e-03,  1.0148e-02,  ..., -1.4943e-02,\n",
      "           -4.0128e-03, -2.6327e-03],\n",
      "          [ 2.1773e-02,  1.7559e-02,  2.0849e-02,  ..., -1.2382e-02,\n",
      "           -6.7413e-03,  4.5439e-04],\n",
      "          ...,\n",
      "          [ 3.7115e-03,  1.0135e-02,  7.4318e-03,  ..., -1.8424e-03,\n",
      "            6.1173e-03,  4.5774e-03],\n",
      "          [ 1.2217e-02,  1.5697e-02,  1.3970e-02,  ..., -3.2188e-03,\n",
      "            3.0497e-03,  4.0602e-04],\n",
      "          [ 1.3129e-02,  1.3444e-02,  1.1911e-02,  ..., -1.7858e-03,\n",
      "            6.0570e-04, -1.1400e-03]]]])\n",
      "torch.Size([32, 3, 40, 251])\n"
     ]
    }
   ],
   "source": [
    "print(clip9)\n",
    "print(clip9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([32, 182])\n"
     ]
    }
   ],
   "source": [
    "print(audio_label9)\n",
    "print(audio_label9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(audio_label9[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8000, 0.7333, 0.6333, 0.5333, 0.7333, 0.9333, 0.7667, 0.8333, 0.8000,\n",
      "        0.6333, 0.7333, 0.7333, 0.8000, 0.8000, 0.9333, 0.7333, 0.7333, 0.8667,\n",
      "        0.8000, 0.8667, 0.7000, 0.8000, 0.7000, 0.8333, 0.7333, 0.7000, 0.6667,\n",
      "        0.7000, 0.9333, 0.6333, 0.9333, 0.7667])\n"
     ]
    }
   ],
   "source": [
    "print(audio_weights9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, I need to put the prepared data into a pre-trained model and train it as a feature extractor\n",
    "\n",
    "Here, the first choice is the efficientNet_s3_in21K pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = timm.create_model('tf_efficientnetv2_s_in21k', pretrained=True,in_chans=3) # 可以通过传入argument in_chans来改变 预训练模型接受的数据通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "EfficientNet                                  [128, 21843]              --\n",
       "├─Conv2dSame: 1-1                             [128, 24, 20, 126]        648\n",
       "├─BatchNormAct2d: 1-2                         [128, 24, 20, 126]        48\n",
       "│    └─Identity: 2-1                          [128, 24, 20, 126]        --\n",
       "│    └─SiLU: 2-2                              [128, 24, 20, 126]        --\n",
       "├─Sequential: 1-3                             [128, 256, 2, 8]          --\n",
       "│    └─Sequential: 2-3                        [128, 24, 20, 126]        --\n",
       "│    │    └─ConvBnAct: 3-1                    [128, 24, 20, 126]        5,232\n",
       "│    │    └─ConvBnAct: 3-2                    [128, 24, 20, 126]        5,232\n",
       "│    └─Sequential: 2-4                        [128, 48, 10, 63]         --\n",
       "│    │    └─EdgeResidual: 3-3                 [128, 48, 10, 63]         25,632\n",
       "│    │    └─EdgeResidual: 3-4                 [128, 48, 10, 63]         92,640\n",
       "│    │    └─EdgeResidual: 3-5                 [128, 48, 10, 63]         92,640\n",
       "│    │    └─EdgeResidual: 3-6                 [128, 48, 10, 63]         92,640\n",
       "│    └─Sequential: 2-5                        [128, 64, 5, 32]          --\n",
       "│    │    └─EdgeResidual: 3-7                 [128, 64, 5, 32]          95,744\n",
       "│    │    └─EdgeResidual: 3-8                 [128, 64, 5, 32]          164,480\n",
       "│    │    └─EdgeResidual: 3-9                 [128, 64, 5, 32]          164,480\n",
       "│    │    └─EdgeResidual: 3-10                [128, 64, 5, 32]          164,480\n",
       "│    └─Sequential: 2-6                        [128, 128, 3, 16]         --\n",
       "│    │    └─InvertedResidual: 3-11            [128, 128, 3, 16]         61,200\n",
       "│    │    └─InvertedResidual: 3-12            [128, 128, 3, 16]         171,296\n",
       "│    │    └─InvertedResidual: 3-13            [128, 128, 3, 16]         171,296\n",
       "│    │    └─InvertedResidual: 3-14            [128, 128, 3, 16]         171,296\n",
       "│    │    └─InvertedResidual: 3-15            [128, 128, 3, 16]         171,296\n",
       "│    │    └─InvertedResidual: 3-16            [128, 128, 3, 16]         171,296\n",
       "│    └─Sequential: 2-7                        [128, 160, 3, 16]         --\n",
       "│    │    └─InvertedResidual: 3-17            [128, 160, 3, 16]         281,440\n",
       "│    │    └─InvertedResidual: 3-18            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-19            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-20            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-21            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-22            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-23            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-24            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-25            [128, 160, 3, 16]         397,800\n",
       "│    └─Sequential: 2-8                        [128, 256, 2, 8]          --\n",
       "│    │    └─InvertedResidual: 3-26            [128, 256, 2, 8]          490,152\n",
       "│    │    └─InvertedResidual: 3-27            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-28            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-29            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-30            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-31            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-32            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-33            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-34            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-35            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-36            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-37            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-38            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-39            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-40            [128, 256, 2, 8]          1,005,120\n",
       "├─Conv2d: 1-4                                 [128, 1280, 2, 8]         327,680\n",
       "├─BatchNormAct2d: 1-5                         [128, 1280, 2, 8]         2,560\n",
       "│    └─Identity: 2-9                          [128, 1280, 2, 8]         --\n",
       "│    └─SiLU: 2-10                             [128, 1280, 2, 8]         --\n",
       "├─SelectAdaptivePool2d: 1-6                   [128, 1280]               --\n",
       "│    └─AdaptiveAvgPool2d: 2-11                [128, 1280, 1, 1]         --\n",
       "│    └─Flatten: 2-12                          [128, 1280]               --\n",
       "├─Linear: 1-7                                 [128, 21843]              27,980,883\n",
       "===============================================================================================\n",
       "Total params: 48,158,371\n",
       "Trainable params: 48,158,371\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 90.69\n",
       "===============================================================================================\n",
       "Input size (MB): 15.42\n",
       "Forward/backward pass size (MB): 3097.44\n",
       "Params size (MB): 192.02\n",
       "Estimated Total Size (MB): 3304.88\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model,input_size=(128,3,40,251))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNormAct2d(\n",
       "   1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "   (drop): Identity()\n",
       "   (act): SiLU(inplace=True)\n",
       " ),\n",
       " SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1)),\n",
       " Linear(in_features=1280, out_features=21843, bias=True)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because we want to customize the shape of the data, we need to change the last few layers of this pre-trained model\n",
    "# First check the last few layers of the pre-trained model\n",
    "\n",
    "layers_last4 = list(model.children())[-4:]\n",
    "\n",
    "layers_last4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last two layers are an adaptive pooling layer and a fully connected layer\n",
    "# Here I choose to replace these two layers. First remove these two layers\n",
    "\n",
    "layers = list(model.children())[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nn.Sequential(*layers) # Encapsulate multiple layers in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2dSame(3, 24, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNormAct2d(\n",
       "    24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvBnAct(\n",
       "        (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): ConvBnAct(\n",
       "        (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): EdgeResidual(\n",
       "        (conv_exp): Conv2dSame(24, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): EdgeResidual(\n",
       "        (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): EdgeResidual(\n",
       "        (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): EdgeResidual(\n",
       "        (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): EdgeResidual(\n",
       "        (conv_exp): Conv2dSame(48, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): EdgeResidual(\n",
       "        (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): EdgeResidual(\n",
       "        (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): EdgeResidual(\n",
       "        (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2dSame(256, 256, kernel_size=(3, 3), stride=(2, 2), groups=256, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2dSame(960, 960, kernel_size=(3, 3), stride=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (4): BatchNormAct2d(\n",
       "    1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1280, out_features=21843, bias=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier # classifier is the last fully connected layer of the model, out_features represents the number of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n",
      "21843\n"
     ]
    }
   ],
   "source": [
    "print(model.classifier.in_features)\n",
    "print(model.classifier.out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 251, 40])\n"
     ]
    }
   ],
   "source": [
    "## The pre-trained model will be used for feature extraction\n",
    "\n",
    "clip10=clip9.permute((0,1,3,2))\n",
    "\n",
    "print(clip10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the time frame of each time segment\n",
    "frames_num=clip10.shape[2] \n",
    "\n",
    "frames_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.4345e+00,  1.3736e+00,  1.4010e+00,  ...,  9.7046e-01,\n",
      "            9.9589e-01,  1.0101e+00],\n",
      "          [ 1.1148e+00,  9.6725e-01,  1.1009e+00,  ...,  9.3517e-01,\n",
      "            9.5411e-01,  1.0262e+00],\n",
      "          [ 8.8883e-01,  8.3815e-01,  8.8324e-01,  ...,  9.7624e-01,\n",
      "            9.4301e-01,  1.0100e+00],\n",
      "          ...,\n",
      "          [ 8.4184e-01,  7.3311e-01,  8.3998e-01,  ...,  6.8910e-01,\n",
      "            6.7257e-01,  8.5800e-01],\n",
      "          [ 8.0268e-01,  6.8876e-01,  7.9308e-01,  ...,  6.6533e-01,\n",
      "            6.4602e-01,  7.7112e-01],\n",
      "          [ 8.4739e-01,  6.1566e-01,  6.6143e-01,  ...,  6.4825e-01,\n",
      "            6.3218e-01,  7.4726e-01]],\n",
      "\n",
      "         [[-1.4110e-01, -1.4771e-01, -1.3356e-01,  ..., -2.3733e-03,\n",
      "           -1.4755e-02,  1.5833e-03],\n",
      "          [-1.6941e-01, -1.6631e-01, -1.6581e-01,  ...,  2.7224e-03,\n",
      "           -1.7414e-02, -4.3255e-03],\n",
      "          [-1.4138e-01, -1.1789e-01, -1.3459e-01,  ...,  1.1019e-02,\n",
      "            1.2764e-03, -4.9612e-03],\n",
      "          ...,\n",
      "          [-1.9575e-02, -6.2426e-02, -6.2607e-02,  ..., -5.8670e-02,\n",
      "           -5.9508e-02, -3.7832e-02],\n",
      "          [-4.2075e-03, -4.7582e-02, -5.9530e-02,  ..., -3.9810e-02,\n",
      "           -3.8984e-02, -3.6608e-02],\n",
      "          [ 5.5795e-03, -3.0801e-02, -4.8875e-02,  ..., -9.8778e-03,\n",
      "           -9.4622e-03, -2.4532e-02]],\n",
      "\n",
      "         [[-2.8887e-03,  4.1048e-03, -3.4303e-03,  ...,  3.1881e-03,\n",
      "            2.9403e-03, -1.8998e-03],\n",
      "          [ 1.8936e-02,  3.1444e-02,  1.6816e-02,  ...,  7.5332e-03,\n",
      "            1.0209e-02, -4.6753e-04],\n",
      "          [ 4.6632e-02,  5.3384e-02,  4.1423e-02,  ...,  8.2229e-03,\n",
      "            1.3475e-02,  1.7637e-03],\n",
      "          ...,\n",
      "          [ 9.2543e-03,  6.7975e-03, -9.6913e-04,  ...,  7.9326e-03,\n",
      "            9.9517e-03,  1.1752e-03],\n",
      "          [ 9.8209e-03,  8.6613e-03,  2.1337e-03,  ...,  1.4904e-02,\n",
      "            1.5512e-02,  4.0302e-03],\n",
      "          [ 6.0096e-03,  8.0032e-03,  3.8118e-03,  ...,  1.2752e-02,\n",
      "            1.2961e-02,  3.8675e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2100e+00,  1.1888e+00,  1.1860e+00,  ...,  1.1656e+00,\n",
      "            1.1551e+00,  1.2437e+00],\n",
      "          [ 1.2044e+00,  1.2201e+00,  1.2193e+00,  ...,  1.1874e+00,\n",
      "            1.1946e+00,  1.1779e+00],\n",
      "          [ 1.1418e+00,  1.2027e+00,  1.1395e+00,  ...,  1.1691e+00,\n",
      "            1.1276e+00,  1.1498e+00],\n",
      "          ...,\n",
      "          [ 8.4762e-01,  8.4169e-01,  8.4494e-01,  ...,  8.3444e-01,\n",
      "            8.5095e-01,  8.2783e-01],\n",
      "          [ 8.2311e-01,  8.2521e-01,  8.2847e-01,  ...,  8.3156e-01,\n",
      "            8.3560e-01,  8.4430e-01],\n",
      "          [ 7.7818e-01,  7.6833e-01,  7.8085e-01,  ...,  7.5966e-01,\n",
      "            7.8742e-01,  7.7556e-01]],\n",
      "\n",
      "         [[-1.4195e-02,  5.9097e-03, -5.9735e-03,  ...,  2.8930e-03,\n",
      "           -1.5618e-03, -2.5361e-02],\n",
      "          [-2.5500e-02, -1.2391e-02, -2.4387e-02,  ..., -1.5259e-02,\n",
      "           -1.9623e-02, -6.5457e-02],\n",
      "          [-4.6682e-02, -4.3617e-02, -4.0367e-02,  ..., -4.5179e-02,\n",
      "           -3.9135e-02, -6.5909e-02],\n",
      "          ...,\n",
      "          [-2.1051e-02, -1.9328e-02, -1.6519e-02,  ..., -1.9059e-02,\n",
      "           -1.6635e-02, -1.2888e-02],\n",
      "          [-2.3390e-02, -2.3336e-02, -2.0871e-02,  ..., -2.2124e-02,\n",
      "           -2.0001e-02, -1.6926e-02],\n",
      "          [-1.8381e-02, -2.0359e-02, -1.7580e-02,  ..., -2.2144e-02,\n",
      "           -1.7524e-02, -1.7327e-02]],\n",
      "\n",
      "         [[-7.6280e-03, -1.1735e-02, -8.7200e-03,  ..., -1.1430e-02,\n",
      "           -9.3208e-03, -1.2119e-02],\n",
      "          [-1.2753e-02, -1.9098e-02, -1.3061e-02,  ..., -1.7300e-02,\n",
      "           -1.2265e-02, -7.6088e-03],\n",
      "          [-7.9024e-03, -1.7934e-02, -9.7673e-03,  ..., -1.5461e-02,\n",
      "           -9.2270e-03,  2.3293e-03],\n",
      "          ...,\n",
      "          [-2.4734e-03, -2.0675e-03, -8.6997e-04,  ..., -2.0420e-03,\n",
      "           -2.6979e-03,  2.5381e-04],\n",
      "          [-1.4389e-03, -1.7202e-03, -1.7540e-03,  ..., -2.4819e-03,\n",
      "           -2.1920e-03, -2.2532e-03],\n",
      "          [ 1.0350e-03,  9.1363e-05,  1.1690e-04,  ..., -6.1905e-04,\n",
      "            6.9885e-05, -9.2812e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0358e+00,  1.0162e+00,  1.1105e+00,  ...,  1.1106e+00,\n",
      "            1.0428e+00,  1.1132e+00],\n",
      "          [ 1.0927e+00,  1.1211e+00,  1.1153e+00,  ...,  1.0938e+00,\n",
      "            1.0776e+00,  1.0843e+00],\n",
      "          [ 1.0274e+00,  1.1094e+00,  1.0742e+00,  ...,  9.9247e-01,\n",
      "            1.0318e+00,  9.9458e-01],\n",
      "          ...,\n",
      "          [ 1.0136e+00,  1.0165e+00,  1.0227e+00,  ...,  1.0276e+00,\n",
      "            1.0355e+00,  1.0211e+00],\n",
      "          [ 1.0118e+00,  1.0226e+00,  1.0176e+00,  ...,  1.0204e+00,\n",
      "            1.0289e+00,  1.0164e+00],\n",
      "          [ 1.0370e+00,  1.0344e+00,  1.0332e+00,  ...,  1.0281e+00,\n",
      "            1.0364e+00,  1.0274e+00]],\n",
      "\n",
      "         [[ 3.9905e-03,  2.9130e-02, -6.7855e-03,  ..., -2.5298e-02,\n",
      "            1.2745e-03, -2.6613e-02],\n",
      "          [ 6.9815e-04,  1.8181e-02, -9.5167e-03,  ..., -3.3146e-02,\n",
      "           -6.0967e-03, -1.8844e-02],\n",
      "          [-7.7804e-03, -4.9695e-03, -2.1318e-02,  ..., -3.1151e-02,\n",
      "           -9.7954e-03, -1.3133e-02],\n",
      "          ...,\n",
      "          [ 2.3155e-03,  4.8405e-03,  3.3808e-03,  ...,  1.1922e-04,\n",
      "            8.7583e-03, -3.0206e-03],\n",
      "          [ 5.3343e-03,  7.4700e-03,  5.6625e-03,  ...,  4.2476e-03,\n",
      "            4.8464e-03,  3.0207e-03],\n",
      "          [ 7.1959e-03,  4.7523e-03,  3.6570e-03,  ...,  8.7514e-04,\n",
      "            9.3176e-04,  2.3459e-03]],\n",
      "\n",
      "         [[-2.6834e-03, -7.9147e-03, -3.1796e-03,  ..., -1.9556e-03,\n",
      "           -2.9511e-03,  3.4729e-03],\n",
      "          [-5.5778e-03, -1.4726e-02, -5.4169e-03,  ...,  5.7899e-04,\n",
      "           -4.1917e-03,  4.9135e-03],\n",
      "          [-1.3123e-03, -1.4208e-02, -3.1801e-03,  ...,  6.8614e-03,\n",
      "           -1.9503e-03,  7.3849e-03],\n",
      "          ...,\n",
      "          [ 1.6185e-03,  1.1335e-03,  1.0285e-03,  ...,  8.3430e-05,\n",
      "           -8.7492e-04,  1.9709e-03],\n",
      "          [ 1.2935e-03,  4.2519e-04,  4.9799e-04,  ...,  3.0410e-04,\n",
      "           -1.9558e-03,  1.2352e-03],\n",
      "          [ 1.1622e-03, -2.8941e-04, -1.4531e-04,  ..., -1.8606e-04,\n",
      "           -1.9568e-03,  1.0058e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 9.9344e-01,  1.0373e+00,  1.1227e+00,  ...,  1.0730e+00,\n",
      "            1.1254e+00,  1.0659e+00],\n",
      "          [ 1.0054e+00,  1.0868e+00,  1.0810e+00,  ...,  1.0593e+00,\n",
      "            1.0589e+00,  1.0212e+00],\n",
      "          [ 1.0712e+00,  1.0589e+00,  9.8763e-01,  ...,  9.5580e-01,\n",
      "            9.7193e-01,  1.0144e+00],\n",
      "          ...,\n",
      "          [ 9.9280e-01,  1.0205e+00,  9.3889e-01,  ...,  7.9957e-01,\n",
      "            7.9219e-01,  7.9239e-01],\n",
      "          [ 8.2688e-01,  8.7924e-01,  9.0748e-01,  ...,  8.1287e-01,\n",
      "            8.2154e-01,  8.1293e-01],\n",
      "          [ 8.2902e-01,  8.5651e-01,  8.6500e-01,  ...,  8.2247e-01,\n",
      "            8.2206e-01,  8.2064e-01]],\n",
      "\n",
      "         [[ 1.6756e-02,  9.2802e-03, -3.1169e-02,  ..., -2.4803e-02,\n",
      "           -3.7348e-02, -1.4772e-02],\n",
      "          [-3.9624e-03, -1.2891e-02, -5.3112e-02,  ..., -4.1432e-02,\n",
      "           -5.7987e-02, -8.8431e-03],\n",
      "          [-1.9999e-02, -3.8990e-02, -6.4275e-02,  ..., -5.6597e-02,\n",
      "           -6.3455e-02, -4.0102e-04],\n",
      "          ...,\n",
      "          [-1.6251e-03,  1.2452e-02,  2.0169e-02,  ...,  9.0308e-03,\n",
      "            6.1379e-03,  1.4958e-02],\n",
      "          [-2.4690e-02, -9.6147e-03,  4.5161e-03,  ...,  8.4075e-03,\n",
      "            8.7342e-03,  1.0833e-02],\n",
      "          [-3.2541e-02, -3.5065e-02, -1.9027e-02,  ...,  5.5412e-03,\n",
      "            6.0267e-03,  6.4198e-03]],\n",
      "\n",
      "         [[-9.4228e-03, -1.1871e-02, -8.8155e-03,  ..., -8.0219e-03,\n",
      "           -7.2853e-03,  3.4670e-03],\n",
      "          [-1.3069e-02, -1.9699e-02, -8.4451e-03,  ..., -7.2115e-03,\n",
      "           -2.1527e-03,  4.2598e-03],\n",
      "          [-1.0981e-02, -1.5276e-02,  1.7124e-03,  ...,  2.3033e-03,\n",
      "            8.9591e-03,  6.4891e-03],\n",
      "          ...,\n",
      "          [-2.2388e-02, -2.0473e-02, -6.8206e-03,  ..., -9.8686e-04,\n",
      "            2.5914e-04, -1.2181e-03],\n",
      "          [-1.3958e-02, -1.7612e-02, -1.2070e-02,  ..., -1.1987e-03,\n",
      "           -5.9643e-05, -2.4791e-03],\n",
      "          [-6.9684e-03, -1.2048e-02, -1.0193e-02,  ..., -9.8455e-04,\n",
      "           -2.9298e-04, -2.1490e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7848e-01,  8.5347e-01,  7.8587e-01,  ...,  7.9186e-01,\n",
      "            8.1977e-01,  8.1641e-01],\n",
      "          [ 8.2581e-01,  8.7667e-01,  8.4384e-01,  ...,  7.9942e-01,\n",
      "            8.7615e-01,  8.8303e-01],\n",
      "          [ 8.6608e-01,  9.0245e-01,  8.8130e-01,  ...,  8.7392e-01,\n",
      "            9.1618e-01,  8.6923e-01],\n",
      "          ...,\n",
      "          [ 9.4540e-01,  9.4545e-01,  9.6998e-01,  ...,  9.5462e-01,\n",
      "            9.4006e-01,  9.5592e-01],\n",
      "          [ 8.8818e-01,  8.8807e-01,  9.1466e-01,  ...,  8.9829e-01,\n",
      "            8.8983e-01,  9.0243e-01],\n",
      "          [ 8.3475e-01,  8.1520e-01,  8.1967e-01,  ...,  8.1352e-01,\n",
      "            8.1408e-01,  8.2187e-01]],\n",
      "\n",
      "         [[-7.7484e-03,  1.2117e-02,  2.4881e-02,  ...,  1.7167e-02,\n",
      "            2.4918e-02,  1.7226e-02],\n",
      "          [ 1.4647e-03,  2.3104e-02,  3.9291e-02,  ...,  3.7648e-02,\n",
      "            4.6602e-02,  3.6044e-02],\n",
      "          [ 1.1514e-02,  1.0957e-02,  3.8925e-02,  ...,  4.1507e-02,\n",
      "            3.5380e-02,  2.7938e-02],\n",
      "          ...,\n",
      "          [-5.1767e-02, -5.2166e-02, -5.0164e-02,  ..., -5.0305e-02,\n",
      "           -5.2995e-02, -4.8038e-02],\n",
      "          [-4.4827e-02, -4.9484e-02, -5.2582e-02,  ..., -5.0975e-02,\n",
      "           -5.0260e-02, -4.9183e-02],\n",
      "          [-2.7471e-02, -3.3337e-02, -3.9562e-02,  ..., -3.6699e-02,\n",
      "           -3.2772e-02, -3.4865e-02]],\n",
      "\n",
      "         [[ 4.7739e-03,  8.6673e-04,  4.2498e-03,  ...,  6.9161e-03,\n",
      "            4.2609e-03,  4.0242e-03],\n",
      "          [ 6.7541e-03, -3.5017e-03, -1.6329e-04,  ...,  3.9269e-03,\n",
      "           -2.3274e-03, -1.3371e-03],\n",
      "          [ 6.4411e-03, -6.1985e-03, -7.3000e-03,  ..., -6.7555e-03,\n",
      "           -9.9169e-03, -5.3998e-03],\n",
      "          ...,\n",
      "          [-4.2640e-03, -4.4425e-03, -8.1152e-03,  ..., -7.0610e-03,\n",
      "           -4.9953e-03, -6.3723e-03],\n",
      "          [ 2.6473e-03,  2.0481e-03, -1.4221e-03,  ..., -4.4035e-04,\n",
      "            2.5868e-03,  5.0827e-04],\n",
      "          [ 6.5949e-03,  5.3806e-03,  3.4222e-03,  ...,  4.1490e-03,\n",
      "            5.7934e-03,  4.0664e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4472e+00,  1.3885e+00,  1.4834e+00,  ...,  1.1898e+00,\n",
      "            1.1453e+00,  1.0501e+00],\n",
      "          [ 1.2043e+00,  1.1609e+00,  1.1925e+00,  ...,  1.1625e+00,\n",
      "            1.1414e+00,  1.0694e+00],\n",
      "          [ 1.0491e+00,  1.0859e+00,  1.1075e+00,  ...,  1.1495e+00,\n",
      "            1.1045e+00,  1.0064e+00],\n",
      "          ...,\n",
      "          [ 9.3864e-01,  8.7047e-01,  8.6896e-01,  ...,  8.4801e-01,\n",
      "            8.1902e-01,  8.3881e-01],\n",
      "          [ 1.0069e+00,  9.8855e-01,  9.0039e-01,  ...,  8.2204e-01,\n",
      "            8.2918e-01,  8.4775e-01],\n",
      "          [ 1.0574e+00,  1.0117e+00,  9.1812e-01,  ...,  7.8148e-01,\n",
      "            8.0569e-01,  8.0530e-01]],\n",
      "\n",
      "         [[-1.0391e-01, -8.3280e-02, -1.0428e-01,  ..., -1.0776e-02,\n",
      "           -8.5685e-03, -6.7967e-03],\n",
      "          [-1.1440e-01, -9.5081e-02, -1.2128e-01,  ..., -3.2191e-02,\n",
      "           -1.3931e-02, -1.5360e-02],\n",
      "          [-1.0159e-01, -8.7533e-02, -1.0556e-01,  ..., -5.3135e-02,\n",
      "           -1.4099e-02, -1.8331e-02],\n",
      "          ...,\n",
      "          [-2.4327e-02, -2.5311e-02, -3.6263e-02,  ..., -8.4727e-03,\n",
      "           -8.0452e-03, -7.7791e-03],\n",
      "          [ 3.7875e-03,  7.8704e-03, -1.1760e-02,  ..., -1.7283e-02,\n",
      "           -5.0117e-03, -5.8803e-03],\n",
      "          [ 2.8808e-02,  3.0564e-02,  1.1607e-02,  ..., -1.7362e-02,\n",
      "           -5.0150e-03, -1.0946e-02]],\n",
      "\n",
      "         [[-5.8404e-04, -2.0308e-03, -1.9579e-03,  ..., -1.0613e-02,\n",
      "           -1.6424e-03, -3.1631e-03],\n",
      "          [ 1.0864e-02,  7.2803e-03,  1.0148e-02,  ..., -1.4943e-02,\n",
      "           -4.0128e-03, -2.6327e-03],\n",
      "          [ 2.1773e-02,  1.7559e-02,  2.0849e-02,  ..., -1.2382e-02,\n",
      "           -6.7413e-03,  4.5439e-04],\n",
      "          ...,\n",
      "          [ 3.7115e-03,  1.0135e-02,  7.4318e-03,  ..., -1.8424e-03,\n",
      "            6.1173e-03,  4.5774e-03],\n",
      "          [ 1.2217e-02,  1.5697e-02,  1.3970e-02,  ..., -3.2188e-03,\n",
      "            3.0497e-03,  4.0602e-04],\n",
      "          [ 1.3129e-02,  1.3444e-02,  1.1911e-02,  ..., -1.7858e-03,\n",
      "            6.0570e-04, -1.1400e-03]]]])\n",
      "torch.Size([32, 3, 40, 251])\n"
     ]
    }
   ],
   "source": [
    "clip10=clip10.transpose(2,3)\n",
    "\n",
    "print(clip10)\n",
    "print(clip10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pre-trained model (excluding the last two layers) for calculation\n",
    "clip10=encoder(clip10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.6569e-02, -4.2813e-02, -1.1728e-01,  ...,  5.5723e+00,\n",
      "            7.6509e+00,  8.5630e+00],\n",
      "          [-1.3333e-02, -2.3326e-02, -6.4651e-03,  ...,  5.3766e+00,\n",
      "            5.7731e+00,  5.5217e+00]],\n",
      "\n",
      "         [[-1.2503e-02, -7.5873e-03, -1.3628e-02,  ..., -1.4496e-01,\n",
      "            2.3696e-01,  2.6163e+00],\n",
      "          [-8.0162e-04, -6.1119e-03, -9.9317e-05,  ..., -4.8325e-02,\n",
      "            1.5870e+00,  1.8131e+00]],\n",
      "\n",
      "         [[-7.0111e-04, -9.0271e-05, -2.0155e-03,  ..., -2.2952e-01,\n",
      "           -2.7716e-01, -2.6387e-01],\n",
      "          [-3.0181e-03, -4.2751e-04, -1.1265e-03,  ..., -3.4564e-02,\n",
      "           -1.0372e-01, -1.4868e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2487e-01, -9.2145e-02,  1.8384e+00,  ...,  7.5718e+00,\n",
      "            2.1197e+00, -1.7752e-02],\n",
      "          [-4.5718e-02, -3.4824e-02,  2.2021e+00,  ...,  5.6971e+00,\n",
      "            1.4370e+00, -2.2556e-01]],\n",
      "\n",
      "         [[-1.9169e-01, -7.0096e-02, -1.9271e-01,  ..., -3.4245e-06,\n",
      "           -4.9262e-04, -4.1760e-04],\n",
      "          [-2.4165e-01, -1.1095e-01, -7.1439e-02,  ..., -1.7554e-06,\n",
      "           -1.2731e-04, -3.8483e-04]],\n",
      "\n",
      "         [[-2.4312e-01, -4.1423e-02, -3.5995e-03,  ..., -8.6385e-02,\n",
      "           -2.5267e-01, -7.1629e-02],\n",
      "          [-2.4348e-01, -1.8725e-02, -1.4192e-02,  ..., -3.6783e-03,\n",
      "           -5.5410e-02, -2.1507e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1287e-01, -2.7251e-01, -2.4823e-01,  ..., -2.4934e-01,\n",
      "           -1.4179e-01, -5.1048e-02],\n",
      "          [ 3.1657e-01, -7.6200e-02, -2.7616e-01,  ..., -2.4970e-01,\n",
      "           -8.0830e-02,  9.7065e-02]],\n",
      "\n",
      "         [[-5.8503e-03, -1.3564e-02, -5.7810e-03,  ..., -5.0432e-03,\n",
      "           -2.7427e-01, -2.0222e-01],\n",
      "          [-2.3969e-02, -2.2231e-02, -1.0822e-02,  ..., -6.0648e-02,\n",
      "            1.4870e-01,  4.2330e+00]],\n",
      "\n",
      "         [[-8.0077e-02, -1.4403e-01, -2.7784e-01,  ..., -2.4837e-03,\n",
      "           -6.4346e-03, -2.6355e-01],\n",
      "          [-6.0115e-02, -2.5988e-01, -2.4173e-01,  ..., -1.9564e-04,\n",
      "           -5.4608e-03, -2.6143e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.5481e-01, -2.1005e-01, -2.4108e-01,  ...,  1.9367e+00,\n",
      "           -2.4279e-01, -1.3881e-01],\n",
      "          [-2.6962e-01, -1.9826e-01, -2.3884e-01,  ...,  1.5854e+00,\n",
      "           -2.5405e-01,  2.3587e-02]],\n",
      "\n",
      "         [[-6.2288e-02, -2.7839e-01, -2.4420e-01,  ..., -1.6090e-01,\n",
      "           -2.6946e-01, -2.4618e-01],\n",
      "          [-4.9082e-02, -5.6527e-02, -1.8680e-01,  ..., -9.8895e-02,\n",
      "           -6.6245e-02, -9.2078e-02]],\n",
      "\n",
      "         [[-8.5100e-02, -9.1462e-02, -1.4866e-02,  ..., -1.5266e-02,\n",
      "           -1.8635e-03, -5.7249e-05],\n",
      "          [-1.3572e-01, -1.4108e-01, -7.5779e-03,  ..., -4.0164e-03,\n",
      "           -1.1536e-03, -2.5374e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3184e+00,  5.8379e+00, -3.0060e-02,  ..., -2.0928e-01,\n",
      "           -1.9292e-01, -1.2577e-01],\n",
      "          [ 8.6082e+00,  1.1958e+00, -7.9907e-02,  ...,  7.1481e-03,\n",
      "           -2.4439e-01, -7.3753e-02]],\n",
      "\n",
      "         [[-3.2427e-06, -3.4054e-07, -7.5852e-06,  ...,  1.8393e+00,\n",
      "            1.3036e+00,  3.0277e-01],\n",
      "          [-2.8799e-06, -5.4463e-07, -1.7921e-05,  ...,  4.9671e+00,\n",
      "            1.7882e+00,  9.5129e-01]],\n",
      "\n",
      "         [[-9.2779e-05, -2.7564e-01,  7.9666e-02,  ...,  2.2040e+00,\n",
      "            2.6307e+00,  1.8655e+00],\n",
      "          [-3.4716e-03, -6.8906e-02,  7.8395e-02,  ...,  2.7382e+00,\n",
      "            3.5299e+00,  2.7541e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.2121e-06, -1.1733e-04, -3.6519e-05,  ..., -5.7372e-02,\n",
      "           -7.8522e-02, -2.4710e-01],\n",
      "          [-7.2357e-04, -2.5476e-03, -3.0665e-05,  ..., -3.2868e-02,\n",
      "           -9.5070e-02, -1.9420e-01]],\n",
      "\n",
      "         [[-1.7591e-06, -1.6236e-07, -7.9866e-04,  ...,  2.5352e-02,\n",
      "           -4.0320e-02, -4.9793e-03],\n",
      "          [-2.1967e-07, -1.2913e-04, -1.4547e-03,  ..., -2.3847e-01,\n",
      "           -6.9542e-03, -1.7841e-03]],\n",
      "\n",
      "         [[ 3.1604e+00,  2.5759e+00, -1.2018e-02,  ..., -4.5809e-04,\n",
      "           -4.1014e-04, -3.2963e-03],\n",
      "          [ 1.2131e+00,  1.1637e+00, -4.4551e-02,  ..., -4.2005e-04,\n",
      "           -4.5053e-04, -4.2222e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.6543e-03, -7.9081e-03, -1.8384e-03,  ..., -8.1538e-02,\n",
      "           -6.0061e-02, -4.9892e-02],\n",
      "          [-8.3881e-03, -1.2947e-02, -2.2762e-03,  ..., -2.6642e-02,\n",
      "           -1.4023e-01, -1.1342e-01]],\n",
      "\n",
      "         [[-1.3013e-04, -1.3537e-04, -3.1751e-03,  ..., -2.4883e-01,\n",
      "           -8.7257e-02, -2.0436e-02],\n",
      "          [-2.4302e-03, -4.3394e-03, -1.5312e-02,  ..., -2.7118e-01,\n",
      "            7.5191e-01, -1.6822e-01]],\n",
      "\n",
      "         [[-1.1206e-03, -6.2311e-04, -2.6411e-04,  ..., -5.5971e-02,\n",
      "           -1.2771e-01,  7.5444e-01],\n",
      "          [-1.4836e-02, -1.8856e-04, -7.8932e-05,  ..., -2.9766e-02,\n",
      "           -1.1121e-01,  3.1620e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.4910e-02, -2.3363e-02, -6.9699e-02,  ..., -2.5908e-01,\n",
      "           -2.6268e-01, -6.4960e-02],\n",
      "          [-1.1030e-01, -3.9280e-02, -2.5857e-01,  ..., -1.2948e-01,\n",
      "           -1.2969e-01, -7.3625e-02]],\n",
      "\n",
      "         [[-2.0049e-01, -6.6454e-02, -1.6715e-01,  ..., -2.0495e-01,\n",
      "           -2.7826e-01,  1.5981e+00],\n",
      "          [-1.8766e-01,  9.0340e-01,  2.5258e+00,  ..., -4.5320e-02,\n",
      "           -1.1122e-01,  4.5145e+00]],\n",
      "\n",
      "         [[ 3.3646e+00,  4.4535e+00,  3.9194e+00,  ..., -1.5393e-03,\n",
      "           -9.8785e-04, -2.1216e-03],\n",
      "          [ 4.4815e+00,  6.8491e+00,  3.6242e+00,  ..., -3.4762e-04,\n",
      "           -7.5983e-05, -1.5118e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.2544e-02, -1.9427e-02, -4.2584e-03,  ..., -3.4452e-03,\n",
      "           -4.8424e-04, -7.1568e-05],\n",
      "          [-1.2752e-02, -3.1398e-02, -5.3832e-03,  ..., -4.4092e-04,\n",
      "           -2.4111e-03, -1.1258e-03]],\n",
      "\n",
      "         [[-6.4877e-02,  3.0238e+00,  5.9992e+00,  ..., -7.6899e-03,\n",
      "           -2.3070e-02, -4.2386e-02],\n",
      "          [-2.3671e-01,  2.2121e+00,  2.0627e+00,  ..., -6.0604e-02,\n",
      "           -4.1061e-03, -5.1659e-02]],\n",
      "\n",
      "         [[-1.2774e-02, -3.4543e-02, -1.2914e-02,  ..., -3.3201e-05,\n",
      "           -2.4082e-03, -2.2901e-01],\n",
      "          [-1.0199e-02, -4.4467e-03, -5.0573e-03,  ..., -1.9778e-05,\n",
      "           -5.1490e-04, -1.1152e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.0260e-02, -2.3844e-01,  3.6515e-01,  ..., -4.4147e-02,\n",
      "           -7.3508e-03, -1.6454e-01],\n",
      "          [-1.6657e-01, -1.3502e-01,  7.8259e-01,  ..., -3.7751e-03,\n",
      "           -3.9008e-02, -1.6822e-01]],\n",
      "\n",
      "         [[ 1.3494e+00, -1.5522e-01, -1.6224e-01,  ...,  2.3227e+00,\n",
      "            5.6605e-01,  1.8370e+00],\n",
      "          [-2.6895e-01,  1.6431e+00, -2.3348e-01,  ...,  7.5460e-01,\n",
      "            1.7913e+00, -1.9883e-01]],\n",
      "\n",
      "         [[ 1.2477e+00, -2.7348e-01, -1.3376e-01,  ..., -2.7340e-01,\n",
      "           -1.3077e-01, -8.9271e-03],\n",
      "          [ 6.3304e-01, -2.7479e-01, -2.0788e-01,  ..., -2.6111e-01,\n",
      "           -1.0795e-01, -9.6800e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.7663e-02, -1.2350e-01, -1.3602e-02,  ..., -3.4388e-02,\n",
      "           -3.7628e-02, -4.3494e-02],\n",
      "          [-1.0053e-01, -1.0546e-01, -1.7652e-02,  ..., -6.6499e-02,\n",
      "           -4.1531e-02, -1.2677e-01]],\n",
      "\n",
      "         [[-6.2538e-07, -1.7565e-07, -1.0650e-04,  ...,  1.1679e+00,\n",
      "           -2.7263e-01, -1.9766e-01],\n",
      "          [-1.0478e-04, -6.2357e-07, -5.1250e-05,  ...,  3.1401e+00,\n",
      "            1.6946e+00, -2.4581e-01]],\n",
      "\n",
      "         [[-7.9786e-02, -1.4562e-01, -1.9868e-02,  ..., -6.4239e-02,\n",
      "           -2.7797e-01, -2.7238e-01],\n",
      "          [-2.0699e-02, -3.4967e-02, -5.3429e-03,  ..., -1.5747e-02,\n",
      "           -9.5991e-02, -1.8467e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2684e-01,  6.8140e-01, -1.7627e-03,  ...,  9.9906e-01,\n",
      "           -1.2895e-01, -2.3280e-01],\n",
      "          [-2.2358e-01, -2.3163e-01,  1.6492e+00,  ..., -4.6323e-02,\n",
      "           -1.3472e-01, -2.4605e-01]],\n",
      "\n",
      "         [[ 1.5637e+00, -5.7771e-02, -1.5434e-01,  ..., -2.6076e-02,\n",
      "           -2.2268e-02, -1.1566e-01],\n",
      "          [-1.0361e-02,  1.6373e-01, -2.7663e-01,  ..., -1.9747e-01,\n",
      "           -2.2527e-01, -2.5948e-01]],\n",
      "\n",
      "         [[-5.4662e-04, -1.1378e-04, -1.9217e-04,  ...,  4.4122e-01,\n",
      "            1.5129e+00, -2.7620e-01],\n",
      "          [-5.0131e-02, -2.6993e-03, -9.4745e-05,  ...,  1.1846e+00,\n",
      "            1.7915e+00, -2.7817e-01]]]], grad_fn=<SiluBackward0>)\n",
      "torch.Size([32, 1280, 2, 8])\n"
     ]
    }
   ],
   "source": [
    "print(clip10)\n",
    "print(clip10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of each frequency band and merge them to compress the dimension\n",
    "clip10 = torch.mean(clip10, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.4951e-02, -3.3069e-02, -6.1874e-02,  ...,  5.4745e+00,\n",
      "           6.7120e+00,  7.0424e+00],\n",
      "         [-6.6524e-03, -6.8496e-03, -6.8636e-03,  ..., -9.6645e-02,\n",
      "           9.1196e-01,  2.2147e+00],\n",
      "         [-1.8596e-03, -2.5889e-04, -1.5710e-03,  ..., -1.3204e-01,\n",
      "          -1.9044e-01, -2.0628e-01],\n",
      "         ...,\n",
      "         [-8.5292e-02, -6.3484e-02,  2.0203e+00,  ...,  6.6345e+00,\n",
      "           1.7784e+00, -1.2166e-01],\n",
      "         [-2.1667e-01, -9.0521e-02, -1.3207e-01,  ..., -2.5900e-06,\n",
      "          -3.0996e-04, -4.0122e-04],\n",
      "         [-2.4330e-01, -3.0074e-02, -8.8959e-03,  ..., -4.5032e-02,\n",
      "          -1.5404e-01, -4.6568e-02]],\n",
      "\n",
      "        [[ 5.6472e-01, -1.7435e-01, -2.6220e-01,  ..., -2.4952e-01,\n",
      "          -1.1131e-01,  2.3009e-02],\n",
      "         [-1.4909e-02, -1.7898e-02, -8.3015e-03,  ..., -3.2845e-02,\n",
      "          -6.2784e-02,  2.0154e+00],\n",
      "         [-7.0096e-02, -2.0195e-01, -2.5979e-01,  ..., -1.3397e-03,\n",
      "          -5.9477e-03, -2.6249e-01],\n",
      "         ...,\n",
      "         [-2.6221e-01, -2.0415e-01, -2.3996e-01,  ...,  1.7610e+00,\n",
      "          -2.4842e-01, -5.7610e-02],\n",
      "         [-5.5685e-02, -1.6746e-01, -2.1550e-01,  ..., -1.2990e-01,\n",
      "          -1.6785e-01, -1.6913e-01],\n",
      "         [-1.1041e-01, -1.1627e-01, -1.1222e-02,  ..., -9.6414e-03,\n",
      "          -1.5086e-03, -4.1311e-05]],\n",
      "\n",
      "        [[ 7.4633e+00,  3.5168e+00, -5.4984e-02,  ..., -1.0106e-01,\n",
      "          -2.1865e-01, -9.9760e-02],\n",
      "         [-3.0613e-06, -4.4259e-07, -1.2753e-05,  ...,  3.4032e+00,\n",
      "           1.5459e+00,  6.2703e-01],\n",
      "         [-1.7822e-03, -1.7227e-01,  7.9030e-02,  ...,  2.4711e+00,\n",
      "           3.0803e+00,  2.3098e+00],\n",
      "         ...,\n",
      "         [-3.6589e-04, -1.3325e-03, -3.3592e-05,  ..., -4.5120e-02,\n",
      "          -8.6796e-02, -2.2065e-01],\n",
      "         [-9.8936e-07, -6.4648e-05, -1.1267e-03,  ..., -1.0656e-01,\n",
      "          -2.3637e-02, -3.3817e-03],\n",
      "         [ 2.1867e+00,  1.8698e+00, -2.8284e-02,  ..., -4.3907e-04,\n",
      "          -4.3034e-04, -3.7592e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.5212e-03, -1.0428e-02, -2.0573e-03,  ..., -5.4090e-02,\n",
      "          -1.0015e-01, -8.1654e-02],\n",
      "         [-1.2802e-03, -2.2374e-03, -9.2435e-03,  ..., -2.6000e-01,\n",
      "           3.3233e-01, -9.4329e-02],\n",
      "         [-7.9784e-03, -4.0583e-04, -1.7152e-04,  ..., -4.2868e-02,\n",
      "          -1.1946e-01,  1.9582e+00],\n",
      "         ...,\n",
      "         [-7.2605e-02, -3.1322e-02, -1.6414e-01,  ..., -1.9428e-01,\n",
      "          -1.9618e-01, -6.9293e-02],\n",
      "         [-1.9407e-01,  4.1848e-01,  1.1793e+00,  ..., -1.2513e-01,\n",
      "          -1.9474e-01,  3.0563e+00],\n",
      "         [ 3.9230e+00,  5.6513e+00,  3.7718e+00,  ..., -9.4346e-04,\n",
      "          -5.3192e-04, -1.8167e-03]],\n",
      "\n",
      "        [[-2.7648e-02, -2.5412e-02, -4.8208e-03,  ..., -1.9431e-03,\n",
      "          -1.4477e-03, -5.9870e-04],\n",
      "         [-1.5079e-01,  2.6179e+00,  4.0310e+00,  ..., -3.4147e-02,\n",
      "          -1.3588e-02, -4.7022e-02],\n",
      "         [-1.1486e-02, -1.9495e-02, -8.9855e-03,  ..., -2.6489e-05,\n",
      "          -1.4616e-03, -1.7026e-01],\n",
      "         ...,\n",
      "         [-1.2841e-01, -1.8673e-01,  5.7387e-01,  ..., -2.3961e-02,\n",
      "          -2.3180e-02, -1.6638e-01],\n",
      "         [ 5.4022e-01,  7.4393e-01, -1.9786e-01,  ...,  1.5387e+00,\n",
      "           1.1787e+00,  8.1907e-01],\n",
      "         [ 9.4035e-01, -2.7413e-01, -1.7082e-01,  ..., -2.6726e-01,\n",
      "          -1.1936e-01, -9.3036e-03]],\n",
      "\n",
      "        [[-8.4096e-02, -1.1448e-01, -1.5627e-02,  ..., -5.0444e-02,\n",
      "          -3.9580e-02, -8.5134e-02],\n",
      "         [-5.2700e-05, -3.9961e-07, -7.8876e-05,  ...,  2.1540e+00,\n",
      "           7.1098e-01, -2.2174e-01],\n",
      "         [-5.0243e-02, -9.0294e-02, -1.2605e-02,  ..., -3.9993e-02,\n",
      "          -1.8698e-01, -2.2852e-01],\n",
      "         ...,\n",
      "         [-2.2521e-01,  2.2489e-01,  8.2373e-01,  ...,  4.7637e-01,\n",
      "          -1.3184e-01, -2.3943e-01],\n",
      "         [ 7.7667e-01,  5.2981e-02, -2.1549e-01,  ..., -1.1178e-01,\n",
      "          -1.2377e-01, -1.8757e-01],\n",
      "         [-2.5339e-02, -1.4065e-03, -1.4346e-04,  ...,  8.1288e-01,\n",
      "           1.6522e+00, -2.7718e-01]]], grad_fn=<MeanBackward1>)\n",
      "torch.Size([32, 1280, 8])\n"
     ]
    }
   ],
   "source": [
    "print(clip10)\n",
    "print(clip10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel smoothing\n",
    "x1 = F.max_pool1d(clip10, kernel_size=3, stride=1, padding=1)\n",
    "x2 = F.avg_pool1d(clip10, kernel_size=3, stride=1, padding=1)\n",
    "x = x1 + x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-3.0958e-02, -5.1583e-02, -1.1883e-01,  ...,  1.0742e+01,\n",
      "           1.3452e+01,  1.1627e+01],\n",
      "         [-1.1153e-02, -1.3441e-02, -9.2220e-03,  ...,  1.1510e+00,\n",
      "           3.2247e+00,  3.2569e+00],\n",
      "         [-9.6505e-04, -1.4887e-03, -1.1265e-02,  ..., -2.8853e-01,\n",
      "          -3.0830e-01, -3.2268e-01],\n",
      "         ...,\n",
      "         [-1.1308e-01,  2.6441e+00,  7.1042e+00,  ...,  1.1490e+01,\n",
      "           9.3982e+00,  2.3306e+00],\n",
      "         [-1.9292e-01, -2.3694e-01, -2.0165e-01,  ..., -8.5077e-04,\n",
      "          -2.4051e-04, -5.4703e-04],\n",
      "         [-1.2120e-01, -1.0299e-01, -2.1358e-02,  ..., -1.6043e-01,\n",
      "          -1.2691e-01, -1.1344e-01]],\n",
      "\n",
      "        [[ 6.9485e-01,  6.0745e-01, -4.0838e-01,  ...,  4.4500e-01,\n",
      "          -8.9598e-02, -6.4246e-03],\n",
      "         [-2.5845e-02, -2.2004e-02, -2.1451e-02,  ..., -4.3633e-02,\n",
      "           2.6553e+00,  2.6663e+00],\n",
      "         [-1.6078e-01, -2.4737e-01, -3.9151e-01,  ..., -1.2847e-02,\n",
      "          -9.1266e-02, -9.5428e-02],\n",
      "         ...,\n",
      "         [-3.5961e-01, -4.3960e-01, -4.3284e-01,  ...,  2.1825e+00,\n",
      "           2.2460e+00, -1.5962e-01],\n",
      "         [-1.3007e-01, -2.0190e-01, -3.1483e-01,  ..., -2.9775e-01,\n",
      "          -2.8552e-01, -2.8018e-01],\n",
      "         [-1.8597e-01, -9.0524e-02, -4.8770e-02,  ..., -7.9932e-03,\n",
      "          -3.7717e-03, -5.5794e-04]],\n",
      "\n",
      "        [[ 1.1123e+01,  1.1105e+01,  4.5978e+00,  ..., -2.7558e-01,\n",
      "          -2.3959e-01, -2.0590e-01],\n",
      "         [-1.6105e-06, -5.8616e-06, -2.2155e-04,  ...,  4.9824e+00,\n",
      "           5.2619e+00,  2.2702e+00],\n",
      "         [-5.9801e-02,  4.7355e-02,  5.5322e+00,  ...,  5.8849e+00,\n",
      "           5.7007e+00,  4.8770e+00],\n",
      "         ...,\n",
      "         [-9.3201e-04, -6.1091e-04, -5.4083e-04,  ..., -4.5335e-02,\n",
      "          -1.6264e-01, -1.8928e-01],\n",
      "         [-2.2869e-05, -3.9843e-04, -2.6076e-02,  ...,  5.4248e-01,\n",
      "          -4.7908e-02, -1.2388e-02],\n",
      "         [ 3.5389e+00,  3.5295e+00,  2.4817e+00,  ..., -1.3562e-03,\n",
      "          -1.9732e-03, -1.8269e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0837e-02, -8.0594e-03, -1.2871e-02,  ..., -7.2510e-02,\n",
      "          -1.3272e-01, -1.4225e-01],\n",
      "         [-2.4527e-03, -5.5338e-03, -1.5384e-02,  ...,  2.9447e-01,\n",
      "           3.2499e-01,  4.1166e-01],\n",
      "         [-3.2006e-03, -3.0235e-03, -5.0545e-04,  ..., -7.0843e-02,\n",
      "           2.5569e+00,  2.5712e+00],\n",
      "         ...,\n",
      "         [-6.5964e-02, -1.2068e-01, -1.1696e-01,  ..., -3.2178e-01,\n",
      "          -2.2255e-01, -1.5778e-01],\n",
      "         [ 4.9328e-01,  1.6472e+00,  1.6727e+00,  ..., -1.3396e-01,\n",
      "           3.9684e+00,  4.0101e+00],\n",
      "         [ 8.8427e+00,  1.0100e+01,  8.7540e+00,  ..., -6.3366e-03,\n",
      "          -1.6293e-03, -1.3148e-03]],\n",
      "\n",
      "        [[-4.3099e-02, -2.4115e-02, -1.2386e-02,  ..., -3.5091e-03,\n",
      "          -1.9285e-03, -1.2808e-03],\n",
      "         [ 3.4403e+00,  6.1970e+00,  9.8968e+00,  ...,  2.6806e-01,\n",
      "          -4.5174e-02, -3.3792e-02],\n",
      "         [-2.1813e-02, -2.2308e-02, -1.1827e-02,  ..., -5.6689e-04,\n",
      "          -5.7277e-02, -5.8704e-02],\n",
      "         ...,\n",
      "         [-2.3346e-01,  6.6011e-01,  7.6957e-01,  ..., -9.3000e-02,\n",
      "          -9.4354e-02, -8.6367e-02],\n",
      "         [ 1.1720e+00,  1.1060e+00,  1.9331e+00,  ...,  2.8545e+00,\n",
      "           2.7175e+00,  1.8446e+00],\n",
      "         [ 1.1624e+00,  1.1055e+00, -3.9606e-01,  ..., -3.1772e-01,\n",
      "          -1.4128e-01, -5.2191e-02]],\n",
      "\n",
      "        [[-1.5029e-01, -8.7028e-02, -5.2948e-02,  ..., -5.3838e-02,\n",
      "          -9.7965e-02, -8.1151e-02],\n",
      "         [-1.8100e-05, -4.4392e-05, -1.9037e-03,  ...,  3.1533e+00,\n",
      "           3.0351e+00,  8.7406e-01],\n",
      "         [-9.7088e-02, -6.3653e-02, -3.4618e-02,  ..., -7.5890e-02,\n",
      "          -1.9182e-01, -3.2548e-01],\n",
      "         ...,\n",
      "         [ 2.2478e-01,  1.0982e+00,  2.5855e+00,  ...,  1.7823e+00,\n",
      "           5.1141e-01, -2.5559e-01],\n",
      "         [ 1.0532e+00,  9.8139e-01, -4.6760e-02,  ..., -2.2805e-01,\n",
      "          -2.5281e-01, -2.2755e-01],\n",
      "         [-1.0322e-02, -9.1064e-03, -1.6425e-03,  ...,  2.4373e+00,\n",
      "           2.3815e+00,  2.1105e+00]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([32, 1280, 8])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.dropout(x, p=0.3, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-4.4226e-02, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-1.5933e-02, -1.9201e-02, -1.3174e-02,  ...,  1.6443e+00,\n",
       "           0.0000e+00,  4.6527e+00],\n",
       "         [-1.3786e-03, -0.0000e+00, -0.0000e+00,  ..., -4.1219e-01,\n",
       "          -4.4042e-01, -0.0000e+00],\n",
       "         ...,\n",
       "         [-1.6154e-01,  0.0000e+00,  1.0149e+01,  ...,  1.6414e+01,\n",
       "           1.3426e+01,  3.3295e+00],\n",
       "         [-2.7560e-01, -3.3849e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
       "          -0.0000e+00, -7.8146e-04],\n",
       "         [-0.0000e+00, -1.4712e-01, -3.0512e-02,  ..., -2.2918e-01,\n",
       "          -1.8130e-01, -1.6205e-01]],\n",
       "\n",
       "        [[ 9.9264e-01,  8.6778e-01, -0.0000e+00,  ...,  6.3571e-01,\n",
       "          -1.2800e-01, -9.1779e-03],\n",
       "         [-3.6922e-02, -3.1435e-02, -3.0645e-02,  ..., -6.2332e-02,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-2.2968e-01, -3.5339e-01, -5.5930e-01,  ..., -1.8352e-02,\n",
       "          -1.3038e-01, -0.0000e+00],\n",
       "         ...,\n",
       "         [-5.1373e-01, -6.2800e-01, -0.0000e+00,  ...,  3.1179e+00,\n",
       "           0.0000e+00, -2.2803e-01],\n",
       "         [-0.0000e+00, -0.0000e+00, -4.4976e-01,  ..., -4.2535e-01,\n",
       "          -4.0789e-01, -4.0026e-01],\n",
       "         [-2.6567e-01, -0.0000e+00, -6.9671e-02,  ..., -1.1419e-02,\n",
       "          -5.3882e-03, -7.9706e-04]],\n",
       "\n",
       "        [[ 1.5891e+01,  1.5864e+01,  0.0000e+00,  ..., -0.0000e+00,\n",
       "          -3.4227e-01, -0.0000e+00],\n",
       "         [-2.3008e-06, -8.3738e-06, -3.1649e-04,  ...,  0.0000e+00,\n",
       "           7.5170e+00,  3.2432e+00],\n",
       "         [-8.5430e-02,  6.7650e-02,  0.0000e+00,  ...,  8.4070e+00,\n",
       "           8.1439e+00,  6.9671e+00],\n",
       "         ...,\n",
       "         [-1.3314e-03, -8.7273e-04, -0.0000e+00,  ..., -6.4764e-02,\n",
       "          -0.0000e+00, -0.0000e+00],\n",
       "         [-0.0000e+00, -5.6918e-04, -3.7252e-02,  ...,  7.7497e-01,\n",
       "          -6.8440e-02, -1.7697e-02],\n",
       "         [ 5.0556e+00,  5.0421e+00,  0.0000e+00,  ..., -1.9375e-03,\n",
       "          -2.8189e-03, -2.6098e-03]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0000e+00, -0.0000e+00, -1.8387e-02,  ..., -0.0000e+00,\n",
       "          -1.8960e-01, -2.0322e-01],\n",
       "         [-3.5038e-03, -0.0000e+00, -2.1978e-02,  ...,  4.2067e-01,\n",
       "           4.6427e-01,  5.8808e-01],\n",
       "         [-0.0000e+00, -4.3192e-03, -7.2207e-04,  ..., -1.0120e-01,\n",
       "           3.6527e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [-0.0000e+00, -1.7239e-01, -1.6708e-01,  ..., -4.5968e-01,\n",
       "          -3.1792e-01, -2.2541e-01],\n",
       "         [ 7.0468e-01,  0.0000e+00,  2.3896e+00,  ..., -1.9136e-01,\n",
       "           5.6692e+00,  5.7288e+00],\n",
       "         [ 1.2632e+01,  1.4429e+01,  0.0000e+00,  ..., -0.0000e+00,\n",
       "          -2.3275e-03, -0.0000e+00]],\n",
       "\n",
       "        [[-6.1570e-02, -3.4449e-02, -0.0000e+00,  ..., -5.0130e-03,\n",
       "          -2.7550e-03, -0.0000e+00],\n",
       "         [ 4.9147e+00,  0.0000e+00,  1.4138e+01,  ...,  3.8295e-01,\n",
       "          -0.0000e+00, -4.8274e-02],\n",
       "         [-3.1162e-02, -3.1868e-02, -0.0000e+00,  ..., -8.0985e-04,\n",
       "          -8.1825e-02, -8.3862e-02],\n",
       "         ...,\n",
       "         [-0.0000e+00,  9.4301e-01,  1.0994e+00,  ..., -1.3286e-01,\n",
       "          -1.3479e-01, -0.0000e+00],\n",
       "         [ 1.6743e+00,  1.5800e+00,  0.0000e+00,  ...,  4.0779e+00,\n",
       "           0.0000e+00,  2.6351e+00],\n",
       "         [ 1.6606e+00,  1.5793e+00, -5.6580e-01,  ..., -4.5388e-01,\n",
       "          -2.0182e-01, -7.4559e-02]],\n",
       "\n",
       "        [[-2.1470e-01, -0.0000e+00, -7.5640e-02,  ..., -0.0000e+00,\n",
       "          -1.3995e-01, -1.1593e-01],\n",
       "         [-2.5857e-05, -6.3417e-05, -0.0000e+00,  ...,  4.5046e+00,\n",
       "           4.3359e+00,  1.2487e+00],\n",
       "         [-0.0000e+00, -9.0932e-02, -4.9455e-02,  ..., -1.0841e-01,\n",
       "          -2.7403e-01, -4.6497e-01],\n",
       "         ...,\n",
       "         [ 3.2111e-01,  0.0000e+00,  3.6936e+00,  ...,  0.0000e+00,\n",
       "           7.3058e-01, -3.6513e-01],\n",
       "         [ 1.5046e+00,  1.4020e+00, -6.6800e-02,  ..., -3.2579e-01,\n",
       "          -3.6116e-01, -3.2507e-01],\n",
       "         [-1.4745e-02, -0.0000e+00, -2.3464e-03,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  3.0151e+00]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 1280])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fully connected layer\n",
    "fc1 = nn.Linear(in_features=model.classifier.in_features, out_features=model.classifier.in_features, bias=True)\n",
    "\n",
    "# Initialize the parameters of the fully connected layer\n",
    "\n",
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight) # Initialize the weights and biases of the network layer\n",
    "\n",
    "    if hasattr(layer, \"bias\"): # Check if the layer has a bias attribute\n",
    "        if layer.bias is not None: # and bias is not None\n",
    "            layer.bias.data.fill_(0.0) # If there is a bias, initialize it to 0\n",
    "\n",
    "init_layer(fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.relu_(fc1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.8493,  0.0000,  2.2463],\n",
      "         [ 1.4956,  0.0000,  0.0000,  ...,  1.7019,  0.0000,  1.2083],\n",
      "         [ 2.9852,  0.0000,  0.0000,  ...,  1.7144,  0.0000,  7.2559],\n",
      "         ...,\n",
      "         [ 0.0000,  4.5035,  0.0000,  ...,  0.4537,  0.0000,  7.8644],\n",
      "         [ 3.3951,  6.4179,  0.0000,  ...,  2.0159,  1.4925,  8.1388],\n",
      "         [ 1.4708,  3.8314,  1.2186,  ...,  1.6265,  3.6036,  2.7818]],\n",
      "\n",
      "        [[ 3.1623,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.7630,  0.3800,  0.0000,  ...,  1.6521,  0.0000,  0.0000],\n",
      "         [ 0.4159,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  1.9986,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.6193,  0.0000,  ...,  2.4450,  0.0000,  6.3322],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.6864,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.6995,  0.0000,  0.0000,  ...,  8.2243,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.4590,  0.0000,  ...,  4.5377,  3.1403,  1.4060],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  7.1252,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  3.2341,  0.0000,  ...,  4.3599,  0.0000,  3.5086],\n",
      "         [ 1.0040,  7.4022,  0.0000,  ...,  6.0008,  0.0000,  6.5508],\n",
      "         [ 0.0000,  4.6618,  0.0000,  ...,  3.0168,  0.0000,  3.8741]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.6708,  0.0000,  6.0693,  ...,  0.0000,  2.7144,  0.3887],\n",
      "         [ 5.0489,  4.2144,  5.9194,  ...,  0.0000,  2.9868,  0.0000],\n",
      "         [ 7.6485,  2.3970,  2.4515,  ...,  0.0000,  0.7989,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  2.9252,  0.2287,  0.2604],\n",
      "         [ 0.0000,  0.0000,  2.4042,  ...,  0.0000,  0.0000,  3.2064],\n",
      "         [ 2.2082,  2.6391,  0.0000,  ...,  2.0332,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 5.0824,  0.0000,  0.0000,  ...,  5.9315,  0.0000,  1.7890],\n",
      "         [ 5.1805,  0.0000,  0.0000,  ...,  9.5063,  0.0000,  0.0000],\n",
      "         [ 2.5619,  0.0000,  0.0000,  ...,  7.6039,  1.8064,  1.2012],\n",
      "         ...,\n",
      "         [ 1.2139,  0.0000,  0.0000,  ...,  8.7555,  0.0000,  2.3350],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., 12.1567,  0.0000,  1.8053],\n",
      "         [ 2.2383,  0.0000,  0.0000,  ...,  5.0030,  0.0000,  1.6835]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  1.9493,  ...,  1.1800,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.9838,  1.7939,  ...,  0.1293,  0.0000,  0.0000],\n",
      "         [ 0.0000,  4.9523,  2.2497,  ...,  1.1559,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 3.3744,  3.8109,  2.5078,  ...,  9.6770,  3.0101,  0.0000],\n",
      "         [ 0.1300,  2.8286,  0.9805,  ...,  4.4998,  0.0000,  0.0000],\n",
      "         [ 0.0000,  2.4572,  0.3725,  ...,  0.4334,  0.0000,  0.0000]]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "torch.Size([32, 8, 1280])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  1.4956,  2.9852,  ...,  0.0000,  3.3951,  1.4708],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  4.5035,  6.4179,  3.8314],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.2186],\n",
      "         ...,\n",
      "         [ 0.8493,  1.7019,  1.7144,  ...,  0.4537,  2.0159,  1.6265],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.4925,  3.6036],\n",
      "         [ 2.2463,  1.2083,  7.2559,  ...,  7.8644,  8.1388,  2.7818]],\n",
      "\n",
      "        [[ 3.1623,  0.7630,  0.4159,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.3800,  0.0000,  ...,  1.9986,  0.6193,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  1.6521,  0.0000,  ...,  0.0000,  2.4450,  1.6864],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  6.3322,  0.0000]],\n",
      "\n",
      "        [[ 0.6995,  0.0000,  0.0000,  ...,  0.0000,  1.0040,  0.0000],\n",
      "         [ 0.0000,  0.4590,  0.0000,  ...,  3.2341,  7.4022,  4.6618],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 8.2243,  4.5377,  7.1252,  ...,  4.3599,  6.0008,  3.0168],\n",
      "         [ 0.0000,  3.1403,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  1.4060,  0.0000,  ...,  3.5086,  6.5508,  3.8741]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.6708,  5.0489,  7.6485,  ...,  0.0000,  0.0000,  2.2082],\n",
      "         [ 0.0000,  4.2144,  2.3970,  ...,  0.0000,  0.0000,  2.6391],\n",
      "         [ 6.0693,  5.9194,  2.4515,  ...,  0.0000,  2.4042,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  2.9252,  0.0000,  2.0332],\n",
      "         [ 2.7144,  2.9868,  0.7989,  ...,  0.2287,  0.0000,  0.0000],\n",
      "         [ 0.3887,  0.0000,  0.0000,  ...,  0.2604,  3.2064,  0.0000]],\n",
      "\n",
      "        [[ 5.0824,  5.1805,  2.5619,  ...,  1.2139,  0.0000,  2.2383],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 5.9315,  9.5063,  7.6039,  ...,  8.7555, 12.1567,  5.0030],\n",
      "         [ 0.0000,  0.0000,  1.8064,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 1.7890,  0.0000,  1.2012,  ...,  2.3350,  1.8053,  1.6835]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  3.3744,  0.1300,  0.0000],\n",
      "         [ 0.0000,  0.9838,  4.9523,  ...,  3.8109,  2.8286,  2.4572],\n",
      "         [ 1.9493,  1.7939,  2.2497,  ...,  2.5078,  0.9805,  0.3725],\n",
      "         ...,\n",
      "         [ 1.1800,  0.1293,  1.1559,  ...,  9.6770,  4.4998,  0.4334],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  3.0101,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "torch.Size([32, 1280, 8])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.dropout(x, p=0.3, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  2.1366,  4.2645,  ...,  0.0000,  4.8502,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  6.4335,  0.0000,  5.4734],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.7409],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  2.4492,  ...,  0.6481,  2.8799,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  5.1480],\n",
      "         [ 3.2090,  1.7262,  0.0000,  ..., 11.2349, 11.6268,  3.9740]],\n",
      "\n",
      "        [[ 4.5176,  1.0900,  0.5942,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.5429,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  2.3601,  0.0000,  ...,  0.0000,  3.4928,  2.4091],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  9.0460,  0.0000]],\n",
      "\n",
      "        [[ 0.9993,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.6557,  0.0000,  ...,  4.6201,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [11.7490,  0.0000, 10.1789,  ...,  6.2285,  8.5726,  4.3097],\n",
      "         [ 0.0000,  4.4862,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  5.0123,  9.3583,  5.5344]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.8155,  7.2127, 10.9265,  ...,  0.0000,  0.0000,  3.1546],\n",
      "         [ 0.0000,  6.0206,  3.4243,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  8.4562,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  4.1789,  0.0000,  2.9046],\n",
      "         [ 0.0000,  4.2669,  1.1412,  ...,  0.3267,  0.0000,  0.0000],\n",
      "         [ 0.5553,  0.0000,  0.0000,  ...,  0.3720,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  3.6599,  ...,  1.7342,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 8.4735, 13.5805, 10.8628,  ...,  0.0000, 17.3668,  7.1472],\n",
      "         [ 0.0000,  0.0000,  2.5806,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 2.5558,  0.0000,  1.7159,  ...,  3.3357,  2.5791,  2.4050]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  1.4055,  7.0747,  ...,  5.4442,  4.0409,  3.5103],\n",
      "         [ 2.7848,  2.5627,  3.2138,  ...,  3.5826,  1.4008,  0.5321],\n",
      "         ...,\n",
      "         [ 1.6857,  0.1847,  1.6513,  ...,  0.0000,  6.4283,  0.6192],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  4.3001,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "torch.Size([32, 1280, 8])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later we want to pass the acquired high-dimensional features into an attention module\n",
    "\n",
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "        # x: This is the final output after the attention weights and classification layer.\n",
    "        # shape: (n_samples, out_features). Since the time dimension is summed and compressed, each sample and each output feature ends up having a single value.\n",
    "        # norm_att: This is the output of the attention layer (att) after the softmax and tanh functions, which shows which parts of the input sequence the model should focus on. Normalization ensures that the attention weights for all time steps add up to 1, which makes it easier to interpret the importance of each time step.\n",
    "        # shape: (n_samples, out_features, n_time), where out_features is the number of output features of the att convolutional layer, which is the same as the out_features argument of the input. Each time step and each output feature has a normalized weight.\n",
    "        # cla: This is the output of the classification layer (cla), which is obtained by processing the input features through another 1D convolutional layer. This output layer is often used to directly predict task-related outputs, such as the probability of a class label.\n",
    "        # Shape: (n_samples, out_features, n_time), same shape as norm_att. This means that each output feature corresponding to each time step has a value processed by the activation function.\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == \"linear\":\n",
    "            return x\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_block=AttBlockV2(in_features=model.classifier.in_features, out_features=182, activation=\"sigmoid\")\n",
    "\n",
    "\n",
    "(clipwise_output, norm_att, segmentwise_output) = att_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7606, 0.3648, 0.1297,  ..., 0.6144, 0.5173, 0.3312],\n",
      "        [0.1332, 0.4221, 0.1250,  ..., 0.1752, 0.4603, 0.2061],\n",
      "        [0.3576, 0.3903, 0.2409,  ..., 0.0723, 0.3924, 0.6862],\n",
      "        ...,\n",
      "        [0.1907, 0.4924, 0.4743,  ..., 0.0145, 0.5626, 0.7469],\n",
      "        [0.3258, 0.2783, 0.3120,  ..., 0.0737, 0.5454, 0.4005],\n",
      "        [0.2966, 0.3888, 0.1759,  ..., 0.0054, 0.5776, 0.5563]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "torch.Size([32, 182])\n"
     ]
    }
   ],
   "source": [
    "print(clipwise_output)\n",
    "print(clipwise_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0706, 0.5008, 0.0730,  ..., 0.0691, 0.0691, 0.0691],\n",
      "         [0.2468, 0.0998, 0.2456,  ..., 0.0348, 0.0494, 0.0337],\n",
      "         [0.0472, 0.1451, 0.1458,  ..., 0.1446, 0.0950, 0.1317],\n",
      "         ...,\n",
      "         [0.0682, 0.0682, 0.0682,  ..., 0.0682, 0.0883, 0.5012],\n",
      "         [0.1257, 0.1206, 0.1257,  ..., 0.1257, 0.1251, 0.1257],\n",
      "         [0.1830, 0.0559, 0.0558,  ..., 0.0558, 0.3998, 0.1381]],\n",
      "\n",
      "        [[0.0944, 0.0687, 0.0688,  ..., 0.4915, 0.0687, 0.0701],\n",
      "         [0.0717, 0.1065, 0.0428,  ..., 0.2911, 0.0430, 0.0831],\n",
      "         [0.0611, 0.3514, 0.2741,  ..., 0.0517, 0.0518, 0.0517],\n",
      "         ...,\n",
      "         [0.0420, 0.0426, 0.0430,  ..., 0.0439, 0.3059, 0.2237],\n",
      "         [0.1413, 0.1417, 0.1302,  ..., 0.1417, 0.1417, 0.1417],\n",
      "         [0.1131, 0.1132, 0.1135,  ..., 0.1131, 0.1130, 0.1961]],\n",
      "\n",
      "        [[0.0287, 0.0287, 0.0286,  ..., 0.2110, 0.2109, 0.2109],\n",
      "         [0.1527, 0.1257, 0.0219,  ..., 0.1527, 0.1060, 0.1494],\n",
      "         [0.2474, 0.2474, 0.0335,  ..., 0.0336, 0.0336, 0.1225],\n",
      "         ...,\n",
      "         [0.0398, 0.0602, 0.2570,  ..., 0.0692, 0.2568, 0.2469],\n",
      "         [0.1407, 0.1406, 0.1405,  ..., 0.1325, 0.1407, 0.1407],\n",
      "         [0.1111, 0.1112, 0.1115,  ..., 0.1499, 0.1111, 0.1830]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1165, 0.0729, 0.0672,  ..., 0.0668, 0.0668, 0.0668],\n",
      "         [0.1566, 0.1566, 0.1566,  ..., 0.0377, 0.0302, 0.1492],\n",
      "         [0.0358, 0.0440, 0.0366,  ..., 0.2630, 0.1144, 0.2073],\n",
      "         ...,\n",
      "         [0.1249, 0.1249, 0.1249,  ..., 0.1252, 0.1249, 0.1249],\n",
      "         [0.1640, 0.1640, 0.1640,  ..., 0.0235, 0.0230, 0.1474],\n",
      "         [0.1667, 0.4001, 0.0556,  ..., 0.0541, 0.0541, 0.0541]],\n",
      "\n",
      "        [[0.0328, 0.1883, 0.1559,  ..., 0.1887, 0.0442, 0.0261],\n",
      "         [0.1580, 0.1640, 0.1512,  ..., 0.1641, 0.0223, 0.0302],\n",
      "         [0.2483, 0.1660, 0.2493,  ..., 0.0341, 0.1999, 0.0341],\n",
      "         ...,\n",
      "         [0.0695, 0.0695, 0.0697,  ..., 0.0695, 0.5134, 0.0695],\n",
      "         [0.0505, 0.1383, 0.1638,  ..., 0.2140, 0.0399, 0.0638],\n",
      "         [0.0770, 0.0767, 0.0849,  ..., 0.0749, 0.0749, 0.0749]],\n",
      "\n",
      "        [[0.2499, 0.2538, 0.2533,  ..., 0.1039, 0.0353, 0.0345],\n",
      "         [0.2813, 0.2811, 0.2285,  ..., 0.0386, 0.0489, 0.0442],\n",
      "         [0.2569, 0.0631, 0.2479,  ..., 0.0350, 0.0612, 0.0420],\n",
      "         ...,\n",
      "         [0.4591, 0.0637, 0.0777,  ..., 0.0637, 0.0675, 0.0639],\n",
      "         [0.1085, 0.0238, 0.0300,  ..., 0.1759, 0.1686, 0.1758],\n",
      "         [0.0638, 0.0486, 0.2925,  ..., 0.0479, 0.3506, 0.1012]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([32, 182, 8])\n"
     ]
    }
   ],
   "source": [
    "print(norm_att)\n",
    "print(norm_att.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.3260e-01, 7.6388e-01, 9.8241e-01,  ..., 9.9195e-01,\n",
      "          8.3926e-01, 9.2274e-01],\n",
      "         [9.2157e-01, 4.2898e-01, 9.4977e-02,  ..., 8.6080e-01,\n",
      "          6.6333e-02, 1.0297e-02],\n",
      "         [5.0828e-01, 4.3726e-02, 8.2208e-04,  ..., 3.2264e-04,\n",
      "          8.8152e-04, 3.2245e-02],\n",
      "         ...,\n",
      "         [1.6388e-02, 5.7675e-01, 3.0566e-02,  ..., 4.0920e-01,\n",
      "          8.9302e-02, 9.4412e-01],\n",
      "         [2.3313e-01, 9.9041e-02, 4.7421e-01,  ..., 9.9710e-01,\n",
      "          9.3333e-01, 9.9261e-01],\n",
      "         [9.4480e-01, 2.2029e-01, 3.5299e-01,  ..., 9.9298e-01,\n",
      "          8.4289e-03, 9.1082e-02]],\n",
      "\n",
      "        [[2.9726e-01, 5.3759e-02, 1.4502e-01,  ..., 7.6063e-02,\n",
      "          7.7011e-03, 6.6838e-01],\n",
      "         [8.5680e-01, 7.5084e-01, 9.1159e-01,  ..., 7.0751e-01,\n",
      "          6.9029e-03, 2.7388e-01],\n",
      "         [1.1977e-01, 7.3634e-02, 1.2665e-02,  ..., 4.7414e-02,\n",
      "          6.2078e-01, 9.6099e-01],\n",
      "         ...,\n",
      "         [1.4380e-01, 6.6253e-02, 1.4006e-01,  ..., 3.5708e-01,\n",
      "          1.1437e-02, 1.0242e-02],\n",
      "         [6.0863e-01, 2.0301e-01, 9.2344e-01,  ..., 5.5511e-01,\n",
      "          2.3058e-04, 7.1455e-03],\n",
      "         [9.1089e-02, 4.8054e-01, 2.9200e-03,  ..., 2.8293e-01,\n",
      "          8.9032e-02, 4.1210e-01]],\n",
      "\n",
      "        [[9.9184e-01, 1.4014e-01, 5.3392e-02,  ..., 9.8472e-01,\n",
      "          5.3133e-01, 1.6114e-02],\n",
      "         [5.0887e-02, 3.3939e-01, 9.9545e-01,  ..., 1.1572e-01,\n",
      "          6.2750e-02, 4.3907e-01],\n",
      "         [1.7145e-01, 2.0552e-02, 6.9406e-01,  ..., 9.9875e-01,\n",
      "          9.2145e-01, 7.0695e-01],\n",
      "         ...,\n",
      "         [2.9509e-05, 1.1689e-01, 4.8706e-04,  ..., 1.8464e-04,\n",
      "          6.6198e-04, 4.3814e-02],\n",
      "         [7.1946e-01, 2.2916e-07, 2.3236e-05,  ..., 9.9699e-01,\n",
      "          4.8103e-01, 6.0160e-01],\n",
      "         [9.9836e-01, 1.0323e-05, 4.6059e-01,  ..., 3.5035e-01,\n",
      "          9.9559e-01, 9.3210e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[4.1968e-02, 5.0393e-01, 8.4754e-01,  ..., 2.9295e-01,\n",
      "          5.7880e-03, 2.8241e-01],\n",
      "         [8.1351e-01, 9.8393e-01, 1.3812e-04,  ..., 2.1587e-03,\n",
      "          5.3090e-01, 4.0491e-04],\n",
      "         [6.1397e-02, 9.9477e-01, 9.9073e-01,  ..., 5.2477e-02,\n",
      "          9.1859e-01, 9.8614e-01],\n",
      "         ...,\n",
      "         [6.9382e-03, 1.4360e-04, 4.4267e-03,  ..., 3.8017e-02,\n",
      "          1.0325e-03, 6.3173e-02],\n",
      "         [9.9374e-01, 3.5880e-04, 5.9374e-01,  ..., 1.8216e-04,\n",
      "          4.7072e-01, 9.9851e-01],\n",
      "         [3.7324e-02, 9.9991e-01, 1.8917e-03,  ..., 9.4739e-01,\n",
      "          9.9490e-01, 9.9756e-01]],\n",
      "\n",
      "        [[8.1330e-01, 8.9880e-02, 9.1690e-01,  ..., 7.0062e-01,\n",
      "          9.4645e-06, 5.6711e-02],\n",
      "         [6.1751e-02, 4.7742e-01, 9.9968e-01,  ..., 3.1740e-03,\n",
      "          2.2769e-04, 8.6631e-03],\n",
      "         [2.2639e-02, 1.1935e-02, 8.7497e-01,  ..., 9.5448e-01,\n",
      "          1.9004e-01, 3.8269e-04],\n",
      "         ...,\n",
      "         [1.0750e-02, 2.2956e-02, 1.1805e-02,  ..., 5.0977e-01,\n",
      "          1.5381e-04, 1.4054e-04],\n",
      "         [1.9826e-02, 8.2370e-03, 1.3691e-01,  ..., 9.3715e-01,\n",
      "          6.2439e-02, 6.5761e-01],\n",
      "         [7.0980e-01, 9.8839e-01, 8.5960e-04,  ..., 8.2155e-01,\n",
      "          9.8912e-01, 9.7452e-01]],\n",
      "\n",
      "        [[2.9191e-02, 2.6118e-05, 9.9973e-01,  ..., 1.3457e-03,\n",
      "          1.1909e-02, 4.7885e-02],\n",
      "         [3.1400e-01, 3.4415e-01, 4.3668e-01,  ..., 4.9456e-01,\n",
      "          1.9090e-01, 8.7727e-02],\n",
      "         [4.8614e-01, 1.6765e-02, 1.0737e-03,  ..., 1.4582e-01,\n",
      "          3.9081e-03, 8.7794e-01],\n",
      "         ...,\n",
      "         [2.2402e-03, 5.0082e-02, 1.3802e-03,  ..., 6.4831e-03,\n",
      "          7.1305e-03, 2.1550e-03],\n",
      "         [2.3768e-02, 6.8176e-01, 9.9283e-01,  ..., 8.0814e-01,\n",
      "          1.6848e-02, 3.8895e-01],\n",
      "         [9.2870e-01, 2.0025e-01, 2.2295e-02,  ..., 3.5861e-01,\n",
      "          9.8270e-01, 7.0914e-01]]], grad_fn=<SigmoidBackward0>)\n",
      "torch.Size([32, 182, 8])\n"
     ]
    }
   ],
   "source": [
    "print(segmentwise_output)\n",
    "print(segmentwise_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentwise_logit = att_block.cla(x).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ -0.2713,   2.4638,   0.0331,  ...,  -4.0947,  -1.1907,   2.8400],\n",
      "         [  1.1741,  -0.2860,  -3.0851,  ...,   0.3095,  -2.2079,  -1.2640],\n",
      "         [  4.0224,  -2.2543,  -7.1029,  ...,  -3.4568,  -0.1033,  -0.6059],\n",
      "         ...,\n",
      "         [  4.8146,   1.8220,  -8.0387,  ...,  -0.3673,   5.8394,   4.9515],\n",
      "         [  1.6528,  -2.6444,  -7.0330,  ...,  -2.3222,   2.6389,  -4.7676],\n",
      "         [  2.4801,  -4.5656,  -3.4016,  ...,   2.8271,   4.9005,  -2.3005]],\n",
      "\n",
      "        [[ -0.8604,   1.7889,  -1.9946,  ...,  -1.7841,   0.4416,  -2.3004],\n",
      "         [ -2.8680,   1.1031,  -2.5322,  ...,  -2.6457,  -1.3676,  -0.0779],\n",
      "         [ -1.7742,   2.3332,  -4.3562,  ...,  -1.8148,   2.4901,  -5.8333],\n",
      "         ...,\n",
      "         [ -2.4971,   0.8833,  -3.0003,  ...,  -0.5880,   0.2213,  -0.9300],\n",
      "         [ -4.8587,  -4.9689,   0.4929,  ...,  -4.4594,  -8.3747,  -2.3255],\n",
      "         [  0.7008,  -0.9750,   3.2043,  ...,  -4.5710,  -4.9341,  -0.3553]],\n",
      "\n",
      "        [[  4.7997,  -2.9259,  -1.5754,  ..., -10.4308,   0.9418,   6.4117],\n",
      "         [ -1.8141,  -0.6660,  -3.8640,  ...,  -2.0222, -15.2888, -11.4811],\n",
      "         [ -2.8752,   5.3881,   0.8192,  ...,  -7.6266, -10.6698,  -0.1580],\n",
      "         ...,\n",
      "         [  4.1660,  -2.0336,   6.6845,  ...,  -8.5969,   5.8026,  -0.6175],\n",
      "         [  0.1255,  -2.7038,   2.4623,  ...,  -7.3196,  -0.0759,   5.4196],\n",
      "         [ -4.1118,  -0.2449,   0.8806,  ...,  -3.0830,   0.4121,   2.6194]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -3.1280,   1.4730,  -2.7270,  ...,  -4.9637,   5.0672,  -3.2501],\n",
      "         [  0.0157,   4.1144,   5.2474,  ...,  -8.8484,  -7.9324,   9.3276],\n",
      "         [  1.7154,  -8.8873,   4.6720,  ...,  -5.4157,   0.3795,  -6.2684],\n",
      "         ...,\n",
      "         [ -0.8811,  -6.1361,  -2.8935,  ...,  -3.2310,  -8.6104,   2.8908],\n",
      "         [ -5.1462,   0.1238,   2.4233,  ...,  -6.8748,  -0.1172,   5.2730],\n",
      "         [ -0.9325,  -7.8114,   4.2646,  ...,  -2.6966,   6.5049,   6.0127]],\n",
      "\n",
      "        [[  1.4716,  -2.7209,  -3.7652,  ...,  -4.5221,  -3.9008,   0.8944],\n",
      "         [ -2.3151,  -0.0904,  -4.4163,  ...,  -3.7509,  -4.7908,   4.4445],\n",
      "         [  2.4009,   8.0613,   1.9456,  ...,  -4.4273,  -1.8412,  -7.0582],\n",
      "         ...,\n",
      "         [  0.8503,  -5.7496,   3.0431,  ...,   0.0391,   2.7022,   1.5269],\n",
      "         [-11.5680,  -8.3873,  -1.4498,  ...,  -8.7796,  -2.7091,   4.5096],\n",
      "         [ -2.8114,  -4.7400,  -7.8679,  ...,  -8.8698,   0.6527,   3.6439]],\n",
      "\n",
      "        [[ -3.5043,  -0.7815,  -0.0554,  ...,  -6.0990,  -3.7154,   2.5669],\n",
      "         [-10.5529,  -0.6448,  -4.0716,  ...,  -2.9427,   0.7619,  -1.3847],\n",
      "         [  8.2089,  -0.2547,  -6.8356,  ...,  -6.5841,   4.9303,  -3.7809],\n",
      "         ...,\n",
      "         [ -6.6095,  -0.0218,  -1.7678,  ...,  -5.0321,   1.4379,  -0.5814],\n",
      "         [ -4.4185,  -1.4442,  -5.5408,  ...,  -4.9362,  -4.0665,   4.0398],\n",
      "         [ -2.9899,  -2.3417,   1.9731,  ...,  -6.1378,  -0.4517,   0.8912]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "torch.Size([32, 8, 182])\n"
     ]
    }
   ],
   "source": [
    "print(segmentwise_logit)\n",
    "print(segmentwise_logit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentwise_output = segmentwise_output.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.3260e-01, 9.2157e-01, 5.0828e-01,  ..., 1.6388e-02,\n",
      "          2.3313e-01, 9.4480e-01],\n",
      "         [7.6388e-01, 4.2898e-01, 4.3726e-02,  ..., 5.7675e-01,\n",
      "          9.9041e-02, 2.2029e-01],\n",
      "         [9.8241e-01, 9.4977e-02, 8.2208e-04,  ..., 3.0566e-02,\n",
      "          4.7421e-01, 3.5299e-01],\n",
      "         ...,\n",
      "         [9.9195e-01, 8.6080e-01, 3.2264e-04,  ..., 4.0920e-01,\n",
      "          9.9710e-01, 9.9298e-01],\n",
      "         [8.3926e-01, 6.6333e-02, 8.8152e-04,  ..., 8.9302e-02,\n",
      "          9.3333e-01, 8.4289e-03],\n",
      "         [9.2274e-01, 1.0297e-02, 3.2245e-02,  ..., 9.4412e-01,\n",
      "          9.9261e-01, 9.1082e-02]],\n",
      "\n",
      "        [[2.9726e-01, 8.5680e-01, 1.1977e-01,  ..., 1.4380e-01,\n",
      "          6.0863e-01, 9.1089e-02],\n",
      "         [5.3759e-02, 7.5084e-01, 7.3634e-02,  ..., 6.6253e-02,\n",
      "          2.0301e-01, 4.8054e-01],\n",
      "         [1.4502e-01, 9.1159e-01, 1.2665e-02,  ..., 1.4006e-01,\n",
      "          9.2344e-01, 2.9200e-03],\n",
      "         ...,\n",
      "         [7.6063e-02, 7.0751e-01, 4.7414e-02,  ..., 3.5708e-01,\n",
      "          5.5511e-01, 2.8293e-01],\n",
      "         [7.7011e-03, 6.9029e-03, 6.2078e-01,  ..., 1.1437e-02,\n",
      "          2.3058e-04, 8.9032e-02],\n",
      "         [6.6838e-01, 2.7388e-01, 9.6099e-01,  ..., 1.0242e-02,\n",
      "          7.1455e-03, 4.1210e-01]],\n",
      "\n",
      "        [[9.9184e-01, 5.0887e-02, 1.7145e-01,  ..., 2.9509e-05,\n",
      "          7.1946e-01, 9.9836e-01],\n",
      "         [1.4014e-01, 3.3939e-01, 2.0552e-02,  ..., 1.1689e-01,\n",
      "          2.2916e-07, 1.0323e-05],\n",
      "         [5.3392e-02, 9.9545e-01, 6.9406e-01,  ..., 4.8706e-04,\n",
      "          2.3236e-05, 4.6059e-01],\n",
      "         ...,\n",
      "         [9.8472e-01, 1.1572e-01, 9.9875e-01,  ..., 1.8464e-04,\n",
      "          9.9699e-01, 3.5035e-01],\n",
      "         [5.3133e-01, 6.2750e-02, 9.2145e-01,  ..., 6.6198e-04,\n",
      "          4.8103e-01, 9.9559e-01],\n",
      "         [1.6114e-02, 4.3907e-01, 7.0695e-01,  ..., 4.3814e-02,\n",
      "          6.0160e-01, 9.3210e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[4.1968e-02, 8.1351e-01, 6.1397e-02,  ..., 6.9382e-03,\n",
      "          9.9374e-01, 3.7324e-02],\n",
      "         [5.0393e-01, 9.8393e-01, 9.9477e-01,  ..., 1.4360e-04,\n",
      "          3.5880e-04, 9.9991e-01],\n",
      "         [8.4754e-01, 1.3812e-04, 9.9073e-01,  ..., 4.4267e-03,\n",
      "          5.9374e-01, 1.8917e-03],\n",
      "         ...,\n",
      "         [2.9295e-01, 2.1587e-03, 5.2477e-02,  ..., 3.8017e-02,\n",
      "          1.8216e-04, 9.4739e-01],\n",
      "         [5.7880e-03, 5.3090e-01, 9.1859e-01,  ..., 1.0325e-03,\n",
      "          4.7072e-01, 9.9490e-01],\n",
      "         [2.8241e-01, 4.0491e-04, 9.8614e-01,  ..., 6.3173e-02,\n",
      "          9.9851e-01, 9.9756e-01]],\n",
      "\n",
      "        [[8.1330e-01, 6.1751e-02, 2.2639e-02,  ..., 1.0750e-02,\n",
      "          1.9826e-02, 7.0980e-01],\n",
      "         [8.9880e-02, 4.7742e-01, 1.1935e-02,  ..., 2.2956e-02,\n",
      "          8.2370e-03, 9.8839e-01],\n",
      "         [9.1690e-01, 9.9968e-01, 8.7497e-01,  ..., 1.1805e-02,\n",
      "          1.3691e-01, 8.5960e-04],\n",
      "         ...,\n",
      "         [7.0062e-01, 3.1740e-03, 9.5448e-01,  ..., 5.0977e-01,\n",
      "          9.3715e-01, 8.2155e-01],\n",
      "         [9.4645e-06, 2.2769e-04, 1.9004e-01,  ..., 1.5381e-04,\n",
      "          6.2439e-02, 9.8912e-01],\n",
      "         [5.6711e-02, 8.6631e-03, 3.8269e-04,  ..., 1.4054e-04,\n",
      "          6.5761e-01, 9.7452e-01]],\n",
      "\n",
      "        [[2.9191e-02, 3.1400e-01, 4.8614e-01,  ..., 2.2402e-03,\n",
      "          2.3768e-02, 9.2870e-01],\n",
      "         [2.6118e-05, 3.4415e-01, 1.6765e-02,  ..., 5.0082e-02,\n",
      "          6.8176e-01, 2.0025e-01],\n",
      "         [9.9973e-01, 4.3668e-01, 1.0737e-03,  ..., 1.3802e-03,\n",
      "          9.9283e-01, 2.2295e-02],\n",
      "         ...,\n",
      "         [1.3457e-03, 4.9456e-01, 1.4582e-01,  ..., 6.4831e-03,\n",
      "          8.0814e-01, 3.5861e-01],\n",
      "         [1.1909e-02, 1.9090e-01, 3.9081e-03,  ..., 7.1305e-03,\n",
      "          1.6848e-02, 9.8270e-01],\n",
      "         [4.7885e-02, 8.7727e-02, 8.7794e-01,  ..., 2.1550e-03,\n",
      "          3.8895e-01, 7.0914e-01]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([32, 8, 182])\n"
     ]
    }
   ],
   "source": [
    "print(segmentwise_output)\n",
    "print(segmentwise_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_ratio = frames_num // segmentwise_output.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolate_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0.5 * loss_function(torch.logit(clipwise_output), audio_label9) + 0.5 * loss_function(segmentwise_logit.max(1)[0], audio_label9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1261, 1.4997, 0.4244,  ..., 1.9188, 3.2854, 2.6804],\n",
      "        [0.6234, 1.4871, 1.6888,  ..., 0.4304, 1.5933, 0.4429],\n",
      "        [2.6252, 2.9437, 3.4807,  ..., 1.3277, 3.1519, 3.7862],\n",
      "        ...,\n",
      "        [1.0462, 2.4043, 2.9479,  ..., 0.0399, 3.6667, 5.3508],\n",
      "        [1.4409, 4.1939, 1.7318,  ..., 0.3947, 3.7390, 2.5161],\n",
      "        [4.2805, 2.6539, 1.1483,  ..., 0.0284, 3.1180, 2.7050]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([32, 182])\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss.sum(dim=1) * audio_weights9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([449.2588, 332.0229, 472.7906, 256.2851, 380.4775, 404.8902, 427.2510,\n",
      "        352.7689, 374.0200, 363.3866, 334.1092, 368.8346, 509.0506, 405.9546,\n",
      "        423.9656, 378.8881, 476.6589, 594.4567, 451.1944, 451.7960, 395.6176,\n",
      "        354.9887, 274.0173, 597.6990, 409.6134, 340.1158, 289.0433, 355.9919,\n",
      "        683.0813, 348.1871, 465.6527, 419.7467], grad_fn=<MulBackward0>)\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13141.8154, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1558, -0.5544, -1.9038,  ...,  0.4658,  0.0692, -0.7026],\n",
       "        [-1.8725, -0.3140, -1.9461,  ..., -1.5493, -0.1590, -1.3483],\n",
       "        [-0.5859, -0.4461, -1.1479,  ..., -2.5514, -0.4370,  0.7826],\n",
       "        ...,\n",
       "        [-1.4455, -0.0305, -0.1029,  ..., -4.2208,  0.2518,  1.0819],\n",
       "        [-0.7273, -0.9530, -0.7908,  ..., -2.5312,  0.1820, -0.4033],\n",
       "        [-0.8633, -0.4523, -1.5447,  ..., -5.2091,  0.3130,  0.2260]],\n",
       "       grad_fn=<LogitBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred\n",
    "torch.logit(clipwise_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_label9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 182])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logit(clipwise_output).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 182])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_label9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1558, -0.5544, -1.9038,  0.5842,  0.6793, -0.3103,  0.3622,  2.6720,\n",
       "         1.1968,  1.9605, -0.1440,  0.6012,  0.3439,  0.7290,  0.4987, -1.0556,\n",
       "        -3.2401,  0.9414, -0.8551, -0.3132, -1.2216, -0.4961,  1.8152,  1.6972,\n",
       "        -2.4760,  0.1262,  0.0644, -0.2398, -2.1218, -3.0737, -1.4441, -0.2646,\n",
       "         0.1405,  2.3220, -2.3530, -2.5800,  1.3406,  2.7800, -0.3509, -1.0579,\n",
       "         0.8010, -0.0457,  0.5179, -0.2395,  0.6103,  0.1513,  0.5079,  0.4382,\n",
       "         0.1196,  0.6469, -5.4115,  1.2755,  1.3952,  1.7183, -1.7108, -0.9875,\n",
       "        -0.0209,  0.3060,  0.6401,  2.0920, -1.9121, -1.0388, -0.9372, -1.3631,\n",
       "        -0.5262,  0.0459,  0.4150, -1.3921, -2.8248,  6.8728, -1.5901,  3.2996,\n",
       "        -0.9241, -2.2736, -1.0838,  2.5152, -1.7841, -0.7900,  3.3089,  0.5002,\n",
       "         0.5658,  0.1768, -0.3029, -0.9915, -0.4425,  0.1313, -0.6286, -1.0696,\n",
       "        -0.8901,  2.1551, -0.1422, -0.7597,  1.1850, -4.9617,  1.8083,  0.1927,\n",
       "         0.1561,  1.0944,  2.1176, -0.0833,  0.5367,  1.7268, -0.0564, -1.2794,\n",
       "         1.7925,  1.3651,  0.8339, -0.7247,  0.2637,  3.5001, -0.5646, -0.0130,\n",
       "        -0.3665, -4.4366, -0.3586, -2.7585,  0.7741,  1.1120,  2.8752,  0.2857,\n",
       "        -0.0577, -1.0480,  2.8153,  0.1203, -0.5668, -1.2370,  0.3716,  1.1423,\n",
       "         0.7134,  0.6664,  2.2281,  1.8049, -1.2926, -3.6962,  0.7007, -3.5314,\n",
       "         0.9036,  0.1734, -0.9402,  1.8639, -0.3653,  3.9816, -1.9448,  0.0372,\n",
       "        -0.6395,  1.1591,  1.7588,  1.0811,  0.3220,  2.2894,  0.8025,  0.3321,\n",
       "         1.4103, -3.1107, -0.9307,  1.1936, -3.3294,  0.6092,  0.6699, -0.5633,\n",
       "        -1.6716, -0.6053,  5.3975,  1.2967,  0.9071, -0.5511, -5.0456, -0.3362,\n",
       "        -0.8561, -1.7674, -0.5641, -1.0723, -0.1987,  0.8798, -1.5446, -0.4889,\n",
       "        -1.0459, -1.7837,  1.4251,  0.4658,  0.0692, -0.7026],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logit(clipwise_output)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.8000, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logit(clipwise_output)[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7606, 0.3648, 0.1297, 0.6420, 0.6636, 0.4230, 0.5896, 0.9354, 0.7680,\n",
       "        0.8766, 0.4641, 0.6459, 0.5851, 0.6746, 0.6221, 0.2581, 0.0377, 0.7194,\n",
       "        0.2984, 0.4223, 0.2277, 0.3785, 0.8600, 0.8452, 0.0776, 0.5315, 0.5161,\n",
       "        0.4403, 0.1070, 0.0442, 0.1909, 0.4342, 0.5351, 0.9107, 0.0868, 0.0704,\n",
       "        0.7926, 0.9416, 0.4132, 0.2577, 0.6902, 0.4886, 0.6267, 0.4404, 0.6480,\n",
       "        0.5378, 0.6243, 0.6078, 0.5299, 0.6563, 0.0044, 0.7817, 0.8014, 0.8479,\n",
       "        0.1531, 0.2714, 0.4948, 0.5759, 0.6548, 0.8901, 0.1287, 0.2614, 0.2815,\n",
       "        0.2037, 0.3714, 0.5115, 0.6023, 0.1991, 0.0560, 0.9990, 0.1694, 0.9644,\n",
       "        0.2841, 0.0933, 0.2528, 0.9252, 0.1438, 0.3122, 0.9647, 0.6225, 0.6378,\n",
       "        0.5441, 0.4248, 0.2706, 0.3911, 0.5328, 0.3478, 0.2555, 0.2911, 0.8961,\n",
       "        0.4645, 0.3187, 0.7658, 0.0070, 0.8592, 0.5480, 0.5389, 0.7492, 0.8926,\n",
       "        0.4792, 0.6310, 0.8490, 0.4859, 0.2177, 0.8572, 0.7966, 0.6972, 0.3264,\n",
       "        0.5655, 0.9707, 0.3625, 0.4967, 0.4094, 0.0117, 0.4113, 0.0596, 0.6844,\n",
       "        0.7525, 0.9466, 0.5710, 0.4856, 0.2596, 0.9435, 0.5300, 0.3620, 0.2250,\n",
       "        0.5918, 0.7581, 0.6711, 0.6607, 0.9027, 0.8587, 0.2154, 0.0242, 0.6683,\n",
       "        0.0284, 0.7117, 0.5432, 0.2809, 0.8658, 0.4097, 0.9817, 0.1251, 0.5093,\n",
       "        0.3454, 0.7612, 0.8531, 0.7467, 0.5798, 0.9080, 0.6905, 0.5823, 0.8038,\n",
       "        0.0427, 0.2828, 0.7674, 0.0346, 0.6478, 0.6615, 0.3628, 0.1582, 0.3531,\n",
       "        0.9955, 0.7853, 0.7124, 0.3656, 0.0064, 0.4167, 0.2981, 0.1459, 0.3626,\n",
       "        0.2550, 0.4505, 0.7068, 0.1759, 0.3801, 0.2600, 0.1438, 0.8061, 0.6144,\n",
       "        0.5173, 0.3312], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipwise_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 182])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipwise_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6815, 0.5902, 0.5324,  ..., 0.6489, 0.6265, 0.5821],\n",
       "        [0.5333, 0.6040, 0.5312,  ..., 0.5437, 0.6131, 0.5514],\n",
       "        [0.5885, 0.5964, 0.5599,  ..., 0.5181, 0.5969, 0.6651],\n",
       "        ...,\n",
       "        [0.5475, 0.6207, 0.6164,  ..., 0.5036, 0.6371, 0.6785],\n",
       "        [0.5807, 0.5691, 0.5774,  ..., 0.5184, 0.6331, 0.5988],\n",
       "        [0.5736, 0.5960, 0.5439,  ..., 0.5014, 0.6405, 0.6356]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipwise_output.sigmoid().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68147707, 0.5902113 , 0.5323743 , ..., 0.6489438 , 0.6265168 ,\n",
       "        0.5820622 ],\n",
       "       [0.53326297, 0.60399425, 0.53120345, ..., 0.5436858 , 0.6130908 ,\n",
       "        0.551355  ],\n",
       "       [0.58845305, 0.5963501 , 0.5599288 , ..., 0.51807535, 0.59687227,\n",
       "        0.6651295 ],\n",
       "       ...,\n",
       "       [0.5475301 , 0.6206659 , 0.61640054, ..., 0.50361854, 0.63705707,\n",
       "        0.67849326],\n",
       "       [0.5807343 , 0.5691229 , 0.5773728 , ..., 0.51841724, 0.63306177,\n",
       "        0.59881085],\n",
       "       [0.57362306, 0.5959976 , 0.5438503 , ..., 0.50135916, 0.64051944,\n",
       "        0.6355869 ]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=clipwise_output.sigmoid().detach().numpy()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 182)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_label9[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdclef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
