{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I choose to introduce a pre-trained model as a feature extractor, and here I choose to use tf_efficientnetv2_s.in21k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to the data processing section of 2-chrononet-with-torchdataset-melspecs.ipynb. The same data processing steps are used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from typing import List\n",
    "from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
    "\n",
    "import torchaudio\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "from lightning.pytorch.callbacks  import ModelCheckpoint, EarlyStopping\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/birdclef/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path='../../data/train_metadata_new_tiny.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize label encoder\n",
    "\n",
    "encoder=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lblwar1', 'blrwar1', 'bkskit1', 'comros', 'houcro1', 'houspa', 'graher1', 'blhori1', 'mawthr1', 'grewar3', 'hoopoe', 'indpit1', 'litspi1', 'wemhar1', 'laudov1', 'litgre1', 'rocpig', 'grecou1', 'whbwoo2', 'barswa', 'gyhcaf1', 'purher1', 'litegr', 'commyn', 'lirplo', 'putbab1', 'cregos1', 'bkwsti', 'gybpri1', 'commoo3', 'categr', 'asbfly', 'brwowl1', 'marsan', 'maghor2', 'zitcis1', 'bcnher', 'woosan', 'greegr', 'grtdro1', 'comtai1', 'eaywag1', 'grejun2', 'placuc3', 'grnsan', 'eucdov', 'comkin1', 'junowl1', 'ingori1', 'emedov2', 'sttwoo1', 'rorpar', 'thbwar1', 'comsan', 'goflea1', 'indrol2', 'cohcuc1', 'blakit1', 'comgre', 'eurcoo', 'whbbul2', 'rewlap1', 'inbrob1', 'brnshr', 'rerswa1', 'plapri1', 'whiter2', 'whbwat1', 'labcro1', 'plaflo1', 'grywag', 'spodov', 'redspu1', 'spepic1', 'yebbul3', 'gargan', 'spoowl1', 'aspswi1', 'eurbla2', 'brodro1', 'rewbul', 'stbkin1', 'ashdro1', 'lobsun2', 'rossta2', 'tilwar1', 'grefla1', 'compea', 'sbeowl1', 'barfly1', 'crseag1', 'comior1', 'grenig1', 'ruftre2', 'grehor1', 'blnmon1', 'whtkin2', 'asikoe2', 'insbab1', 'bladro1', 'heswoo1', 'brnhao1', 'grbeat1', 'inpher1', 'piebus1', 'wynlau1', 'kenplo1', 'grnwar1', 'junmyn1', 'insowl1', 'bwfshr1', 'junbab2', 'orihob2', 'shikra1', 'indrob1', 'btbeat1', 'whbwag1', 'pursun3', 'oripip1', 'forwag1', 'brcful1', 'sqtbul1', 'sohmyn1', 'whrmun', 'litswi1', 'yebbab1', 'brwjac1', 'revbul', 'purswa3', 'moipig1', 'lewduc1', 'gryfra', 'tibfly3', 'comfla1', 'whbsho3', 'ashpri1', 'pabflo1', 'copbar1', 'vehpar1', 'grynig2', 'gloibi', 'piekin1', 'lesyel1', 'nutman', 'whcbar1', 'bkrfla1', 'pursun4', 'ashwoo2', 'brasta1', 'malwoo1', 'kerlau2', 'plhpar1', 'smamin1', 'dafbab1', 'indtit1', 'maltro1', 'vefnut1', 'brakit1', 'wbbfly1', 'paisto1']\n",
      "160\n",
      "[ 89  16  10  36  71  72  52  14 102  60  70  74  95 145  88  94 125  54\n",
      " 150   7  68 115  93  34  92 119  40  11  67  33  27   0  24 101  98 159\n",
      "   8 155  55  63  38  43  58 111  61  45  32  84  78  44 138 126 139  37\n",
      "  51  76  28  13  30  47 146 124  73  21 121 113 152 149  87 112  66 134\n",
      " 120 133 158  49 135   5  46  22 123 137   1  97 127 141  56  35 129   6\n",
      "  41  31  59 128  57  15 154   4  80  12  69  20  53  79 109 156  85  62\n",
      "  83  81  26  82 105 130  75  25 148 116 106  48  19 136 132 153  96 157\n",
      "  23 122 118 103  91  64 140  29 147   2 107  39 143  65  50 110  90 104\n",
      " 151   9 117   3  18 100  86 114 131  42  77  99 142  17 144 108]\n",
      "{'asbfly': 0, 'ashdro1': 1, 'ashpri1': 2, 'ashwoo2': 3, 'asikoe2': 4, 'aspswi1': 5, 'barfly1': 6, 'barswa': 7, 'bcnher': 8, 'bkrfla1': 9, 'bkskit1': 10, 'bkwsti': 11, 'bladro1': 12, 'blakit1': 13, 'blhori1': 14, 'blnmon1': 15, 'blrwar1': 16, 'brakit1': 17, 'brasta1': 18, 'brcful1': 19, 'brnhao1': 20, 'brnshr': 21, 'brodro1': 22, 'brwjac1': 23, 'brwowl1': 24, 'btbeat1': 25, 'bwfshr1': 26, 'categr': 27, 'cohcuc1': 28, 'comfla1': 29, 'comgre': 30, 'comior1': 31, 'comkin1': 32, 'commoo3': 33, 'commyn': 34, 'compea': 35, 'comros': 36, 'comsan': 37, 'comtai1': 38, 'copbar1': 39, 'cregos1': 40, 'crseag1': 41, 'dafbab1': 42, 'eaywag1': 43, 'emedov2': 44, 'eucdov': 45, 'eurbla2': 46, 'eurcoo': 47, 'forwag1': 48, 'gargan': 49, 'gloibi': 50, 'goflea1': 51, 'graher1': 52, 'grbeat1': 53, 'grecou1': 54, 'greegr': 55, 'grefla1': 56, 'grehor1': 57, 'grejun2': 58, 'grenig1': 59, 'grewar3': 60, 'grnsan': 61, 'grnwar1': 62, 'grtdro1': 63, 'gryfra': 64, 'grynig2': 65, 'grywag': 66, 'gybpri1': 67, 'gyhcaf1': 68, 'heswoo1': 69, 'hoopoe': 70, 'houcro1': 71, 'houspa': 72, 'inbrob1': 73, 'indpit1': 74, 'indrob1': 75, 'indrol2': 76, 'indtit1': 77, 'ingori1': 78, 'inpher1': 79, 'insbab1': 80, 'insowl1': 81, 'junbab2': 82, 'junmyn1': 83, 'junowl1': 84, 'kenplo1': 85, 'kerlau2': 86, 'labcro1': 87, 'laudov1': 88, 'lblwar1': 89, 'lesyel1': 90, 'lewduc1': 91, 'lirplo': 92, 'litegr': 93, 'litgre1': 94, 'litspi1': 95, 'litswi1': 96, 'lobsun2': 97, 'maghor2': 98, 'maltro1': 99, 'malwoo1': 100, 'marsan': 101, 'mawthr1': 102, 'moipig1': 103, 'nutman': 104, 'orihob2': 105, 'oripip1': 106, 'pabflo1': 107, 'paisto1': 108, 'piebus1': 109, 'piekin1': 110, 'placuc3': 111, 'plaflo1': 112, 'plapri1': 113, 'plhpar1': 114, 'purher1': 115, 'pursun3': 116, 'pursun4': 117, 'purswa3': 118, 'putbab1': 119, 'redspu1': 120, 'rerswa1': 121, 'revbul': 122, 'rewbul': 123, 'rewlap1': 124, 'rocpig': 125, 'rorpar': 126, 'rossta2': 127, 'ruftre2': 128, 'sbeowl1': 129, 'shikra1': 130, 'smamin1': 131, 'sohmyn1': 132, 'spepic1': 133, 'spodov': 134, 'spoowl1': 135, 'sqtbul1': 136, 'stbkin1': 137, 'sttwoo1': 138, 'thbwar1': 139, 'tibfly3': 140, 'tilwar1': 141, 'vefnut1': 142, 'vehpar1': 143, 'wbbfly1': 144, 'wemhar1': 145, 'whbbul2': 146, 'whbsho3': 147, 'whbwag1': 148, 'whbwat1': 149, 'whbwoo2': 150, 'whcbar1': 151, 'whiter2': 152, 'whrmun': 153, 'whtkin2': 154, 'woosan': 155, 'wynlau1': 156, 'yebbab1': 157, 'yebbul3': 158, 'zitcis1': 159}\n"
     ]
    }
   ],
   "source": [
    "raw_df=pd.read_csv(labels_path,header=0)\n",
    "\n",
    "labels_all=raw_df.primary_label.unique().tolist()\n",
    "\n",
    "print(labels_all)\n",
    "print(len(labels_all))\n",
    "\n",
    "labels_encoded=encoder.fit_transform(labels_all)\n",
    "\n",
    "print(labels_encoded)\n",
    "\n",
    "# If needed, you can view the mapping of original labels to encodings\n",
    "label_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw_df,labels_all,labels_encoded,label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(path: str):\n",
    "    \"\"\"\n",
    "    Read an OGG file using torchaudio and return the waveform tensor and sample rate.\n",
    "\n",
    "    Parameters:\n",
    "        path: Path to the .ogg file\n",
    "\n",
    "    Returns:\n",
    "        waveform: Tensor representing the waveform\n",
    "        sample_rate: Sample rate of the audio file\n",
    "    \"\"\"\n",
    "    audio, sample_rate = torchaudio.load(path)\n",
    "    return audio, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regarding the data of a single audio, some audio information needs to be paid attention to, such as audio duration and number of channels.\n",
    "\n",
    "\n",
    "def audio_info(audio: torch.Tensor, sample_rate: int):\n",
    "    \"\"\"\n",
    "    Grab all information of the input audio loaded by torchaudio.\n",
    "\n",
    "    Parameters:\n",
    "        audio: Tensor representing the waveform\n",
    "        sample_rate: Sample rate of the audio file\n",
    "\n",
    "    Return:\n",
    "        duration_seconds: Duration of the audio in seconds\n",
    "        num_channels: Number of audio channels\n",
    "    \"\"\"\n",
    "    # The audio duration time (seconds)\n",
    "    duration_seconds = audio.shape[1] / sample_rate\n",
    "\n",
    "    # The number of channels\n",
    "    num_channels = audio.shape[0]\n",
    "\n",
    "\n",
    "    return duration_seconds, num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do mel spectrogram transform\n",
    "\n",
    "\n",
    "def mel_transform(sample_rate:float,audio:torch.Tensor,window_size: float=0.04,hop_size:float=0.02,n_mels:int=40)->torch.Tensor:\n",
    "    \"\"\"\n",
    "    transform audio data into mel sepctrogram\n",
    "    \"\"\"\n",
    "    # Determine window size and frame shift\n",
    "    # window_size = 0.04 # 40 milliseconds\n",
    "    # hop_size = 0.02 # 20 milliseconds, usually half the window size\n",
    "    n_fft = int(window_size * sample_rate)  \n",
    "    hop_length = int(hop_size * sample_rate) \n",
    "\n",
    "    # Calculate Mel Spectrogram\n",
    "    # n_mels = 40 # Number of Mel filters\n",
    "\n",
    "    # Set up Mel Spectrogram converter\n",
    "    mel_transformer = MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "        f_min=0,\n",
    "        f_max=16000\n",
    "    )\n",
    "\n",
    "    melspec=mel_transformer(audio)\n",
    "\n",
    "    return melspec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdclefDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 encoder:LabelEncoder,\n",
    "                 audio_dir:str='../../data/train_audio',\n",
    "                 labels_path:str=None,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            encoder: label encoder\n",
    "            audio_dir: the parent path where all audio files stored\n",
    "            labels_path: the file including all corresponding labels\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.encoder=encoder\n",
    "        self.audio_dir=audio_dir\n",
    "        # read data into dataframe\n",
    "        self.labels_df=pd.read_csv(labels_path,header=0)\n",
    "\n",
    "\n",
    "    def get_audio_path(self,index) -> str:\n",
    "        '''\n",
    "        Get the audio path of the corresponding index through the provided train metadata csv file. \n",
    "        Since there is only one index, only one path will be returned.\n",
    "\n",
    "        Parameters:\n",
    "            index: the index of labels metadata file\n",
    "\n",
    "        Return:\n",
    "            the single audio path string\n",
    "        '''\n",
    "        # Get the child path of audio from labels_df\n",
    "        audio_child_path=self.labels_df['filename'].iloc[index]\n",
    "\n",
    "        # concatenate parent path and child path\n",
    "        return os.path.join(self.audio_dir,audio_child_path)\n",
    "    \n",
    "\n",
    "    def get_audio_label(self,index)->str:\n",
    "        '''\n",
    "        According to the provided index, get the corresponding label from the train metadata file\n",
    "\n",
    "        Parameters:\n",
    "            index: the index of labels metadata file\n",
    "        '''\n",
    "\n",
    "        return self.labels_df['primary_label'].iloc[index]\n",
    "    \n",
    "\n",
    "    def target_clip(self,index:int,audio:torch.Tensor,sample_rate:int, duration_seconds:float)->torch.Tensor:\n",
    "        \"\"\"\n",
    "        calculate the index corresponding audio clip \n",
    "\n",
    "        information from the train metadata csv\n",
    "\n",
    "        Parameters:\n",
    "            audio: the raw audio in tensor [num_channels,length]\n",
    "            sample_rate: audio sampling rate\n",
    "            duration_seconds: audio duration in seconds\n",
    "        \"\"\"\n",
    "        # Get the audio start time corresponding to index\n",
    "        clip_start_time=self.labels_df['clip_start_time'].iloc[index]\n",
    "\n",
    "        # define clip length\n",
    "        segment_duration = 5 * sample_rate\n",
    "\n",
    "        # Total number of samples in the waveform\n",
    "        total_samples = audio.shape[1]\n",
    "\n",
    "        if clip_start_time<=duration_seconds:\n",
    "            clip_start_point=clip_start_time*sample_rate\n",
    "            # For the last clip, the original audio may not be long enough, so we need to use a mask to fill the sequence\n",
    "            # The first step is to confirm whether the length is sufficient\n",
    "            # The length is sufficient, no mask is needed\n",
    "            if clip_start_point+segment_duration<=total_samples:\n",
    "                clip=audio[:, clip_start_point:clip_start_point + segment_duration]\n",
    "\n",
    "            # Not long enough, a mask is needed\n",
    "            else:\n",
    "                padding_length = clip_start_point+segment_duration - total_samples\n",
    "                silence = torch.zeros(audio.shape[0], padding_length)\n",
    "                # concat the last segment of raw audio with silence\n",
    "                clip=torch.cat((audio[:,clip_start_point:],silence),dim=1)\n",
    "\n",
    "            # Calculate mean and standard deviation\n",
    "            mean_vals = clip.mean(dim=1, keepdim=True)\n",
    "            std_vals = clip.std(dim=1, keepdim=True)\n",
    "\n",
    "            # standardization\n",
    "            standardized_clip = (clip - mean_vals) / std_vals\n",
    "\n",
    "            # # Map normalized data to the range 0-255\n",
    "            # scaled_clip = 255 * (standardized_clip - standardized_clip.min()) / (standardized_clip.max() - standardized_clip.min())\n",
    "            # final_clip = scaled_clip.round().to(torch.uint8)  # Round and convert to an 8-bit unsigned integer\n",
    "\n",
    "                \n",
    "        else:\n",
    "            raise ValueError('The clip start time is out of raw audio length')\n",
    "        \n",
    "\n",
    "\n",
    "        return standardized_clip\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        #  return the size of the dataset by many Sampler implementations and the default options of DataLoader.\n",
    "    \n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # a_list[1] -> a_list.__getitems__(1)\n",
    "        # Get the path to a single audio file\n",
    "        single_audio_dir=self.get_audio_path(index)\n",
    "        # Get the corresponding label value\n",
    "        audio_label=self.encoder.transform([self.get_audio_label(index)])[0]\n",
    "\n",
    "        # Read audio array according to path\n",
    "        audio, sr=read_audio(single_audio_dir)\n",
    "        \n",
    "        # Read the duration and number of channels corresponding to the audio\n",
    "        duration_seconds, num_channels=audio_info(audio,sample_rate=sr)\n",
    "\n",
    "        # Get the audio clip corresponding to index\n",
    "        clip=self.target_clip(index,audio,sample_rate=sr, duration_seconds=duration_seconds)\n",
    "\n",
    "        # mel spectrogram transformation\n",
    "        mel_spec=mel_transform(sample_rate=sr,audio=clip)\n",
    "\n",
    "        # # Calculates the minimum and maximum values ​​of a tensor\n",
    "        # min_val = mel_spec.min()\n",
    "        # max_val = mel_spec.max()\n",
    "\n",
    "        # # Normalize the data to the range 0-1\n",
    "        # normalized_tensor = (mel_spec - min_val) / (max_val - min_val)\n",
    "\n",
    "        # # Scale the data in the 0-1 range to the 0-255 range\n",
    "        # scaled_tensor = normalized_tensor * 255\n",
    "\n",
    "        # # Round and convert to integer\n",
    "        # final_tensor = scaled_tensor.round().to(torch.float32)\n",
    "\n",
    "        return audio_label, mel_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BD=BirdclefDataset(encoder=encoder,labels_path=labels_path)\n",
    "dataloader = DataLoader(dataset=BD, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0, 113,  87,  32,  66,  34,  92,  11, 125, 145,  47,  52,  66,  96,\n",
      "         16,  16,  98,  52, 152,  93,  33,  16,  52,  20,  36,  34,  32,  43,\n",
      "        153,  33,  21, 149,  16,  87,  36,  34,  16, 128,  34,  16,  16,  31,\n",
      "        159,  36,  16,  72,  34,  36, 126, 113, 139,  88,  94,  68,  52, 115,\n",
      "         68,  43,  72,  34,  15,   7, 126,  27,  68,   8,  16,  11,  37,   8,\n",
      "         61,   9,  30,  89,  88,  67, 145, 130,  55,  23,  93,  76, 125,   7,\n",
      "         32,  45,  39,   0, 112,  68, 154,  66,  43,  93,  33, 153, 143,  34,\n",
      "         92, 146,  41,  15, 141,  36,  95,  92,  30,  16, 122,  60,  72, 122,\n",
      "        140,  45,  72, 154, 124, 139, 116,  72, 159,  13, 118,  45,  25,  16,\n",
      "         41,   8])\n",
      "tensor([[[[2.5582e-06, 7.1976e-05, 2.2219e+00,  ..., 4.1435e-08,\n",
      "           3.7231e-08, 4.1788e+01],\n",
      "          [2.3467e-06, 2.6229e-04, 2.5768e+00,  ..., 1.4192e-07,\n",
      "           1.5844e-07, 4.5789e+01],\n",
      "          [3.9678e-06, 2.9553e-04, 3.7667e+00,  ..., 3.2753e-04,\n",
      "           1.0462e-04, 4.9357e+01],\n",
      "          ...,\n",
      "          [6.4639e-04, 3.3510e-01, 3.7122e+03,  ..., 1.1407e+05,\n",
      "           1.3699e+05, 1.4393e+05],\n",
      "          [5.0318e-04, 8.8029e-02, 4.9822e+02,  ..., 9.6147e+02,\n",
      "           1.1418e+03, 2.0084e+03],\n",
      "          [5.1406e-04, 5.6391e-03, 2.0987e+01,  ..., 1.5910e+02,\n",
      "           1.8874e+02, 1.5349e+02]]],\n",
      "\n",
      "\n",
      "        [[[7.3384e+00, 9.2850e+01, 9.5940e+01,  ..., 8.5859e+05,\n",
      "           1.5773e+05, 9.0379e+03],\n",
      "          [1.4556e+00, 1.4893e+01, 8.3705e+00,  ..., 4.0606e+05,\n",
      "           3.3760e+04, 8.0274e+03],\n",
      "          [1.0618e+00, 2.5532e+00, 5.2775e+00,  ..., 4.8571e+04,\n",
      "           4.3348e+03, 1.3445e+03],\n",
      "          ...,\n",
      "          [7.5528e-03, 6.2743e-03, 5.7431e-03,  ..., 5.4405e-03,\n",
      "           6.3125e-03, 9.7590e-03],\n",
      "          [9.1537e-03, 7.8583e-03, 8.3352e-03,  ..., 3.6366e-03,\n",
      "           6.3697e-03, 1.5243e-02],\n",
      "          [4.7822e-03, 6.6250e-03, 6.7830e-03,  ..., 7.0171e-04,\n",
      "           3.3394e-03, 1.1796e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.7465e+03, 1.0428e+03, 9.9357e+02,  ..., 7.6359e+02,\n",
      "           5.2566e+02, 2.3604e+03],\n",
      "          [1.2287e+04, 3.0371e+03, 2.1618e+03,  ..., 2.2636e+03,\n",
      "           1.5044e+03, 2.1524e+03],\n",
      "          [1.1032e+04, 4.7939e+03, 3.2706e+03,  ..., 9.4715e+03,\n",
      "           1.8523e+03, 2.5952e+03],\n",
      "          ...,\n",
      "          [2.5777e+01, 2.4293e+01, 2.7274e+01,  ..., 1.9510e+01,\n",
      "           2.8057e+01, 2.2292e+01],\n",
      "          [1.8082e+01, 2.4839e+01, 3.1539e+01,  ..., 2.1105e+01,\n",
      "           2.5258e+01, 2.4783e+01],\n",
      "          [1.8502e+01, 1.5208e+01, 1.6688e+01,  ..., 1.2320e+01,\n",
      "           1.7163e+01, 1.0493e+01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1.0461e+01, 1.2546e+01, 7.3676e+00,  ..., 1.6970e+00,\n",
      "           3.2181e+00, 5.6544e+00],\n",
      "          [1.3713e+01, 8.2678e+00, 2.6717e+00,  ..., 7.9777e-01,\n",
      "           1.8189e+00, 7.6654e+00],\n",
      "          [2.9810e+01, 1.5156e+01, 8.5474e+00,  ..., 2.2000e+01,\n",
      "           9.3318e+00, 8.4891e+01],\n",
      "          ...,\n",
      "          [1.8884e+01, 2.1329e+01, 1.3821e+01,  ..., 1.7608e+01,\n",
      "           1.3545e+01, 1.3810e+01],\n",
      "          [1.7596e+01, 1.9898e+01, 1.2607e+01,  ..., 1.7948e+01,\n",
      "           1.6125e+01, 1.3618e+01],\n",
      "          [1.3914e+01, 1.6466e+01, 1.0055e+01,  ..., 1.2432e+01,\n",
      "           1.1141e+01, 9.8385e+00]]],\n",
      "\n",
      "\n",
      "        [[[7.6002e+01, 7.7296e-04, 2.2987e-04,  ..., 1.3611e-02,\n",
      "           1.3152e-02, 2.6155e+01],\n",
      "          [8.4916e+01, 1.7428e-01, 8.7774e-01,  ..., 1.2512e+00,\n",
      "           2.4849e-01, 3.1368e+01],\n",
      "          [1.3868e+02, 2.9656e+00, 5.1730e+00,  ..., 2.0843e+00,\n",
      "           2.2721e+00, 3.3451e+01],\n",
      "          ...,\n",
      "          [4.8954e+02, 3.5176e+02, 3.4212e+02,  ..., 2.7808e+02,\n",
      "           3.0469e+02, 3.3466e+02],\n",
      "          [8.7488e+01, 9.9385e+01, 7.6664e+01,  ..., 4.8543e+01,\n",
      "           4.4606e+01, 6.3249e+01],\n",
      "          [1.9850e+01, 1.7435e+01, 2.5784e+01,  ..., 1.4908e+01,\n",
      "           1.8798e+01, 1.8296e+01]]],\n",
      "\n",
      "\n",
      "        [[[8.2521e-02, 6.8715e-02, 4.3460e+03,  ..., 2.0622e+04,\n",
      "           1.4322e+04, 8.5325e+04],\n",
      "          [8.5156e-04, 5.1014e-03, 7.7377e+03,  ..., 5.0006e+04,\n",
      "           6.0278e+04, 2.7620e+04],\n",
      "          [9.6771e-05, 4.4036e-02, 4.3164e+03,  ..., 6.6583e+04,\n",
      "           8.2270e+04, 2.3057e+04],\n",
      "          ...,\n",
      "          [1.6682e-03, 2.4021e-02, 1.8257e+01,  ..., 6.8527e+01,\n",
      "           1.0882e+02, 9.1197e+01],\n",
      "          [1.5079e-03, 4.4298e-03, 4.9925e+00,  ..., 1.5804e+01,\n",
      "           1.9434e+01, 2.9017e+01],\n",
      "          [1.5543e-03, 7.3070e-03, 6.0402e+00,  ..., 4.2367e+00,\n",
      "           5.5132e+00, 4.4266e+00]]]])\n",
      "torch.Size([128, 1, 40, 251])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "labels, mel_specs = batch\n",
    "print(labels)\n",
    "print(mel_specs)\n",
    "print(mel_specs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/birdclef/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnetv2_s_in21k to current tf_efficientnetv2_s.in21k.\n",
      "  model = create_fn(\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "model = timm.create_model('tf_efficientnetv2_s_in21k', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "EfficientNet                                  [128, 21843]              --\n",
       "├─Conv2dSame: 1-1                             [128, 24, 20, 126]        648\n",
       "├─BatchNormAct2d: 1-2                         [128, 24, 20, 126]        48\n",
       "│    └─Identity: 2-1                          [128, 24, 20, 126]        --\n",
       "│    └─SiLU: 2-2                              [128, 24, 20, 126]        --\n",
       "├─Sequential: 1-3                             [128, 256, 2, 8]          --\n",
       "│    └─Sequential: 2-3                        [128, 24, 20, 126]        --\n",
       "│    │    └─ConvBnAct: 3-1                    [128, 24, 20, 126]        5,232\n",
       "│    │    └─ConvBnAct: 3-2                    [128, 24, 20, 126]        5,232\n",
       "│    └─Sequential: 2-4                        [128, 48, 10, 63]         --\n",
       "│    │    └─EdgeResidual: 3-3                 [128, 48, 10, 63]         25,632\n",
       "│    │    └─EdgeResidual: 3-4                 [128, 48, 10, 63]         92,640\n",
       "│    │    └─EdgeResidual: 3-5                 [128, 48, 10, 63]         92,640\n",
       "│    │    └─EdgeResidual: 3-6                 [128, 48, 10, 63]         92,640\n",
       "│    └─Sequential: 2-5                        [128, 64, 5, 32]          --\n",
       "│    │    └─EdgeResidual: 3-7                 [128, 64, 5, 32]          95,744\n",
       "│    │    └─EdgeResidual: 3-8                 [128, 64, 5, 32]          164,480\n",
       "│    │    └─EdgeResidual: 3-9                 [128, 64, 5, 32]          164,480\n",
       "│    │    └─EdgeResidual: 3-10                [128, 64, 5, 32]          164,480\n",
       "│    └─Sequential: 2-6                        [128, 128, 3, 16]         --\n",
       "│    │    └─InvertedResidual: 3-11            [128, 128, 3, 16]         61,200\n",
       "│    │    └─InvertedResidual: 3-12            [128, 128, 3, 16]         171,296\n",
       "│    │    └─InvertedResidual: 3-13            [128, 128, 3, 16]         171,296\n",
       "│    │    └─InvertedResidual: 3-14            [128, 128, 3, 16]         171,296\n",
       "│    │    └─InvertedResidual: 3-15            [128, 128, 3, 16]         171,296\n",
       "│    │    └─InvertedResidual: 3-16            [128, 128, 3, 16]         171,296\n",
       "│    └─Sequential: 2-7                        [128, 160, 3, 16]         --\n",
       "│    │    └─InvertedResidual: 3-17            [128, 160, 3, 16]         281,440\n",
       "│    │    └─InvertedResidual: 3-18            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-19            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-20            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-21            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-22            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-23            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-24            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-25            [128, 160, 3, 16]         397,800\n",
       "│    └─Sequential: 2-8                        [128, 256, 2, 8]          --\n",
       "│    │    └─InvertedResidual: 3-26            [128, 256, 2, 8]          490,152\n",
       "│    │    └─InvertedResidual: 3-27            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-28            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-29            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-30            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-31            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-32            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-33            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-34            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-35            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-36            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-37            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-38            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-39            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-40            [128, 256, 2, 8]          1,005,120\n",
       "├─Conv2d: 1-4                                 [128, 1280, 2, 8]         327,680\n",
       "├─BatchNormAct2d: 1-5                         [128, 1280, 2, 8]         2,560\n",
       "│    └─Identity: 2-9                          [128, 1280, 2, 8]         --\n",
       "│    └─SiLU: 2-10                             [128, 1280, 2, 8]         --\n",
       "├─SelectAdaptivePool2d: 1-6                   [128, 1280]               --\n",
       "│    └─AdaptiveAvgPool2d: 2-11                [128, 1280, 1, 1]         --\n",
       "│    └─Flatten: 2-12                          [128, 1280]               --\n",
       "├─Linear: 1-7                                 [128, 21843]              27,980,883\n",
       "===============================================================================================\n",
       "Total params: 48,158,371\n",
       "Trainable params: 48,158,371\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 90.69\n",
       "===============================================================================================\n",
       "Input size (MB): 15.42\n",
       "Forward/backward pass size (MB): 3097.44\n",
       "Params size (MB): 192.02\n",
       "Estimated Total Size (MB): 3304.88\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tf_efficientnetv2_s_in21k model expects the input data to be a three-channel image (usually an RGB image) by default\n",
    "# So here, temporarily change ch_num to 3 to view the information of the pre-trained model\n",
    "summary(model,input_size=(128,3,40,251))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2dSame(3, 24, kernel_size=(3, 3), stride=(2, 2), bias=False)\n"
     ]
    }
   ],
   "source": [
    "# Modify the model to accept 1-channel input\n",
    "first_conv_layer = model.conv_stem\n",
    "\n",
    "print(first_conv_layer)\n",
    "\n",
    "model.conv_stem = nn.Conv2d(in_channels=1, out_channels=first_conv_layer.out_channels, \n",
    "                            kernel_size=first_conv_layer.kernel_size, \n",
    "                            stride=first_conv_layer.stride, \n",
    "                            padding=first_conv_layer.padding, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "EfficientNet                                  [128, 21843]              --\n",
       "├─Conv2d: 1-1                                 [128, 24, 19, 125]        216\n",
       "├─BatchNormAct2d: 1-2                         [128, 24, 19, 125]        48\n",
       "│    └─Identity: 2-1                          [128, 24, 19, 125]        --\n",
       "│    └─SiLU: 2-2                              [128, 24, 19, 125]        --\n",
       "├─Sequential: 1-3                             [128, 256, 2, 8]          --\n",
       "│    └─Sequential: 2-3                        [128, 24, 19, 125]        --\n",
       "│    │    └─ConvBnAct: 3-1                    [128, 24, 19, 125]        5,232\n",
       "│    │    └─ConvBnAct: 3-2                    [128, 24, 19, 125]        5,232\n",
       "│    └─Sequential: 2-4                        [128, 48, 10, 63]         --\n",
       "│    │    └─EdgeResidual: 3-3                 [128, 48, 10, 63]         25,632\n",
       "│    │    └─EdgeResidual: 3-4                 [128, 48, 10, 63]         92,640\n",
       "│    │    └─EdgeResidual: 3-5                 [128, 48, 10, 63]         92,640\n",
       "│    │    └─EdgeResidual: 3-6                 [128, 48, 10, 63]         92,640\n",
       "│    └─Sequential: 2-5                        [128, 64, 5, 32]          --\n",
       "│    │    └─EdgeResidual: 3-7                 [128, 64, 5, 32]          95,744\n",
       "│    │    └─EdgeResidual: 3-8                 [128, 64, 5, 32]          164,480\n",
       "│    │    └─EdgeResidual: 3-9                 [128, 64, 5, 32]          164,480\n",
       "│    │    └─EdgeResidual: 3-10                [128, 64, 5, 32]          164,480\n",
       "│    └─Sequential: 2-6                        [128, 128, 3, 16]         --\n",
       "│    │    └─InvertedResidual: 3-11            [128, 128, 3, 16]         61,200\n",
       "│    │    └─InvertedResidual: 3-12            [128, 128, 3, 16]         171,296\n",
       "│    │    └─InvertedResidual: 3-13            [128, 128, 3, 16]         171,296\n",
       "│    │    └─InvertedResidual: 3-14            [128, 128, 3, 16]         171,296\n",
       "│    │    └─InvertedResidual: 3-15            [128, 128, 3, 16]         171,296\n",
       "│    │    └─InvertedResidual: 3-16            [128, 128, 3, 16]         171,296\n",
       "│    └─Sequential: 2-7                        [128, 160, 3, 16]         --\n",
       "│    │    └─InvertedResidual: 3-17            [128, 160, 3, 16]         281,440\n",
       "│    │    └─InvertedResidual: 3-18            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-19            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-20            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-21            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-22            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-23            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-24            [128, 160, 3, 16]         397,800\n",
       "│    │    └─InvertedResidual: 3-25            [128, 160, 3, 16]         397,800\n",
       "│    └─Sequential: 2-8                        [128, 256, 2, 8]          --\n",
       "│    │    └─InvertedResidual: 3-26            [128, 256, 2, 8]          490,152\n",
       "│    │    └─InvertedResidual: 3-27            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-28            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-29            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-30            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-31            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-32            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-33            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-34            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-35            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-36            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-37            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-38            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-39            [128, 256, 2, 8]          1,005,120\n",
       "│    │    └─InvertedResidual: 3-40            [128, 256, 2, 8]          1,005,120\n",
       "├─Conv2d: 1-4                                 [128, 1280, 2, 8]         327,680\n",
       "├─BatchNormAct2d: 1-5                         [128, 1280, 2, 8]         2,560\n",
       "│    └─Identity: 2-9                          [128, 1280, 2, 8]         --\n",
       "│    └─SiLU: 2-10                             [128, 1280, 2, 8]         --\n",
       "├─SelectAdaptivePool2d: 1-6                   [128, 1280]               --\n",
       "│    └─AdaptiveAvgPool2d: 2-11                [128, 1280, 1, 1]         --\n",
       "│    └─Flatten: 2-12                          [128, 1280]               --\n",
       "├─Linear: 1-7                                 [128, 21843]              27,980,883\n",
       "===============================================================================================\n",
       "Total params: 48,157,939\n",
       "Trainable params: 48,157,939\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 90.35\n",
       "===============================================================================================\n",
       "Input size (MB): 5.14\n",
       "Forward/backward pass size (MB): 3086.75\n",
       "Params size (MB): 192.02\n",
       "Estimated Total Size (MB): 3283.91\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model,input_size=(128,1,40,251))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (conv_stem): Conv2d(1, 24, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (bn1): BatchNormAct2d(\n",
       "    24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvBnAct(\n",
       "        (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): ConvBnAct(\n",
       "        (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): EdgeResidual(\n",
       "        (conv_exp): Conv2dSame(24, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): EdgeResidual(\n",
       "        (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): EdgeResidual(\n",
       "        (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): EdgeResidual(\n",
       "        (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): EdgeResidual(\n",
       "        (conv_exp): Conv2dSame(48, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): EdgeResidual(\n",
       "        (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): EdgeResidual(\n",
       "        (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): EdgeResidual(\n",
       "        (conv_exp): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2dSame(256, 256, kernel_size=(3, 3), stride=(2, 2), groups=256, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv_pw): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2dSame(960, 960, kernel_size=(3, 3), stride=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (conv_pw): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_head): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNormAct2d(\n",
       "    1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (classifier): Linear(in_features=1280, out_features=21843, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract features using the model\n",
    "# features_list = []\n",
    "# with torch.no_grad():\n",
    "#     for inputs in dataloader:\n",
    "#         # Assume your model is slightly modified for feature extraction\n",
    "#         features = model(inputs[1])\n",
    "#         features_list.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally convert the feature list into a large tensor\n",
    "# features_tensor = torch.cat(features_list, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that if the output layer of the pre-trained model is not modified, the result is the same as the definition of the original model itself, and 21,843 categories will be returned.\n",
    "\n",
    "But we only have 182 categories. If a small data set is used, there are only 160 categories. I need to redefine the output layer and retrain the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the last classification layer, the number of output features of the new layer is 160\n",
    "model.classifier = nn.Linear(in_features=model.classifier.in_features, out_features=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, you need to train the new output layer. You can choose to freeze the previous layers and only train this new classification layer, \n",
    "# or adjust the training settings of some layers as needed.\n",
    "\n",
    "# Freeze the parameters of all previous layers and only train the new classification layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Enable gradient updates only for the last classification layer\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def train_model(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "#     model.train()  # Set model to training mode\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         running_loss = 0.0\n",
    "#         correct_predictions = 0\n",
    "        \n",
    "#         for inputs, labels in dataloader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "#             optimizer.zero_grad()  # Clear previous gradients\n",
    "            \n",
    "#             # Forward Propagation\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "            \n",
    "#             # Backpropagation and Optimization\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             # statistics\n",
    "#             running_loss += loss.item()\n",
    "#             _, predictions = torch.max(outputs, 1)\n",
    "#             correct_predictions += (predictions == labels).sum().item()\n",
    "        \n",
    "#         epoch_loss = running_loss / len(dataloader.dataset)\n",
    "#         epoch_acc = correct_predictions / len(dataloader.dataset)\n",
    "        \n",
    "#         print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "        \n",
    "#     return model\n",
    "\n",
    "# # Training the model\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.to(device)\n",
    "# trained_model = train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, weight=None, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight  # category weights\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.weight)\n",
    "        p_t = torch.exp(-ce_loss) # Modulating Factor\n",
    "        loss = (1 - p_t) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use lightning to encapsulate the training steps\n",
    "\n",
    "class effnetv2tune(L.LightningModule):\n",
    "    def __init__(self,model,learning_rate=0.0001):\n",
    "        super().__init__()\n",
    "        self.model=model\n",
    "        self.lr=learning_rate\n",
    "        self.train_acc=torchmetrics.Accuracy(task='multiclass',num_classes=160)\n",
    "        self.val_acc=torchmetrics.Accuracy(task='multiclass',num_classes=160)\n",
    "        self.focal_loss = FocalLoss(gamma=2.0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        labels,features=batch\n",
    "        # Send data to GPU for training\n",
    "        features=features.to(self.device)\n",
    "        labels=labels.to(self.device)\n",
    "\n",
    "        outputs=self(features)\n",
    "        # print(outputs)\n",
    "        # print('-------------')\n",
    "        # loss=F.cross_entropy(outputs,labels)\n",
    "        loss = self.focal_loss(outputs, labels)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        acc=self.train_acc(outputs,labels)\n",
    "        self.log(\"train_acc\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "        \n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "\n",
    "        labels,features=batch\n",
    "        # Send data to GPU for training\n",
    "        features=features.to(self.device)\n",
    "        labels=labels.to(self.device)\n",
    "\n",
    "        outputs=self(features)\n",
    "        # loss=F.cross_entropy(outputs,labels)\n",
    "        loss = self.focal_loss(outputs, labels)\n",
    "        # self.log('val_loss',loss)\n",
    "\n",
    "        # # Calculate accuracy\n",
    "        # _, predictions = torch.max(outputs, 1)\n",
    "        # acc = torch.tensor(torch.sum(predictions == labels).item() / len(predictions))\n",
    "        # self.log('val_acc', acc, on_step=False, on_epoch=True)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        acc=self.val_acc(outputs,labels)\n",
    "        self.log(\"val_acc\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.classifier.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I introduce lightningDataModule here to distinguish trainset and valset\n",
    "\n",
    "class ChronoNetDataModule(L.LightningDataModule):\n",
    "    def __init__(self,dataset:Dataset,pred=None,batch_size:int=128):\n",
    "        super().__init__()\n",
    "        self.dataset=dataset\n",
    "        self.batch_size=batch_size\n",
    "\n",
    "        self.pred=pred\n",
    "\n",
    "    def setup(self,stage:str):\n",
    "        # assign train/val splits for use in dataloaders\n",
    "        if stage=='fit':\n",
    "            # self.train_dataset,self.val_dataset=random_split(self.dataset,[0.8,0.2],generator=torch.Generator().manual_seed(41))\n",
    "            self.train_dataset,self.val_dataset=random_split(self.dataset,[0.8,0.2],generator=torch.Generator())\n",
    "        # if stage=='predict':\n",
    "            \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        loader= DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        return loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        loader= DataLoader(self.val_dataset, batch_size=self.batch_size,shuffle=False)\n",
    "\n",
    "        return loader\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        loader=DataLoader(self.dataset,batch_size=self.batch_size,shuffle=False)\n",
    "\n",
    "        return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',  # monitor val set loss\n",
    "    dirpath='/Users/yiding/personal_projects/ML/github_repo/birdcief/code/feature-extractor/checkpoints/',\n",
    "    filename='chrononet-{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=1,  \n",
    "    mode='min',  \n",
    "    auto_insert_metric_name=False  \n",
    ")\n",
    "\n",
    "# 设置早停（EarlyStopping）\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    min_delta=0.00,\n",
    "    patience=3,  \n",
    "    verbose=True,\n",
    "    mode='min'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.ChronoNetDataModule object at 0x2890eb0a0>\n"
     ]
    }
   ],
   "source": [
    "#initialize Dataset first\n",
    "\n",
    "BD=BirdclefDataset(encoder=encoder,labels_path=labels_path)\n",
    "# Previously we used a separate dataloader to feed the model\n",
    "# Here we encapsulate the dataloader and use this class to read data for training\n",
    "\n",
    "dm=ChronoNetDataModule(dataset=BD,batch_size=128)\n",
    "print(dm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/birdclef/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:653: Checkpoint directory /Users/yiding/personal_projects/ML/github_repo/birdcief/code/feature-extractor/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | model      | EfficientNet       | 20.4 M\n",
      "1 | train_acc  | MulticlassAccuracy | 0     \n",
      "2 | val_acc    | MulticlassAccuracy | 0     \n",
      "3 | focal_loss | FocalLoss          | 0     \n",
      "--------------------------------------------------\n",
      "204 K     Trainable params\n",
      "20.2 M    Non-trainable params\n",
      "20.4 M    Total params\n",
      "81.528    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/birdclef/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/birdclef/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/birdclef/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 14/14 [03:29<00:00,  0.07it/s, v_num=11, train_loss_step=6.85e+4, train_acc_step=0.0256, val_loss_step=7.06e+4, val_acc_step=0.0196, val_loss_epoch=7.25e+4, val_acc_epoch=0.0115, train_loss_epoch=8.75e+4, train_acc_epoch=0.00976]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 72491.164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 14/14 [03:25<00:00,  0.07it/s, v_num=11, train_loss_step=8.25e+4, train_acc_step=0.0385, val_loss_step=6.21e+4, val_acc_step=0.0392, val_loss_epoch=6.54e+4, val_acc_epoch=0.0276, train_loss_epoch=6.53e+4, train_acc_epoch=0.023]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 7056.953 >= min_delta = 0.0. New best score: 65434.211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 14/14 [03:26<00:00,  0.07it/s, v_num=11, train_loss_step=5.7e+4, train_acc_step=0.0128, val_loss_step=6.01e+4, val_acc_step=0.0588, val_loss_epoch=6.33e+4, val_acc_epoch=0.0299, train_loss_epoch=5.81e+4, train_acc_epoch=0.0344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 2156.781 >= min_delta = 0.0. New best score: 63277.430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 14/14 [03:30<00:00,  0.07it/s, v_num=11, train_loss_step=5.62e+4, train_acc_step=0.0256, val_loss_step=5.97e+4, val_acc_step=0.0588, val_loss_epoch=6.17e+4, val_acc_epoch=0.0276, train_loss_epoch=5.18e+4, train_acc_epoch=0.0339]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 1610.840 >= min_delta = 0.0. New best score: 61666.590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 14/14 [03:27<00:00,  0.07it/s, v_num=11, train_loss_step=4.85e+4, train_acc_step=0.000, val_loss_step=5.85e+4, val_acc_step=0.0588, val_loss_epoch=6.01e+4, val_acc_epoch=0.0276, train_loss_epoch=4.66e+4, train_acc_epoch=0.0396] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 1530.258 >= min_delta = 0.0. New best score: 60136.332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 14/14 [03:27<00:00,  0.07it/s, v_num=11, train_loss_step=4.15e+4, train_acc_step=0.0513, val_loss_step=5.88e+4, val_acc_step=0.0588, val_loss_epoch=5.94e+4, val_acc_epoch=0.0276, train_loss_epoch=4.2e+4, train_acc_epoch=0.0499] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 768.602 >= min_delta = 0.0. New best score: 59367.730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 14/14 [03:27<00:00,  0.07it/s, v_num=11, train_loss_step=3.46e+4, train_acc_step=0.0897, val_loss_step=5.83e+4, val_acc_step=0.0784, val_loss_epoch=5.84e+4, val_acc_epoch=0.0299, train_loss_epoch=3.78e+4, train_acc_epoch=0.0643]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 934.332 >= min_delta = 0.0. New best score: 58433.398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 14/14 [03:27<00:00,  0.07it/s, v_num=11, train_loss_step=2.83e+4, train_acc_step=0.0513, val_loss_step=5.83e+4, val_acc_step=0.0784, val_loss_epoch=5.78e+4, val_acc_epoch=0.0299, train_loss_epoch=3.42e+4, train_acc_epoch=0.0723]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 624.707 >= min_delta = 0.0. New best score: 57808.691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 14/14 [03:34<00:00,  0.07it/s, v_num=11, train_loss_step=2.39e+4, train_acc_step=0.141, val_loss_step=5.85e+4, val_acc_step=0.0588, val_loss_epoch=5.75e+4, val_acc_epoch=0.0253, train_loss_epoch=3.07e+4, train_acc_epoch=0.0913] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 322.035 >= min_delta = 0.0. New best score: 57486.656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 14/14 [03:28<00:00,  0.07it/s, v_num=11, train_loss_step=3.27e+4, train_acc_step=0.115, val_loss_step=5.77e+4, val_acc_step=0.0588, val_loss_epoch=5.67e+4, val_acc_epoch=0.023, train_loss_epoch=2.77e+4, train_acc_epoch=0.115]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 813.547 >= min_delta = 0.0. New best score: 56673.109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 14/14 [03:28<00:00,  0.07it/s, v_num=11, train_loss_step=2.39e+4, train_acc_step=0.0897, val_loss_step=5.82e+4, val_acc_step=0.0588, val_loss_epoch=5.64e+4, val_acc_epoch=0.0253, train_loss_epoch=2.49e+4, train_acc_epoch=0.130]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 232.277 >= min_delta = 0.0. New best score: 56440.832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 14/14 [03:29<00:00,  0.07it/s, v_num=11, train_loss_step=2.71e+4, train_acc_step=0.128, val_loss_step=5.71e+4, val_acc_step=0.0588, val_loss_epoch=5.58e+4, val_acc_epoch=0.0276, train_loss_epoch=2.24e+4, train_acc_epoch=0.148] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 602.281 >= min_delta = 0.0. New best score: 55838.551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 14/14 [03:29<00:00,  0.07it/s, v_num=11, train_loss_step=2.07e+4, train_acc_step=0.154, val_loss_step=5.63e+4, val_acc_step=0.0588, val_loss_epoch=5.55e+4, val_acc_epoch=0.0253, train_loss_epoch=2.02e+4, train_acc_epoch=0.177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 314.137 >= min_delta = 0.0. New best score: 55524.414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 14/14 [03:30<00:00,  0.07it/s, v_num=11, train_loss_step=1.52e+4, train_acc_step=0.218, val_loss_step=5.61e+4, val_acc_step=0.0588, val_loss_epoch=5.49e+4, val_acc_epoch=0.0253, train_loss_epoch=1.82e+4, train_acc_epoch=0.207]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 626.926 >= min_delta = 0.0. New best score: 54897.488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 14/14 [03:28<00:00,  0.07it/s, v_num=11, train_loss_step=2.13e+4, train_acc_step=0.0897, val_loss_step=5.58e+4, val_acc_step=0.0588, val_loss_epoch=5.48e+4, val_acc_epoch=0.0299, train_loss_epoch=1.66e+4, train_acc_epoch=0.222]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 93.867 >= min_delta = 0.0. New best score: 54803.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 14/14 [03:29<00:00,  0.07it/s, v_num=11, train_loss_step=1.61e+4, train_acc_step=0.244, val_loss_step=5.59e+4, val_acc_step=0.0588, val_loss_epoch=5.44e+4, val_acc_epoch=0.0253, train_loss_epoch=1.51e+4, train_acc_epoch=0.251] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 437.746 >= min_delta = 0.0. New best score: 54365.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 14/14 [03:26<00:00,  0.07it/s, v_num=11, train_loss_step=1.43e+4, train_acc_step=0.295, val_loss_step=5.54e+4, val_acc_step=0.0588, val_loss_epoch=5.41e+4, val_acc_epoch=0.0276, train_loss_epoch=1.37e+4, train_acc_epoch=0.270]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 253.598 >= min_delta = 0.0. New best score: 54112.277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 14/14 [03:25<00:00,  0.07it/s, v_num=11, train_loss_step=9.95e+3, train_acc_step=0.295, val_loss_step=5.52e+4, val_acc_step=0.0588, val_loss_epoch=5.36e+4, val_acc_epoch=0.0276, train_loss_epoch=1.25e+4, train_acc_epoch=0.298]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 478.336 >= min_delta = 0.0. New best score: 53633.941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 14/14 [03:23<00:00,  0.07it/s, v_num=11, train_loss_step=9.88e+3, train_acc_step=0.346, val_loss_step=5.48e+4, val_acc_step=0.0588, val_loss_epoch=5.34e+4, val_acc_epoch=0.0299, train_loss_epoch=1.15e+4, train_acc_epoch=0.321]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 270.883 >= min_delta = 0.0. New best score: 53363.059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 14/14 [03:24<00:00,  0.07it/s, v_num=11, train_loss_step=1.05e+4, train_acc_step=0.385, val_loss_step=5.47e+4, val_acc_step=0.0588, val_loss_epoch=5.28e+4, val_acc_epoch=0.0299, train_loss_epoch=9.71e+3, train_acc_epoch=0.362]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 542.020 >= min_delta = 0.0. New best score: 52821.039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 14/14 [03:25<00:00,  0.07it/s, v_num=11, train_loss_step=1.27e+4, train_acc_step=0.321, val_loss_step=5.47e+4, val_acc_step=0.0588, val_loss_epoch=5.28e+4, val_acc_epoch=0.0345, train_loss_epoch=8.94e+3, train_acc_epoch=0.374]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 33.473 >= min_delta = 0.0. New best score: 52787.566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 14/14 [03:26<00:00,  0.07it/s, v_num=11, train_loss_step=7.06e+3, train_acc_step=0.423, val_loss_step=5.43e+4, val_acc_step=0.0588, val_loss_epoch=5.25e+4, val_acc_epoch=0.0276, train_loss_epoch=8.2e+3, train_acc_epoch=0.400] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 282.832 >= min_delta = 0.0. New best score: 52504.734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 14/14 [03:25<00:00,  0.07it/s, v_num=11, train_loss_step=1.01e+4, train_acc_step=0.321, val_loss_step=5.52e+4, val_acc_step=0.0588, val_loss_epoch=5.25e+4, val_acc_epoch=0.0322, train_loss_epoch=7.64e+3, train_acc_epoch=0.409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 8.082 >= min_delta = 0.0. New best score: 52496.652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 14/14 [03:27<00:00,  0.07it/s, v_num=11, train_loss_step=6.56e+3, train_acc_step=0.487, val_loss_step=5.56e+4, val_acc_step=0.0588, val_loss_epoch=5.23e+4, val_acc_epoch=0.0345, train_loss_epoch=7.04e+3, train_acc_epoch=0.427]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 212.453 >= min_delta = 0.0. New best score: 52284.199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 14/14 [03:27<00:00,  0.07it/s, v_num=11, train_loss_step=6.09e+3, train_acc_step=0.423, val_loss_step=5.47e+4, val_acc_step=0.0588, val_loss_epoch=5.23e+4, val_acc_epoch=0.0322, train_loss_epoch=6.45e+3, train_acc_epoch=0.445]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 3.973 >= min_delta = 0.0. New best score: 52280.227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 14/14 [03:26<00:00,  0.07it/s, v_num=11, train_loss_step=4.64e+3, train_acc_step=0.538, val_loss_step=5.48e+4, val_acc_step=0.0588, val_loss_epoch=5.21e+4, val_acc_epoch=0.0299, train_loss_epoch=5.96e+3, train_acc_epoch=0.448]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 164.180 >= min_delta = 0.0. New best score: 52116.047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 14/14 [03:29<00:00,  0.07it/s, v_num=11, train_loss_step=3.89e+3, train_acc_step=0.500, val_loss_step=5.48e+4, val_acc_step=0.0784, val_loss_epoch=5.2e+4, val_acc_epoch=0.0345, train_loss_epoch=5.5e+3, train_acc_epoch=0.473]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 120.590 >= min_delta = 0.0. New best score: 51995.457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 14/14 [03:28<00:00,  0.07it/s, v_num=11, train_loss_step=3.65e+3, train_acc_step=0.526, val_loss_step=5.5e+4, val_acc_step=0.0784, val_loss_epoch=5.21e+4, val_acc_epoch=0.0322, train_loss_epoch=4.7e+3, train_acc_epoch=0.513]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 14/14 [03:28<00:00,  0.07it/s, v_num=11, train_loss_step=3.65e+3, train_acc_step=0.526, val_loss_step=5.5e+4, val_acc_step=0.0784, val_loss_epoch=5.21e+4, val_acc_epoch=0.0322, train_loss_epoch=4.7e+3, train_acc_epoch=0.513]\n"
     ]
    }
   ],
   "source": [
    "effnetv2tune=effnetv2tune(model=model)\n",
    "\n",
    "trainer=L.Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator=\"gpu\", # set to 'auto' or 'gpu' to use gpu if possible\n",
    "    devices=1, # use all gpus if applicable like value=1 or \"auto\"\n",
    "    default_root_dir='/Users/yiding/personal_projects/ML/github_repo/birdcief/code/feature-extractor/',\n",
    "    # logger=CSVLogger(save_dir='/Users/yiding/personal_projects/ML/github_repo/birdcief/code/model-training/log/',name='chrononet')\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],  \n",
    ")\n",
    "\n",
    "# train the model\n",
    "trainer.fit(\n",
    "    model=effnetv2tune,\n",
    "    datamodule=dm \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_stem.weight -> requires_grad: False\n",
      "bn1.weight -> requires_grad: False\n",
      "bn1.bias -> requires_grad: False\n",
      "blocks.0.0.conv.weight -> requires_grad: False\n",
      "blocks.0.0.bn1.weight -> requires_grad: False\n",
      "blocks.0.0.bn1.bias -> requires_grad: False\n",
      "blocks.0.1.conv.weight -> requires_grad: False\n",
      "blocks.0.1.bn1.weight -> requires_grad: False\n",
      "blocks.0.1.bn1.bias -> requires_grad: False\n",
      "blocks.1.0.conv_exp.weight -> requires_grad: False\n",
      "blocks.1.0.bn1.weight -> requires_grad: False\n",
      "blocks.1.0.bn1.bias -> requires_grad: False\n",
      "blocks.1.0.conv_pwl.weight -> requires_grad: False\n",
      "blocks.1.0.bn2.weight -> requires_grad: False\n",
      "blocks.1.0.bn2.bias -> requires_grad: False\n",
      "blocks.1.1.conv_exp.weight -> requires_grad: False\n",
      "blocks.1.1.bn1.weight -> requires_grad: False\n",
      "blocks.1.1.bn1.bias -> requires_grad: False\n",
      "blocks.1.1.conv_pwl.weight -> requires_grad: False\n",
      "blocks.1.1.bn2.weight -> requires_grad: False\n",
      "blocks.1.1.bn2.bias -> requires_grad: False\n",
      "blocks.1.2.conv_exp.weight -> requires_grad: False\n",
      "blocks.1.2.bn1.weight -> requires_grad: False\n",
      "blocks.1.2.bn1.bias -> requires_grad: False\n",
      "blocks.1.2.conv_pwl.weight -> requires_grad: False\n",
      "blocks.1.2.bn2.weight -> requires_grad: False\n",
      "blocks.1.2.bn2.bias -> requires_grad: False\n",
      "blocks.1.3.conv_exp.weight -> requires_grad: False\n",
      "blocks.1.3.bn1.weight -> requires_grad: False\n",
      "blocks.1.3.bn1.bias -> requires_grad: False\n",
      "blocks.1.3.conv_pwl.weight -> requires_grad: False\n",
      "blocks.1.3.bn2.weight -> requires_grad: False\n",
      "blocks.1.3.bn2.bias -> requires_grad: False\n",
      "blocks.2.0.conv_exp.weight -> requires_grad: False\n",
      "blocks.2.0.bn1.weight -> requires_grad: False\n",
      "blocks.2.0.bn1.bias -> requires_grad: False\n",
      "blocks.2.0.conv_pwl.weight -> requires_grad: False\n",
      "blocks.2.0.bn2.weight -> requires_grad: False\n",
      "blocks.2.0.bn2.bias -> requires_grad: False\n",
      "blocks.2.1.conv_exp.weight -> requires_grad: False\n",
      "blocks.2.1.bn1.weight -> requires_grad: False\n",
      "blocks.2.1.bn1.bias -> requires_grad: False\n",
      "blocks.2.1.conv_pwl.weight -> requires_grad: False\n",
      "blocks.2.1.bn2.weight -> requires_grad: False\n",
      "blocks.2.1.bn2.bias -> requires_grad: False\n",
      "blocks.2.2.conv_exp.weight -> requires_grad: False\n",
      "blocks.2.2.bn1.weight -> requires_grad: False\n",
      "blocks.2.2.bn1.bias -> requires_grad: False\n",
      "blocks.2.2.conv_pwl.weight -> requires_grad: False\n",
      "blocks.2.2.bn2.weight -> requires_grad: False\n",
      "blocks.2.2.bn2.bias -> requires_grad: False\n",
      "blocks.2.3.conv_exp.weight -> requires_grad: False\n",
      "blocks.2.3.bn1.weight -> requires_grad: False\n",
      "blocks.2.3.bn1.bias -> requires_grad: False\n",
      "blocks.2.3.conv_pwl.weight -> requires_grad: False\n",
      "blocks.2.3.bn2.weight -> requires_grad: False\n",
      "blocks.2.3.bn2.bias -> requires_grad: False\n",
      "blocks.3.0.conv_pw.weight -> requires_grad: False\n",
      "blocks.3.0.bn1.weight -> requires_grad: False\n",
      "blocks.3.0.bn1.bias -> requires_grad: False\n",
      "blocks.3.0.conv_dw.weight -> requires_grad: False\n",
      "blocks.3.0.bn2.weight -> requires_grad: False\n",
      "blocks.3.0.bn2.bias -> requires_grad: False\n",
      "blocks.3.0.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.3.0.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.3.0.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.3.0.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.3.0.conv_pwl.weight -> requires_grad: False\n",
      "blocks.3.0.bn3.weight -> requires_grad: False\n",
      "blocks.3.0.bn3.bias -> requires_grad: False\n",
      "blocks.3.1.conv_pw.weight -> requires_grad: False\n",
      "blocks.3.1.bn1.weight -> requires_grad: False\n",
      "blocks.3.1.bn1.bias -> requires_grad: False\n",
      "blocks.3.1.conv_dw.weight -> requires_grad: False\n",
      "blocks.3.1.bn2.weight -> requires_grad: False\n",
      "blocks.3.1.bn2.bias -> requires_grad: False\n",
      "blocks.3.1.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.3.1.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.3.1.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.3.1.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.3.1.conv_pwl.weight -> requires_grad: False\n",
      "blocks.3.1.bn3.weight -> requires_grad: False\n",
      "blocks.3.1.bn3.bias -> requires_grad: False\n",
      "blocks.3.2.conv_pw.weight -> requires_grad: False\n",
      "blocks.3.2.bn1.weight -> requires_grad: False\n",
      "blocks.3.2.bn1.bias -> requires_grad: False\n",
      "blocks.3.2.conv_dw.weight -> requires_grad: False\n",
      "blocks.3.2.bn2.weight -> requires_grad: False\n",
      "blocks.3.2.bn2.bias -> requires_grad: False\n",
      "blocks.3.2.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.3.2.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.3.2.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.3.2.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.3.2.conv_pwl.weight -> requires_grad: False\n",
      "blocks.3.2.bn3.weight -> requires_grad: False\n",
      "blocks.3.2.bn3.bias -> requires_grad: False\n",
      "blocks.3.3.conv_pw.weight -> requires_grad: False\n",
      "blocks.3.3.bn1.weight -> requires_grad: False\n",
      "blocks.3.3.bn1.bias -> requires_grad: False\n",
      "blocks.3.3.conv_dw.weight -> requires_grad: False\n",
      "blocks.3.3.bn2.weight -> requires_grad: False\n",
      "blocks.3.3.bn2.bias -> requires_grad: False\n",
      "blocks.3.3.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.3.3.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.3.3.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.3.3.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.3.3.conv_pwl.weight -> requires_grad: False\n",
      "blocks.3.3.bn3.weight -> requires_grad: False\n",
      "blocks.3.3.bn3.bias -> requires_grad: False\n",
      "blocks.3.4.conv_pw.weight -> requires_grad: False\n",
      "blocks.3.4.bn1.weight -> requires_grad: False\n",
      "blocks.3.4.bn1.bias -> requires_grad: False\n",
      "blocks.3.4.conv_dw.weight -> requires_grad: False\n",
      "blocks.3.4.bn2.weight -> requires_grad: False\n",
      "blocks.3.4.bn2.bias -> requires_grad: False\n",
      "blocks.3.4.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.3.4.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.3.4.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.3.4.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.3.4.conv_pwl.weight -> requires_grad: False\n",
      "blocks.3.4.bn3.weight -> requires_grad: False\n",
      "blocks.3.4.bn3.bias -> requires_grad: False\n",
      "blocks.3.5.conv_pw.weight -> requires_grad: False\n",
      "blocks.3.5.bn1.weight -> requires_grad: False\n",
      "blocks.3.5.bn1.bias -> requires_grad: False\n",
      "blocks.3.5.conv_dw.weight -> requires_grad: False\n",
      "blocks.3.5.bn2.weight -> requires_grad: False\n",
      "blocks.3.5.bn2.bias -> requires_grad: False\n",
      "blocks.3.5.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.3.5.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.3.5.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.3.5.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.3.5.conv_pwl.weight -> requires_grad: False\n",
      "blocks.3.5.bn3.weight -> requires_grad: False\n",
      "blocks.3.5.bn3.bias -> requires_grad: False\n",
      "blocks.4.0.conv_pw.weight -> requires_grad: False\n",
      "blocks.4.0.bn1.weight -> requires_grad: False\n",
      "blocks.4.0.bn1.bias -> requires_grad: False\n",
      "blocks.4.0.conv_dw.weight -> requires_grad: False\n",
      "blocks.4.0.bn2.weight -> requires_grad: False\n",
      "blocks.4.0.bn2.bias -> requires_grad: False\n",
      "blocks.4.0.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.4.0.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.4.0.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.4.0.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.4.0.conv_pwl.weight -> requires_grad: False\n",
      "blocks.4.0.bn3.weight -> requires_grad: False\n",
      "blocks.4.0.bn3.bias -> requires_grad: False\n",
      "blocks.4.1.conv_pw.weight -> requires_grad: False\n",
      "blocks.4.1.bn1.weight -> requires_grad: False\n",
      "blocks.4.1.bn1.bias -> requires_grad: False\n",
      "blocks.4.1.conv_dw.weight -> requires_grad: False\n",
      "blocks.4.1.bn2.weight -> requires_grad: False\n",
      "blocks.4.1.bn2.bias -> requires_grad: False\n",
      "blocks.4.1.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.4.1.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.4.1.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.4.1.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.4.1.conv_pwl.weight -> requires_grad: False\n",
      "blocks.4.1.bn3.weight -> requires_grad: False\n",
      "blocks.4.1.bn3.bias -> requires_grad: False\n",
      "blocks.4.2.conv_pw.weight -> requires_grad: False\n",
      "blocks.4.2.bn1.weight -> requires_grad: False\n",
      "blocks.4.2.bn1.bias -> requires_grad: False\n",
      "blocks.4.2.conv_dw.weight -> requires_grad: False\n",
      "blocks.4.2.bn2.weight -> requires_grad: False\n",
      "blocks.4.2.bn2.bias -> requires_grad: False\n",
      "blocks.4.2.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.4.2.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.4.2.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.4.2.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.4.2.conv_pwl.weight -> requires_grad: False\n",
      "blocks.4.2.bn3.weight -> requires_grad: False\n",
      "blocks.4.2.bn3.bias -> requires_grad: False\n",
      "blocks.4.3.conv_pw.weight -> requires_grad: False\n",
      "blocks.4.3.bn1.weight -> requires_grad: False\n",
      "blocks.4.3.bn1.bias -> requires_grad: False\n",
      "blocks.4.3.conv_dw.weight -> requires_grad: False\n",
      "blocks.4.3.bn2.weight -> requires_grad: False\n",
      "blocks.4.3.bn2.bias -> requires_grad: False\n",
      "blocks.4.3.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.4.3.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.4.3.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.4.3.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.4.3.conv_pwl.weight -> requires_grad: False\n",
      "blocks.4.3.bn3.weight -> requires_grad: False\n",
      "blocks.4.3.bn3.bias -> requires_grad: False\n",
      "blocks.4.4.conv_pw.weight -> requires_grad: False\n",
      "blocks.4.4.bn1.weight -> requires_grad: False\n",
      "blocks.4.4.bn1.bias -> requires_grad: False\n",
      "blocks.4.4.conv_dw.weight -> requires_grad: False\n",
      "blocks.4.4.bn2.weight -> requires_grad: False\n",
      "blocks.4.4.bn2.bias -> requires_grad: False\n",
      "blocks.4.4.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.4.4.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.4.4.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.4.4.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.4.4.conv_pwl.weight -> requires_grad: False\n",
      "blocks.4.4.bn3.weight -> requires_grad: False\n",
      "blocks.4.4.bn3.bias -> requires_grad: False\n",
      "blocks.4.5.conv_pw.weight -> requires_grad: False\n",
      "blocks.4.5.bn1.weight -> requires_grad: False\n",
      "blocks.4.5.bn1.bias -> requires_grad: False\n",
      "blocks.4.5.conv_dw.weight -> requires_grad: False\n",
      "blocks.4.5.bn2.weight -> requires_grad: False\n",
      "blocks.4.5.bn2.bias -> requires_grad: False\n",
      "blocks.4.5.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.4.5.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.4.5.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.4.5.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.4.5.conv_pwl.weight -> requires_grad: False\n",
      "blocks.4.5.bn3.weight -> requires_grad: False\n",
      "blocks.4.5.bn3.bias -> requires_grad: False\n",
      "blocks.4.6.conv_pw.weight -> requires_grad: False\n",
      "blocks.4.6.bn1.weight -> requires_grad: False\n",
      "blocks.4.6.bn1.bias -> requires_grad: False\n",
      "blocks.4.6.conv_dw.weight -> requires_grad: False\n",
      "blocks.4.6.bn2.weight -> requires_grad: False\n",
      "blocks.4.6.bn2.bias -> requires_grad: False\n",
      "blocks.4.6.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.4.6.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.4.6.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.4.6.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.4.6.conv_pwl.weight -> requires_grad: False\n",
      "blocks.4.6.bn3.weight -> requires_grad: False\n",
      "blocks.4.6.bn3.bias -> requires_grad: False\n",
      "blocks.4.7.conv_pw.weight -> requires_grad: False\n",
      "blocks.4.7.bn1.weight -> requires_grad: False\n",
      "blocks.4.7.bn1.bias -> requires_grad: False\n",
      "blocks.4.7.conv_dw.weight -> requires_grad: False\n",
      "blocks.4.7.bn2.weight -> requires_grad: False\n",
      "blocks.4.7.bn2.bias -> requires_grad: False\n",
      "blocks.4.7.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.4.7.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.4.7.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.4.7.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.4.7.conv_pwl.weight -> requires_grad: False\n",
      "blocks.4.7.bn3.weight -> requires_grad: False\n",
      "blocks.4.7.bn3.bias -> requires_grad: False\n",
      "blocks.4.8.conv_pw.weight -> requires_grad: False\n",
      "blocks.4.8.bn1.weight -> requires_grad: False\n",
      "blocks.4.8.bn1.bias -> requires_grad: False\n",
      "blocks.4.8.conv_dw.weight -> requires_grad: False\n",
      "blocks.4.8.bn2.weight -> requires_grad: False\n",
      "blocks.4.8.bn2.bias -> requires_grad: False\n",
      "blocks.4.8.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.4.8.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.4.8.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.4.8.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.4.8.conv_pwl.weight -> requires_grad: False\n",
      "blocks.4.8.bn3.weight -> requires_grad: False\n",
      "blocks.4.8.bn3.bias -> requires_grad: False\n",
      "blocks.5.0.conv_pw.weight -> requires_grad: False\n",
      "blocks.5.0.bn1.weight -> requires_grad: False\n",
      "blocks.5.0.bn1.bias -> requires_grad: False\n",
      "blocks.5.0.conv_dw.weight -> requires_grad: False\n",
      "blocks.5.0.bn2.weight -> requires_grad: False\n",
      "blocks.5.0.bn2.bias -> requires_grad: False\n",
      "blocks.5.0.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.5.0.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.5.0.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.5.0.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.5.0.conv_pwl.weight -> requires_grad: False\n",
      "blocks.5.0.bn3.weight -> requires_grad: False\n",
      "blocks.5.0.bn3.bias -> requires_grad: False\n",
      "blocks.5.1.conv_pw.weight -> requires_grad: False\n",
      "blocks.5.1.bn1.weight -> requires_grad: False\n",
      "blocks.5.1.bn1.bias -> requires_grad: False\n",
      "blocks.5.1.conv_dw.weight -> requires_grad: False\n",
      "blocks.5.1.bn2.weight -> requires_grad: False\n",
      "blocks.5.1.bn2.bias -> requires_grad: False\n",
      "blocks.5.1.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.5.1.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.5.1.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.5.1.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.5.1.conv_pwl.weight -> requires_grad: False\n",
      "blocks.5.1.bn3.weight -> requires_grad: False\n",
      "blocks.5.1.bn3.bias -> requires_grad: False\n",
      "blocks.5.2.conv_pw.weight -> requires_grad: False\n",
      "blocks.5.2.bn1.weight -> requires_grad: False\n",
      "blocks.5.2.bn1.bias -> requires_grad: False\n",
      "blocks.5.2.conv_dw.weight -> requires_grad: False\n",
      "blocks.5.2.bn2.weight -> requires_grad: False\n",
      "blocks.5.2.bn2.bias -> requires_grad: False\n",
      "blocks.5.2.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.5.2.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.5.2.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.5.2.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.5.2.conv_pwl.weight -> requires_grad: False\n",
      "blocks.5.2.bn3.weight -> requires_grad: False\n",
      "blocks.5.2.bn3.bias -> requires_grad: False\n",
      "blocks.5.3.conv_pw.weight -> requires_grad: False\n",
      "blocks.5.3.bn1.weight -> requires_grad: False\n",
      "blocks.5.3.bn1.bias -> requires_grad: False\n",
      "blocks.5.3.conv_dw.weight -> requires_grad: False\n",
      "blocks.5.3.bn2.weight -> requires_grad: False\n",
      "blocks.5.3.bn2.bias -> requires_grad: False\n",
      "blocks.5.3.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.5.3.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.5.3.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.5.3.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.5.3.conv_pwl.weight -> requires_grad: False\n",
      "blocks.5.3.bn3.weight -> requires_grad: False\n",
      "blocks.5.3.bn3.bias -> requires_grad: False\n",
      "blocks.5.4.conv_pw.weight -> requires_grad: False\n",
      "blocks.5.4.bn1.weight -> requires_grad: False\n",
      "blocks.5.4.bn1.bias -> requires_grad: False\n",
      "blocks.5.4.conv_dw.weight -> requires_grad: False\n",
      "blocks.5.4.bn2.weight -> requires_grad: False\n",
      "blocks.5.4.bn2.bias -> requires_grad: False\n",
      "blocks.5.4.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.5.4.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.5.4.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.5.4.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.5.4.conv_pwl.weight -> requires_grad: False\n",
      "blocks.5.4.bn3.weight -> requires_grad: False\n",
      "blocks.5.4.bn3.bias -> requires_grad: False\n",
      "blocks.5.5.conv_pw.weight -> requires_grad: False\n",
      "blocks.5.5.bn1.weight -> requires_grad: False\n",
      "blocks.5.5.bn1.bias -> requires_grad: False\n",
      "blocks.5.5.conv_dw.weight -> requires_grad: False\n",
      "blocks.5.5.bn2.weight -> requires_grad: False\n",
      "blocks.5.5.bn2.bias -> requires_grad: False\n",
      "blocks.5.5.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.5.5.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.5.5.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.5.5.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.5.5.conv_pwl.weight -> requires_grad: False\n",
      "blocks.5.5.bn3.weight -> requires_grad: False\n",
      "blocks.5.5.bn3.bias -> requires_grad: False\n",
      "blocks.5.6.conv_pw.weight -> requires_grad: False\n",
      "blocks.5.6.bn1.weight -> requires_grad: False\n",
      "blocks.5.6.bn1.bias -> requires_grad: False\n",
      "blocks.5.6.conv_dw.weight -> requires_grad: False\n",
      "blocks.5.6.bn2.weight -> requires_grad: False\n",
      "blocks.5.6.bn2.bias -> requires_grad: False\n",
      "blocks.5.6.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.5.6.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.5.6.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.5.6.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.5.6.conv_pwl.weight -> requires_grad: False\n",
      "blocks.5.6.bn3.weight -> requires_grad: False\n",
      "blocks.5.6.bn3.bias -> requires_grad: False\n",
      "blocks.5.7.conv_pw.weight -> requires_grad: False\n",
      "blocks.5.7.bn1.weight -> requires_grad: False\n",
      "blocks.5.7.bn1.bias -> requires_grad: False\n",
      "blocks.5.7.conv_dw.weight -> requires_grad: False\n",
      "blocks.5.7.bn2.weight -> requires_grad: False\n",
      "blocks.5.7.bn2.bias -> requires_grad: False\n",
      "blocks.5.7.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.5.7.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.5.7.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.5.7.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.5.7.conv_pwl.weight -> requires_grad: False\n",
      "blocks.5.7.bn3.weight -> requires_grad: False\n",
      "blocks.5.7.bn3.bias -> requires_grad: False\n",
      "blocks.5.8.conv_pw.weight -> requires_grad: False\n",
      "blocks.5.8.bn1.weight -> requires_grad: False\n",
      "blocks.5.8.bn1.bias -> requires_grad: False\n",
      "blocks.5.8.conv_dw.weight -> requires_grad: False\n",
      "blocks.5.8.bn2.weight -> requires_grad: False\n",
      "blocks.5.8.bn2.bias -> requires_grad: False\n",
      "blocks.5.8.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.5.8.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.5.8.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.5.8.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.5.8.conv_pwl.weight -> requires_grad: False\n",
      "blocks.5.8.bn3.weight -> requires_grad: False\n",
      "blocks.5.8.bn3.bias -> requires_grad: False\n",
      "blocks.5.9.conv_pw.weight -> requires_grad: False\n",
      "blocks.5.9.bn1.weight -> requires_grad: False\n",
      "blocks.5.9.bn1.bias -> requires_grad: False\n",
      "blocks.5.9.conv_dw.weight -> requires_grad: False\n",
      "blocks.5.9.bn2.weight -> requires_grad: False\n",
      "blocks.5.9.bn2.bias -> requires_grad: False\n",
      "blocks.5.9.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.5.9.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.5.9.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.5.9.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.5.9.conv_pwl.weight -> requires_grad: False\n",
      "blocks.5.9.bn3.weight -> requires_grad: False\n",
      "blocks.5.9.bn3.bias -> requires_grad: False\n",
      "blocks.5.10.conv_pw.weight -> requires_grad: False\n",
      "blocks.5.10.bn1.weight -> requires_grad: False\n",
      "blocks.5.10.bn1.bias -> requires_grad: False\n",
      "blocks.5.10.conv_dw.weight -> requires_grad: False\n",
      "blocks.5.10.bn2.weight -> requires_grad: False\n",
      "blocks.5.10.bn2.bias -> requires_grad: False\n",
      "blocks.5.10.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.5.10.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.5.10.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.5.10.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.5.10.conv_pwl.weight -> requires_grad: False\n",
      "blocks.5.10.bn3.weight -> requires_grad: False\n",
      "blocks.5.10.bn3.bias -> requires_grad: False\n",
      "blocks.5.11.conv_pw.weight -> requires_grad: False\n",
      "blocks.5.11.bn1.weight -> requires_grad: False\n",
      "blocks.5.11.bn1.bias -> requires_grad: False\n",
      "blocks.5.11.conv_dw.weight -> requires_grad: False\n",
      "blocks.5.11.bn2.weight -> requires_grad: False\n",
      "blocks.5.11.bn2.bias -> requires_grad: False\n",
      "blocks.5.11.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.5.11.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.5.11.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.5.11.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.5.11.conv_pwl.weight -> requires_grad: False\n",
      "blocks.5.11.bn3.weight -> requires_grad: False\n",
      "blocks.5.11.bn3.bias -> requires_grad: False\n",
      "blocks.5.12.conv_pw.weight -> requires_grad: False\n",
      "blocks.5.12.bn1.weight -> requires_grad: False\n",
      "blocks.5.12.bn1.bias -> requires_grad: False\n",
      "blocks.5.12.conv_dw.weight -> requires_grad: False\n",
      "blocks.5.12.bn2.weight -> requires_grad: False\n",
      "blocks.5.12.bn2.bias -> requires_grad: False\n",
      "blocks.5.12.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.5.12.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.5.12.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.5.12.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.5.12.conv_pwl.weight -> requires_grad: False\n",
      "blocks.5.12.bn3.weight -> requires_grad: False\n",
      "blocks.5.12.bn3.bias -> requires_grad: False\n",
      "blocks.5.13.conv_pw.weight -> requires_grad: False\n",
      "blocks.5.13.bn1.weight -> requires_grad: False\n",
      "blocks.5.13.bn1.bias -> requires_grad: False\n",
      "blocks.5.13.conv_dw.weight -> requires_grad: False\n",
      "blocks.5.13.bn2.weight -> requires_grad: False\n",
      "blocks.5.13.bn2.bias -> requires_grad: False\n",
      "blocks.5.13.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.5.13.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.5.13.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.5.13.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.5.13.conv_pwl.weight -> requires_grad: False\n",
      "blocks.5.13.bn3.weight -> requires_grad: False\n",
      "blocks.5.13.bn3.bias -> requires_grad: False\n",
      "blocks.5.14.conv_pw.weight -> requires_grad: False\n",
      "blocks.5.14.bn1.weight -> requires_grad: False\n",
      "blocks.5.14.bn1.bias -> requires_grad: False\n",
      "blocks.5.14.conv_dw.weight -> requires_grad: False\n",
      "blocks.5.14.bn2.weight -> requires_grad: False\n",
      "blocks.5.14.bn2.bias -> requires_grad: False\n",
      "blocks.5.14.se.conv_reduce.weight -> requires_grad: False\n",
      "blocks.5.14.se.conv_reduce.bias -> requires_grad: False\n",
      "blocks.5.14.se.conv_expand.weight -> requires_grad: False\n",
      "blocks.5.14.se.conv_expand.bias -> requires_grad: False\n",
      "blocks.5.14.conv_pwl.weight -> requires_grad: False\n",
      "blocks.5.14.bn3.weight -> requires_grad: False\n",
      "blocks.5.14.bn3.bias -> requires_grad: False\n",
      "conv_head.weight -> requires_grad: False\n",
      "bn2.weight -> requires_grad: False\n",
      "bn2.bias -> requires_grad: False\n",
      "classifier.weight -> requires_grad: True\n",
      "classifier.bias -> requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "# You can iterate over all parameters of the model and print their names and requires_grad status. This will help you verify whether the freezing and updating status are set correctly.\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name} -> requires_grad: {param.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight in classifier -> requires_grad: True\n",
      "bias in classifier -> requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "# If you are only interested in certain layers (such as classification layers), you can check the parameter status of these layers specifically:\n",
    "\n",
    "# Assuming the classifier layer is named 'classifier'\n",
    "for name, param in model.classifier.named_parameters():\n",
    "    print(f\"{name} in classifier -> requires_grad: {param.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "EfficientNet                                  [128, 160]                --\n",
       "├─Conv2d: 1-1                                 [128, 24, 19, 125]        (216)\n",
       "├─BatchNormAct2d: 1-2                         [128, 24, 19, 125]        48\n",
       "│    └─Identity: 2-1                          [128, 24, 19, 125]        --\n",
       "│    └─SiLU: 2-2                              [128, 24, 19, 125]        --\n",
       "├─Sequential: 1-3                             [128, 256, 2, 8]          --\n",
       "│    └─Sequential: 2-3                        [128, 24, 19, 125]        --\n",
       "│    │    └─ConvBnAct: 3-1                    [128, 24, 19, 125]        (5,232)\n",
       "│    │    └─ConvBnAct: 3-2                    [128, 24, 19, 125]        (5,232)\n",
       "│    └─Sequential: 2-4                        [128, 48, 10, 63]         --\n",
       "│    │    └─EdgeResidual: 3-3                 [128, 48, 10, 63]         (25,632)\n",
       "│    │    └─EdgeResidual: 3-4                 [128, 48, 10, 63]         (92,640)\n",
       "│    │    └─EdgeResidual: 3-5                 [128, 48, 10, 63]         (92,640)\n",
       "│    │    └─EdgeResidual: 3-6                 [128, 48, 10, 63]         (92,640)\n",
       "│    └─Sequential: 2-5                        [128, 64, 5, 32]          --\n",
       "│    │    └─EdgeResidual: 3-7                 [128, 64, 5, 32]          (95,744)\n",
       "│    │    └─EdgeResidual: 3-8                 [128, 64, 5, 32]          (164,480)\n",
       "│    │    └─EdgeResidual: 3-9                 [128, 64, 5, 32]          (164,480)\n",
       "│    │    └─EdgeResidual: 3-10                [128, 64, 5, 32]          (164,480)\n",
       "│    └─Sequential: 2-6                        [128, 128, 3, 16]         --\n",
       "│    │    └─InvertedResidual: 3-11            [128, 128, 3, 16]         (61,200)\n",
       "│    │    └─InvertedResidual: 3-12            [128, 128, 3, 16]         (171,296)\n",
       "│    │    └─InvertedResidual: 3-13            [128, 128, 3, 16]         (171,296)\n",
       "│    │    └─InvertedResidual: 3-14            [128, 128, 3, 16]         (171,296)\n",
       "│    │    └─InvertedResidual: 3-15            [128, 128, 3, 16]         (171,296)\n",
       "│    │    └─InvertedResidual: 3-16            [128, 128, 3, 16]         (171,296)\n",
       "│    └─Sequential: 2-7                        [128, 160, 3, 16]         --\n",
       "│    │    └─InvertedResidual: 3-17            [128, 160, 3, 16]         (281,440)\n",
       "│    │    └─InvertedResidual: 3-18            [128, 160, 3, 16]         (397,800)\n",
       "│    │    └─InvertedResidual: 3-19            [128, 160, 3, 16]         (397,800)\n",
       "│    │    └─InvertedResidual: 3-20            [128, 160, 3, 16]         (397,800)\n",
       "│    │    └─InvertedResidual: 3-21            [128, 160, 3, 16]         (397,800)\n",
       "│    │    └─InvertedResidual: 3-22            [128, 160, 3, 16]         (397,800)\n",
       "│    │    └─InvertedResidual: 3-23            [128, 160, 3, 16]         (397,800)\n",
       "│    │    └─InvertedResidual: 3-24            [128, 160, 3, 16]         (397,800)\n",
       "│    │    └─InvertedResidual: 3-25            [128, 160, 3, 16]         (397,800)\n",
       "│    └─Sequential: 2-8                        [128, 256, 2, 8]          --\n",
       "│    │    └─InvertedResidual: 3-26            [128, 256, 2, 8]          (490,152)\n",
       "│    │    └─InvertedResidual: 3-27            [128, 256, 2, 8]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-28            [128, 256, 2, 8]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-29            [128, 256, 2, 8]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-30            [128, 256, 2, 8]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-31            [128, 256, 2, 8]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-32            [128, 256, 2, 8]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-33            [128, 256, 2, 8]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-34            [128, 256, 2, 8]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-35            [128, 256, 2, 8]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-36            [128, 256, 2, 8]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-37            [128, 256, 2, 8]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-38            [128, 256, 2, 8]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-39            [128, 256, 2, 8]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-40            [128, 256, 2, 8]          (1,005,120)\n",
       "├─Conv2d: 1-4                                 [128, 1280, 2, 8]         (327,680)\n",
       "├─BatchNormAct2d: 1-5                         [128, 1280, 2, 8]         2,560\n",
       "│    └─Identity: 2-9                          [128, 1280, 2, 8]         --\n",
       "│    └─SiLU: 2-10                             [128, 1280, 2, 8]         --\n",
       "├─SelectAdaptivePool2d: 1-6                   [128, 1280]               --\n",
       "│    └─AdaptiveAvgPool2d: 2-11                [128, 1280, 1, 1]         --\n",
       "│    └─Flatten: 2-12                          [128, 1280]               --\n",
       "├─Linear: 1-7                                 [128, 160]                204,960\n",
       "===============================================================================================\n",
       "Total params: 20,382,016\n",
       "Trainable params: 204,960\n",
       "Non-trainable params: 20,177,056\n",
       "Total mult-adds (G): 86.80\n",
       "===============================================================================================\n",
       "Input size (MB): 5.14\n",
       "Forward/backward pass size (MB): 3064.55\n",
       "Params size (MB): 80.91\n",
       "Estimated Total Size (MB): 3150.60\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model,input_size=(128,1,40,251))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdclef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
